{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34a0ad60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading graphs...\n",
      "Loaded /home/ubuntu/myproject/venv/drug_data_kg_openfda_edges_no_drop.graphml -> DiGraph | nodes=100,495 edges=160,229\n",
      "Loaded /home/ubuntu/myproject/venv/primekg_hetionet_combined.graphml -> DiGraph | nodes=176,408 edges=9,435,440\n",
      "\n",
      "OpenFDA types (top): [('drug', 55430), ('effect/phenotype', 27473), ('exposure', 16513), ('disease', 1079)] | missing node_name: 0\n",
      "PrimeKG+Hetionet types (top): [('gene/protein', 48616), ('biological_process', 40023), ('effect/phenotype', 21483), ('disease', 17217), ('anatomy', 14437), ('molecular_function', 14053), ('drug', 9854), ('cellular_component', 5567), ('pathway', 4338), ('exposure', 818)] | missing node_name: 0\n",
      "Adding OpenFDA nodes and edges...\n",
      "After OpenFDA -> merged: nodes=95,170 edges=160,229\n",
      "Adding PrimeKG nodes and edges...\n",
      "After PrimeKG -> merged: nodes=233,412 edges=9,595,669\n",
      "Saving merged graph...\n",
      "Saved merged graph (GraphML) -> /home/ubuntu/myproject/venv/merged_openfda_primekg.graphml\n",
      "Saved merged graph (Pickle) -> /home/ubuntu/myproject/venv/merged_openfda_primekg.pickle\n",
      "Generating summary...\n",
      "\n",
      "=== MERGED SUMMARY ===\n",
      "{\n",
      "  \"graph_kind\": \"MultiDiGraph\",\n",
      "  \"nodes\": 233412,\n",
      "  \"edges\": 9595669,\n",
      "  \"node_types_count\": 11,\n",
      "  \"node_types\": [\n",
      "    [\n",
      "      \"drug\",\n",
      "      58968\n",
      "    ],\n",
      "    [\n",
      "      \"effect/phenotype\",\n",
      "      46644\n",
      "    ],\n",
      "    [\n",
      "      \"gene/protein\",\n",
      "      30319\n",
      "    ],\n",
      "    [\n",
      "      \"biological_process\",\n",
      "      29439\n",
      "    ],\n",
      "    [\n",
      "      \"disease\",\n",
      "      18119\n",
      "    ],\n",
      "    [\n",
      "      \"exposure\",\n",
      "      16921\n",
      "    ],\n",
      "    [\n",
      "      \"anatomy\",\n",
      "      14037\n",
      "    ],\n",
      "    [\n",
      "      \"molecular_function\",\n",
      "      11501\n",
      "    ],\n",
      "    [\n",
      "      \"cellular_component\",\n",
      "      4269\n",
      "    ],\n",
      "    [\n",
      "      \"pathway\",\n",
      "      3193\n",
      "    ],\n",
      "    [\n",
      "      \"unknown\",\n",
      "      2\n",
      "    ]\n",
      "  ],\n",
      "  \"relation_types_count\": 38,\n",
      "  \"relation_types\": [\n",
      "    [\n",
      "      \"anatomy_protein_present\",\n",
      "      3624231\n",
      "    ],\n",
      "    [\n",
      "      \"drug_drug\",\n",
      "      2737099\n",
      "    ],\n",
      "    [\n",
      "      \"protein_protein\",\n",
      "      788421\n",
      "    ],\n",
      "    [\n",
      "      \"disease_phenotype_positive\",\n",
      "      300634\n",
      "    ],\n",
      "    [\n",
      "      \"bioprocess_protein\",\n",
      "      289610\n",
      "    ],\n",
      "    [\n",
      "      \"gene_regulates_gene\",\n",
      "      265672\n",
      "    ],\n",
      "    [\n",
      "      \"drug_effect\",\n",
      "      227081\n",
      "    ],\n",
      "    [\n",
      "      \"disease_protein\",\n",
      "      188520\n",
      "    ],\n",
      "    [\n",
      "      \"pathway_protein\",\n",
      "      169664\n",
      "    ],\n",
      "    [\n",
      "      \"cellcomp_protein\",\n",
      "      166804\n",
      "    ],\n",
      "    [\n",
      "      \"molfunc_protein\",\n",
      "      139060\n",
      "    ],\n",
      "    [\n",
      "      \"bioprocess_bioprocess\",\n",
      "      105770\n",
      "    ],\n",
      "    [\n",
      "      \"drug_protein\",\n",
      "      102292\n",
      "    ],\n",
      "    [\n",
      "      \"bert_group\",\n",
      "      97490\n",
      "    ],\n",
      "    [\n",
      "      \"disease_disease\",\n",
      "      64929\n",
      "    ],\n",
      "    [\n",
      "      \"contraindication\",\n",
      "      64318\n",
      "    ],\n",
      "    [\n",
      "      \"gene_gene\",\n",
      "      61632\n",
      "    ],\n",
      "    [\n",
      "      \"anatomy_protein_absent\",\n",
      "      39774\n",
      "    ],\n",
      "    [\n",
      "      \"phenotype_phenotype\",\n",
      "      37468\n",
      "    ],\n",
      "    [\n",
      "      \"anatomy_anatomy\",\n",
      "      28064\n",
      "    ],\n",
      "    [\n",
      "      \"molfunc_molfunc\",\n",
      "      27148\n",
      "    ],\n",
      "    [\n",
      "      \"indication\",\n",
      "      18620\n",
      "    ],\n",
      "    [\n",
      "      \"cellcomp_cellcomp\",\n",
      "      9690\n",
      "    ],\n",
      "    [\n",
      "      \"phenotype_protein\",\n",
      "      6660\n",
      "    ],\n",
      "    [\n",
      "      \"pathway_pathway\",\n",
      "      5070\n",
      "    ],\n",
      "    [\n",
      "      \"off-label use\",\n",
      "      5036\n",
      "    ],\n",
      "    [\n",
      "      \"exposure_disease\",\n",
      "      4608\n",
      "    ],\n",
      "    [\n",
      "      \"exposure_exposure\",\n",
      "      4140\n",
      "    ],\n",
      "    [\n",
      "      \"disease_anatomy\",\n",
      "      3602\n",
      "    ],\n",
      "    [\n",
      "      \"disease_phenotype\",\n",
      "      3357\n",
      "    ],\n",
      "    [\n",
      "      \"exposure_bioprocess\",\n",
      "      3250\n",
      "    ],\n",
      "    [\n",
      "      \"exposure_protein\",\n",
      "      2424\n",
      "    ],\n",
      "    [\n",
      "      \"disease_phenotype_negative\",\n",
      "      2042\n",
      "    ],\n",
      "    [\n",
      "      \"drug_disease\",\n",
      "      1285\n",
      "    ],\n",
      "    [\n",
      "      \"exposure_molfunc\",\n",
      "      90\n",
      "    ],\n",
      "    [\n",
      "      \"metaedge\",\n",
      "      86\n",
      "    ],\n",
      "    [\n",
      "      \"exposure_cellcomp\",\n",
      "      20\n",
      "    ],\n",
      "    [\n",
      "      \"bert_related\",\n",
      "      8\n",
      "    ]\n",
      "  ],\n",
      "  \"connectivity\": {\n",
      "    \"components\": 9405,\n",
      "    \"largest_component_size\": 219157,\n",
      "    \"largest_component_fraction\": 0.938927732935753,\n",
      "    \"orphans\": 8136\n",
      "  },\n",
      "  \"keys_used\": {\n",
      "    \"node_type_key\": \"node_type\",\n",
      "    \"edge_rel_key\": \"relation\"\n",
      "  },\n",
      "  \"triplet_schema_types\": 101,\n",
      "  \"triplet_schema_top\": [\n",
      "    [\n",
      "      [\n",
      "        \"drug\",\n",
      "        \"drug_drug\",\n",
      "        \"drug\"\n",
      "      ],\n",
      "      2737099\n",
      "    ],\n",
      "    [\n",
      "      [\n",
      "        \"anatomy\",\n",
      "        \"anatomy_protein_present\",\n",
      "        \"gene/protein\"\n",
      "      ],\n",
      "      2106030\n",
      "    ],\n",
      "    [\n",
      "      [\n",
      "        \"gene/protein\",\n",
      "        \"anatomy_protein_present\",\n",
      "        \"anatomy\"\n",
      "      ],\n",
      "      1518201\n",
      "    ],\n",
      "    [\n",
      "      [\n",
      "        \"gene/protein\",\n",
      "        \"protein_protein\",\n",
      "        \"gene/protein\"\n",
      "      ],\n",
      "      788421\n",
      "    ],\n",
      "    [\n",
      "      [\n",
      "        \"gene/protein\",\n",
      "        \"gene_regulates_gene\",\n",
      "        \"gene/protein\"\n",
      "      ],\n",
      "      265672\n",
      "    ],\n",
      "    [\n",
      "      [\n",
      "        \"effect/phenotype\",\n",
      "        \"disease_phenotype_positive\",\n",
      "        \"disease\"\n",
      "      ],\n",
      "      150317\n",
      "    ],\n",
      "    [\n",
      "      [\n",
      "        \"disease\",\n",
      "        \"disease_phenotype_positive\",\n",
      "        \"effect/phenotype\"\n",
      "      ],\n",
      "      150317\n",
      "    ],\n",
      "    [\n",
      "      [\n",
      "        \"gene/protein\",\n",
      "        \"bioprocess_protein\",\n",
      "        \"biological_process\"\n",
      "      ],\n",
      "      144805\n",
      "    ],\n",
      "    [\n",
      "      [\n",
      "        \"biological_process\",\n",
      "        \"bioprocess_protein\",\n",
      "        \"gene/protein\"\n",
      "      ],\n",
      "      144805\n",
      "    ],\n",
      "    [\n",
      "      [\n",
      "        \"drug\",\n",
      "        \"drug_effect\",\n",
      "        \"effect/phenotype\"\n",
      "      ],\n",
      "      135043\n",
      "    ],\n",
      "    [\n",
      "      [\n",
      "        \"gene/protein\",\n",
      "        \"pathway_protein\",\n",
      "        \"pathway\"\n",
      "      ],\n",
      "      127018\n",
      "    ],\n",
      "    [\n",
      "      [\n",
      "        \"disease\",\n",
      "        \"disease_protein\",\n",
      "        \"gene/protein\"\n",
      "      ],\n",
      "      108110\n",
      "    ],\n",
      "    [\n",
      "      [\n",
      "        \"biological_process\",\n",
      "        \"bioprocess_bioprocess\",\n",
      "        \"biological_process\"\n",
      "      ],\n",
      "      105770\n",
      "    ],\n",
      "    [\n",
      "      [\n",
      "        \"gene/protein\",\n",
      "        \"cellcomp_protein\",\n",
      "        \"cellular_component\"\n",
      "      ],\n",
      "      83402\n",
      "    ],\n",
      "    [\n",
      "      [\n",
      "        \"cellular_component\",\n",
      "        \"cellcomp_protein\",\n",
      "        \"gene/protein\"\n",
      "      ],\n",
      "      83402\n",
      "    ],\n",
      "    [\n",
      "      [\n",
      "        \"gene/protein\",\n",
      "        \"disease_protein\",\n",
      "        \"disease\"\n",
      "      ],\n",
      "      80410\n",
      "    ],\n",
      "    [\n",
      "      [\n",
      "        \"drug\",\n",
      "        \"drug_protein\",\n",
      "        \"gene/protein\"\n",
      "      ],\n",
      "      76828\n",
      "    ],\n",
      "    [\n",
      "      [\n",
      "        \"gene/protein\",\n",
      "        \"molfunc_protein\",\n",
      "        \"molecular_function\"\n",
      "      ],\n",
      "      69530\n",
      "    ],\n",
      "    [\n",
      "      [\n",
      "        \"molecular_function\",\n",
      "        \"molfunc_protein\",\n",
      "        \"gene/protein\"\n",
      "      ],\n",
      "      69530\n",
      "    ],\n",
      "    [\n",
      "      [\n",
      "        \"disease\",\n",
      "        \"disease_disease\",\n",
      "        \"disease\"\n",
      "      ],\n",
      "      64929\n",
      "    ],\n",
      "    [\n",
      "      [\n",
      "        \"effect/phenotype\",\n",
      "        \"drug_effect\",\n",
      "        \"drug\"\n",
      "      ],\n",
      "      64919\n",
      "    ],\n",
      "    [\n",
      "      [\n",
      "        \"gene/protein\",\n",
      "        \"gene_gene\",\n",
      "        \"gene/protein\"\n",
      "      ],\n",
      "      61632\n",
      "    ],\n",
      "    [\n",
      "      [\n",
      "        \"pathway\",\n",
      "        \"pathway_protein\",\n",
      "        \"gene/protein\"\n",
      "      ],\n",
      "      42646\n",
      "    ],\n",
      "    [\n",
      "      [\n",
      "        \"gene/protein\",\n",
      "        \"bert_group\",\n",
      "        \"gene/protein\"\n",
      "      ],\n",
      "      42231\n",
      "    ],\n",
      "    [\n",
      "      [\n",
      "        \"effect/phenotype\",\n",
      "        \"phenotype_phenotype\",\n",
      "        \"effect/phenotype\"\n",
      "      ],\n",
      "      37468\n",
      "    ],\n",
      "    [\n",
      "      [\n",
      "        \"drug\",\n",
      "        \"contraindication\",\n",
      "        \"disease\"\n",
      "      ],\n",
      "      33717\n",
      "    ],\n",
      "    [\n",
      "      [\n",
      "        \"disease\",\n",
      "        \"contraindication\",\n",
      "        \"drug\"\n",
      "      ],\n",
      "      30593\n",
      "    ],\n",
      "    [\n",
      "      [\n",
      "        \"anatomy\",\n",
      "        \"anatomy_anatomy\",\n",
      "        \"anatomy\"\n",
      "      ],\n",
      "      28064\n",
      "    ],\n",
      "    [\n",
      "      [\n",
      "        \"molecular_function\",\n",
      "        \"molfunc_molfunc\",\n",
      "        \"molecular_function\"\n",
      "      ],\n",
      "      27148\n",
      "    ],\n",
      "    [\n",
      "      [\n",
      "        \"drug\",\n",
      "        \"drug_effect\",\n",
      "        \"exposure\"\n",
      "      ],\n",
      "      27060\n",
      "    ]\n",
      "  ]\n",
      "}\n",
      "\n",
      "Summary saved -> /home/ubuntu/myproject/venv/merged_openfda_primekg.summary.json\n",
      "\n",
      "=== FILES SAVED ===\n",
      "GraphML: /home/ubuntu/myproject/venv/merged_openfda_primekg.graphml\n",
      "Pickle:  /home/ubuntu/myproject/venv/merged_openfda_primekg.pickle\n",
      "Summary: /home/ubuntu/myproject/venv/merged_openfda_primekg.summary.json\n",
      "\n",
      "File sizes:\n",
      "GraphML: 1708.06 MB\n",
      "Pickle:  579.61 MB\n",
      "Ratio:   2.95x (Pickle is 0.34x smaller)\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "from collections import Counter, defaultdict\n",
    "from pathlib import Path\n",
    "import json\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "# =========================\n",
    "# CONFIG: set your paths (update these to your file locations in Drive)\n",
    "# =========================\n",
    "# Update these paths to point to your files in Google Drive\n",
    "OPENFDA_PATH =  \"/home/ubuntu/myproject/venv/drug_data_kg_openfda_edges_no_drop.graphml\"\n",
    "PRIMEKG_PATH = \"/home/ubuntu/myproject/venv/primekg_hetionet_combined.graphml\"\n",
    "OUT_MERGED_GRAPH = \"/home/ubuntu/myproject/venv/merged_openfda_primekg.graphml\"\n",
    "OUT_MERGED_PICKLE = \"/home/ubuntu/myproject/venv/merged_openfda_primekg.pickle\"\n",
    "OUT_SUMMARY_JSON = \"/home/ubuntu/myproject/venv/merged_openfda_primekg.summary.json\"\n",
    "\n",
    "# Options\n",
    "USE_MULTIGRAPH = True          # keep every parallel edge (no drops)\n",
    "NORMALIZE_NAMES = True         # lower/strip/collapse spaces for node_name when matching\n",
    "PREFER_NODE_SOURCE = \"primekg\" # if node attribute conflicts: \"openfda\" or \"primekg\"\n",
    "\n",
    "# =========================\n",
    "# Helpers\n",
    "# =========================\n",
    "def load_graph(path):\n",
    "    G = nx.read_graphml(path)\n",
    "    kind = \"MultiDiGraph\" if G.is_multigraph() else \"DiGraph\"\n",
    "    print(f\"Loaded {path} -> {kind} | nodes={G.number_of_nodes():,} edges={G.number_of_edges():,}\")\n",
    "    return G\n",
    "\n",
    "def get_attr(attrs, k, default=\"\"):\n",
    "    v = attrs.get(k)\n",
    "    return default if v is None else v\n",
    "\n",
    "_ws_re = re.compile(r\"\\s+\")\n",
    "def canon_name(name: str) -> str:\n",
    "    s = name if isinstance(name, str) else str(name)\n",
    "    if NORMALIZE_NAMES:\n",
    "        s = _ws_re.sub(\" \", s.strip().lower())\n",
    "    return s\n",
    "\n",
    "def node_inventory(G, node_type_key=\"node_type\", node_name_key=\"node_name\"):\n",
    "    types = Counter(nx.get_node_attributes(G, node_type_key).values())\n",
    "    names_missing = sum(1 for _, a in G.nodes(data=True) if node_name_key not in a or not str(a.get(node_name_key,\"\")).strip())\n",
    "    return types, names_missing\n",
    "\n",
    "def ensure_node_basics(G, source_tag):\n",
    "    # guarantee node_name and node_source exist\n",
    "    for n, a in G.nodes(data=True):\n",
    "        if \"node_name\" not in a or not str(a.get(\"node_name\",\"\")).strip():\n",
    "            a[\"node_name\"] = str(n)\n",
    "        # stamp node_source if missing (may already exist in your KGs)\n",
    "        if \"node_source\" not in a or not a[\"node_source\"]:\n",
    "            a[\"node_source\"] = source_tag\n",
    "\n",
    "def summarize_graph(G, node_type_key=\"node_type\", edge_rel_key=\"relation\"):\n",
    "    kind = \"MultiDiGraph\" if G.is_multigraph() else \"DiGraph\"\n",
    "    n_nodes = G.number_of_nodes()\n",
    "    n_edges = G.number_of_edges()\n",
    "    node_types = Counter(nx.get_node_attributes(G, node_type_key).values())\n",
    "    edge_types = Counter(nx.get_edge_attributes(G, edge_rel_key).values())\n",
    "\n",
    "    node_types_list = sorted(node_types.items(), key=lambda kv: (-kv[1], kv[0]))\n",
    "    edge_types_list = sorted(edge_types.items(), key=lambda kv: (-kv[1], kv[0]))\n",
    "\n",
    "    # connectivity (MultiGraphs supported)\n",
    "    UG = G.to_undirected()\n",
    "    comps = list(nx.connected_components(UG))\n",
    "    largest = max((len(c) for c in comps), default=0)\n",
    "    frac = (largest / n_nodes) if n_nodes else 0.0\n",
    "    orphans = sum(1 for _ in nx.isolates(G))\n",
    "\n",
    "    summary = {\n",
    "        \"graph_kind\": kind,\n",
    "        \"nodes\": int(n_nodes),\n",
    "        \"edges\": int(n_edges),\n",
    "\n",
    "        \"node_types_count\": int(len(node_types_list)),\n",
    "        \"node_types\": node_types_list,\n",
    "\n",
    "        \"relation_types_count\": int(len(edge_types_list)),\n",
    "        \"relation_types\": edge_types_list,\n",
    "\n",
    "        \"connectivity\": {\n",
    "            \"components\": int(len(comps)),\n",
    "            \"largest_component_size\": int(largest),\n",
    "            \"largest_component_fraction\": float(frac),\n",
    "            \"orphans\": int(orphans),\n",
    "        },\n",
    "\n",
    "        \"keys_used\": {\n",
    "            \"node_type_key\": node_type_key,\n",
    "            \"edge_rel_key\": edge_rel_key,\n",
    "        },\n",
    "    }\n",
    "    return summary\n",
    "\n",
    "def triplet_schema(G, node_type_key=\"node_type\", edge_rel_key=\"relation\", top=30):\n",
    "    # list unique (src_type, relation, dst_type) and counts\n",
    "    counts = Counter()\n",
    "    # works for DiGraph & MultiDiGraph\n",
    "    if G.is_multigraph():\n",
    "        for u, v, k, a in G.edges(keys=True, data=True):\n",
    "            r = a.get(edge_rel_key, \"unknown\")\n",
    "            st = G.nodes[u].get(node_type_key, \"unknown\")\n",
    "            dt = G.nodes[v].get(node_type_key, \"unknown\")\n",
    "            counts[(st, r, dt)] += 1\n",
    "    else:\n",
    "        for u, v, a in G.edges(data=True):\n",
    "            r = a.get(edge_rel_key, \"unknown\")\n",
    "            st = G.nodes[u].get(node_type_key, \"unknown\")\n",
    "            dt = G.nodes[v].get(node_type_key, \"unknown\")\n",
    "            counts[(st, r, dt)] += 1\n",
    "    total = len(counts)\n",
    "    top_items = counts.most_common(top)\n",
    "    return total, top_items\n",
    "\n",
    "# =========================\n",
    "# Load graphs\n",
    "# =========================\n",
    "print(\"Loading graphs...\")\n",
    "G1 = load_graph(OPENFDA_PATH)     # your normalized OpenFDA minimal (node_type/node_name/node_source + relation/subfield)\n",
    "G2 = load_graph(PRIMEKG_PATH)     # PrimeKG+Hetionet combined\n",
    "\n",
    "# Ensure basic attrs present\n",
    "ensure_node_basics(G1, \"openfda\")\n",
    "ensure_node_basics(G2, \"primekg\")\n",
    "\n",
    "# Quick pre-merge stats\n",
    "t1, miss1 = node_inventory(G1)\n",
    "t2, miss2 = node_inventory(G2)\n",
    "print(\"\\nOpenFDA types (top):\", t1.most_common(10), \"| missing node_name:\", miss1)\n",
    "print(\"PrimeKG+Hetionet types (top):\", t2.most_common(10), \"| missing node_name:\", miss2)\n",
    "\n",
    "# =========================\n",
    "# Build canonical map by (node_type, node_name)\n",
    "# We create a fresh MultiDiGraph (or DiGraph) so nothing is lost.\n",
    "# =========================\n",
    "MG = nx.MultiDiGraph() if USE_MULTIGRAPH else nx.DiGraph()\n",
    "\n",
    "NODE_TYPE_KEY = \"node_type\"\n",
    "NODE_NAME_KEY = \"node_name\"\n",
    "NODE_SOURCE_KEY = \"node_source\"\n",
    "EDGE_REL_KEY = \"relation\"\n",
    "\n",
    "# map canonical key -> merged node id\n",
    "canon2id = {}\n",
    "# keep an incremental integer suffix to avoid accidental id collisions\n",
    "next_int = 0\n",
    "\n",
    "def make_merged_id(ntype, nname):\n",
    "    # Construct a stable readable id. If collides, append counter.\n",
    "    global next_int  # Use global instead of nonlocal\n",
    "    base = f\"{ntype}::{nname}\"\n",
    "    if base in MG:  # extremely rare; but handle\n",
    "        while f\"{base}##{next_int}\" in MG:\n",
    "            next_int += 1\n",
    "        return f\"{base}##{next_int}\"\n",
    "    return base\n",
    "\n",
    "def upsert_node(nid, attrs, source_graph):\n",
    "    \"\"\"Insert node into merged graph using canonical (type, name) matching. Returns merged node id.\"\"\"\n",
    "    ntype = get_attr(attrs, NODE_TYPE_KEY, \"unknown\")\n",
    "    nname = get_attr(attrs, NODE_NAME_KEY, str(nid))\n",
    "    ckey = (canon_name(ntype), canon_name(nname))\n",
    "\n",
    "    if ckey in canon2id:\n",
    "        mid = canon2id[ckey]\n",
    "        # merge attributes (prefer PRIMEKG if configured)\n",
    "        existing = MG.nodes[mid]\n",
    "        # keep node_type and node_name as-is\n",
    "        # merge node_source\n",
    "        srcs = set(str(existing.get(NODE_SOURCE_KEY, \"\")).split(\"|\")) if existing.get(NODE_SOURCE_KEY) else set()\n",
    "        srcs2 = set(str(attrs.get(NODE_SOURCE_KEY, \"\")).split(\"|\")) if attrs.get(NODE_SOURCE_KEY) else set()\n",
    "        all_srcs = [s for s in (srcs | srcs2) if s]\n",
    "        MG.nodes[mid][NODE_SOURCE_KEY] = \"|\".join(sorted(set(all_srcs))) if all_srcs else existing.get(NODE_SOURCE_KEY, \"\")\n",
    "        # retain an 'orig_id_<source>' list\n",
    "        tag = \"primekg\" if source_graph == \"primekg\" else \"openfda\"\n",
    "        orig_key = f\"orig_id_{tag}\"\n",
    "        olds = set(str(MG.nodes[mid].get(orig_key, \"\")).split(\"|\")) if MG.nodes[mid].get(orig_key) else set()\n",
    "        olds.add(str(nid))\n",
    "        MG.nodes[mid][orig_key] = \"|\".join(sorted(olds))\n",
    "        return mid\n",
    "    else:\n",
    "        mid = make_merged_id(ntype, nname)\n",
    "        canon2id[ckey] = mid\n",
    "        # initialize node attrs\n",
    "        MG.add_node(mid)\n",
    "        MG.nodes[mid][NODE_TYPE_KEY] = ntype\n",
    "        MG.nodes[mid][NODE_NAME_KEY] = nname\n",
    "        MG.nodes[mid][NODE_SOURCE_KEY] = attrs.get(NODE_SOURCE_KEY, source_graph)\n",
    "        # store original ids by source\n",
    "        tag = \"primekg\" if source_graph == \"primekg\" else \"openfda\"\n",
    "        MG.nodes[mid][f\"orig_id_{tag}\"] = str(nid)\n",
    "        return mid\n",
    "\n",
    "def add_edge_preserving(u_mid, v_mid, eattrs, source_graph):\n",
    "    # always keep relation and subfield if present\n",
    "    rel = eattrs.get(EDGE_REL_KEY, \"unknown\")\n",
    "    subf = eattrs.get(\"subfield\", None)\n",
    "    payload = {\n",
    "        EDGE_REL_KEY: rel,\n",
    "        \"source_graph\": source_graph,\n",
    "    }\n",
    "    if subf is not None:\n",
    "        payload[\"subfield\"] = subf\n",
    "    # optional: keep original endpoints for traceability\n",
    "    # payload[\"orig_u\"] = str(u_mid)  # usually not needed\n",
    "    # payload[\"orig_v\"] = str(v_mid)\n",
    "    if MG.is_multigraph():\n",
    "        MG.add_edge(u_mid, v_mid, **payload)\n",
    "    else:\n",
    "        # In DiGraph, last write wins; to avoid drops we could count, but we promised no drops, so Multi is recommended.\n",
    "        MG.add_edge(u_mid, v_mid, **payload)\n",
    "\n",
    "# =========================\n",
    "# Add OpenFDA nodes/edges\n",
    "# =========================\n",
    "print(\"Adding OpenFDA nodes and edges...\")\n",
    "for n, a in G1.nodes(data=True):\n",
    "    upsert_node(n, a, \"openfda\")\n",
    "\n",
    "if G1.is_multigraph():\n",
    "    for u, v, k, a in G1.edges(keys=True, data=True):\n",
    "        u_mid = upsert_node(u, G1.nodes[u], \"openfda\")\n",
    "        v_mid = upsert_node(v, G1.nodes[v], \"openfda\")\n",
    "        add_edge_preserving(u_mid, v_mid, a, \"openfda\")\n",
    "else:\n",
    "    for u, v, a in G1.edges(data=True):\n",
    "        u_mid = upsert_node(u, G1.nodes[u], \"openfda\")\n",
    "        v_mid = upsert_node(v, G1.nodes[v], \"openfda\")\n",
    "        add_edge_preserving(u_mid, v_mid, a, \"openfda\")\n",
    "\n",
    "print(f\"After OpenFDA -> merged: nodes={MG.number_of_nodes():,} edges={MG.number_of_edges():,}\")\n",
    "\n",
    "# =========================\n",
    "# Add PrimeKG nodes/edges\n",
    "# =========================\n",
    "print(\"Adding PrimeKG nodes and edges...\")\n",
    "for n, a in G2.nodes(data=True):\n",
    "    upsert_node(n, a, \"primekg\")\n",
    "\n",
    "if G2.is_multigraph():\n",
    "    for u, v, k, a in G2.edges(keys=True, data=True):\n",
    "        u_mid = upsert_node(u, G2.nodes[u], \"primekg\")\n",
    "        v_mid = upsert_node(v, G2.nodes[v], \"primekg\")\n",
    "        add_edge_preserving(u_mid, v_mid, a, \"primekg\")\n",
    "else:\n",
    "    for u, v, a in G2.edges(data=True):\n",
    "        u_mid = upsert_node(u, G2.nodes[u], \"primekg\")\n",
    "        v_mid = upsert_node(v, G2.nodes[v], \"primekg\")\n",
    "        add_edge_preserving(u_mid, v_mid, a, \"primekg\")\n",
    "\n",
    "print(f\"After PrimeKG -> merged: nodes={MG.number_of_nodes():,} edges={MG.number_of_edges():,}\")\n",
    "\n",
    "# =========================\n",
    "# Optional: prefer one source's attrs when conflicts (kept minimal here)\n",
    "# =========================\n",
    "# You can extend this block to pull preferred per-type attributes.\n",
    "\n",
    "# =========================\n",
    "# Save merged graph in multiple formats\n",
    "# =========================\n",
    "print(\"Saving merged graph...\")\n",
    "\n",
    "# Save as GraphML\n",
    "nx.write_graphml(MG, OUT_MERGED_GRAPH)\n",
    "print(f\"Saved merged graph (GraphML) -> {OUT_MERGED_GRAPH}\")\n",
    "\n",
    "# Save as pickle\n",
    "with open(OUT_MERGED_PICKLE, 'wb') as f:\n",
    "    pickle.dump(MG, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "print(f\"Saved merged graph (Pickle) -> {OUT_MERGED_PICKLE}\")\n",
    "\n",
    "# =========================\n",
    "# Build & save summary\n",
    "# =========================\n",
    "print(\"Generating summary...\")\n",
    "summary = summarize_graph(MG, node_type_key=NODE_TYPE_KEY, edge_rel_key=EDGE_REL_KEY)\n",
    "\n",
    "# Triplet schema preview\n",
    "schema_total, schema_top = triplet_schema(MG, node_type_key=NODE_TYPE_KEY, edge_rel_key=EDGE_REL_KEY, top=30)\n",
    "summary[\"triplet_schema_types\"] = int(schema_total)\n",
    "summary[\"triplet_schema_top\"] = [[list(k), int(v)] for k, v in schema_top]\n",
    "\n",
    "with open(OUT_SUMMARY_JSON, \"w\") as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(\"\\n=== MERGED SUMMARY ===\")\n",
    "print(json.dumps(summary, indent=2))\n",
    "print(f\"\\nSummary saved -> {OUT_SUMMARY_JSON}\")\n",
    "\n",
    "# =========================\n",
    "# Additional info about the saved files\n",
    "# =========================\n",
    "print(f\"\\n=== FILES SAVED ===\")\n",
    "print(f\"GraphML: {OUT_MERGED_GRAPH}\")\n",
    "print(f\"Pickle:  {OUT_MERGED_PICKLE}\")\n",
    "print(f\"Summary: {OUT_SUMMARY_JSON}\")\n",
    "\n",
    "# Quick comparison of file sizes\n",
    "import os\n",
    "if os.path.exists(OUT_MERGED_GRAPH) and os.path.exists(OUT_MERGED_PICKLE):\n",
    "    graphml_size = os.path.getsize(OUT_MERGED_GRAPH) / (1024*1024)  # MB\n",
    "    pickle_size = os.path.getsize(OUT_MERGED_PICKLE) / (1024*1024)  # MB\n",
    "    print(f\"\\nFile sizes:\")\n",
    "    print(f\"GraphML: {graphml_size:.2f} MB\")\n",
    "    print(f\"Pickle:  {pickle_size:.2f} MB\")\n",
    "    if graphml_size > 0:\n",
    "        print(f\"Ratio:   {graphml_size/pickle_size:.2f}x (Pickle is {pickle_size/graphml_size:.2f}x smaller)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52ef3aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "ðŸ“¥ Loading GraphML from: /home/ubuntu/myproject/venv/merged_openfda_primekg.graphml\n",
      "âœ… Loaded graph with 233412 nodes and 9595669 edges.\n",
      "âœ… Node types: ['drug', 'effect/phenotype', 'exposure', 'disease', 'gene/protein', 'biological_process', 'molecular_function', 'cellular_component', 'pathway', 'anatomy', 'unknown']\n",
      "âœ… Total edge types: 101\n",
      "Homogeneous nodes: 233412, edges used for training: 7676495\n",
      "\n",
      "ðŸ” Training with NeighborLoader mini-batches + AMP ...\n",
      "Epoch 01 | Loss: 53.8263 | Seen pos edges: 319488\n",
      "Epoch 02 | Loss: 48.6513 | Seen pos edges: 319488\n",
      "Epoch 03 | Loss: 43.4767 | Seen pos edges: 319488\n",
      "Epoch 04 | Loss: 41.6179 | Seen pos edges: 319488\n",
      "Epoch 05 | Loss: 40.6705 | Seen pos edges: 319488\n",
      "Epoch 06 | Loss: 40.0388 | Seen pos edges: 319488\n",
      "Epoch 07 | Loss: 39.4785 | Seen pos edges: 319488\n",
      "Epoch 08 | Loss: 38.9883 | Seen pos edges: 319488\n",
      "Epoch 09 | Loss: 38.5955 | Seen pos edges: 319488\n",
      "Epoch 10 | Loss: 38.3429 | Seen pos edges: 319488\n",
      "Epoch 11 | Loss: 38.1515 | Seen pos edges: 319488\n",
      "Epoch 12 | Loss: 37.9042 | Seen pos edges: 319488\n",
      "Epoch 13 | Loss: 37.7110 | Seen pos edges: 319488\n",
      "Epoch 14 | Loss: 37.4933 | Seen pos edges: 319488\n",
      "Epoch 15 | Loss: 37.4034 | Seen pos edges: 319488\n",
      "Epoch 16 | Loss: 37.2136 | Seen pos edges: 319488\n",
      "Epoch 17 | Loss: 37.1369 | Seen pos edges: 319488\n",
      "Epoch 18 | Loss: 37.0567 | Seen pos edges: 319488\n",
      "Epoch 19 | Loss: 36.9525 | Seen pos edges: 319488\n",
      "Epoch 20 | Loss: 36.8851 | Seen pos edges: 319488\n",
      "Epoch 21 | Loss: 36.7075 | Seen pos edges: 319488\n",
      "Epoch 22 | Loss: 36.7322 | Seen pos edges: 319488\n",
      "Epoch 23 | Loss: 36.6551 | Seen pos edges: 319488\n",
      "Epoch 24 | Loss: 36.5374 | Seen pos edges: 319488\n",
      "Epoch 25 | Loss: 36.5454 | Seen pos edges: 319488\n",
      "Epoch 26 | Loss: 36.4537 | Seen pos edges: 319488\n",
      "Epoch 27 | Loss: 36.2543 | Seen pos edges: 319488\n",
      "Epoch 28 | Loss: 36.1976 | Seen pos edges: 319488\n",
      "Epoch 29 | Loss: 36.1673 | Seen pos edges: 319488\n",
      "Epoch 30 | Loss: 36.0931 | Seen pos edges: 319488\n",
      "\n",
      "ðŸ”Ž Computing full-node embeddings (batched inference) ...\n",
      "\n",
      "ðŸ“Š Final evaluation per edge type (filtered negatives, DistMult):\n",
      "('drug', 'drug_drug', 'drug'): AUC=0.9772, P=0.970, R=0.851, F1=0.907\n",
      "('drug', 'drug_effect', 'effect/phenotype'): AUC=0.6852, P=0.982, R=0.447, F1=0.615\n",
      "('drug', 'drug_effect', 'exposure'): AUC=0.5000, P=0.000, R=0.000, F1=0.000\n",
      "('drug', 'contraindication', 'disease'): AUC=0.8958, P=0.956, R=0.647, F1=0.772\n",
      "('disease', 'disease_disease', 'disease'): AUC=0.6758, P=0.646, R=0.557, F1=0.599\n",
      "('disease', 'contraindication', 'drug'): AUC=0.9591, P=0.955, R=0.761, F1=0.847\n",
      "('disease', 'indication', 'drug'): AUC=0.9378, P=0.967, R=0.627, F1=0.760\n",
      "('disease', 'off-label use', 'drug'): AUC=0.9483, P=0.982, R=0.640, F1=0.775\n",
      "('disease', 'disease_protein', 'gene/protein'): AUC=0.7927, P=0.711, R=0.786, F1=0.746\n",
      "('disease', 'exposure_disease', 'exposure'): AUC=0.7363, P=0.966, R=0.610, F1=0.748\n",
      "('drug', 'drug_protein', 'gene/protein'): AUC=0.8781, P=0.856, R=0.750, F1=0.799\n",
      "('drug', 'indication', 'disease'): AUC=0.8279, P=0.888, R=0.642, F1=0.745\n",
      "('drug', 'bert_group', 'drug'): AUC=0.8188, P=0.931, R=0.481, F1=0.634\n",
      "('drug', 'bert_group', 'gene/protein'): AUC=0.8444, P=0.893, R=0.657, F1=0.757\n",
      "('drug', 'bert_group', 'biological_process'): AUC=0.6211, P=0.682, R=0.441, F1=0.536\n",
      "('drug', 'bert_group', 'molecular_function'): AUC=0.9541, P=1.000, R=0.595, F1=0.746\n",
      "('drug', 'off-label use', 'disease'): AUC=0.8385, P=0.817, R=0.743, F1=0.778\n",
      "('effect/phenotype', 'drug_effect', 'drug'): AUC=0.9814, P=0.964, R=0.920, F1=0.942\n",
      "('effect/phenotype', 'indication', 'effect/phenotype'): AUC=0.5547, P=0.000, R=0.000, F1=0.000\n",
      "('effect/phenotype', 'drug_effect', 'effect/phenotype'): AUC=0.5000, P=0.000, R=0.000, F1=0.000\n",
      "('effect/phenotype', 'metaedge', 'exposure'): AUC=0.5000, P=0.000, R=0.000, F1=0.000\n",
      "('effect/phenotype', 'metaedge', 'effect/phenotype'): AUC=0.5000, P=0.000, R=0.000, F1=0.000\n",
      "('drug', 'bert_group', 'effect/phenotype'): AUC=0.5640, P=0.588, R=0.588, F1=0.588\n",
      "('drug', 'drug_disease', 'disease'): AUC=0.8780, P=0.942, R=0.752, F1=0.836\n",
      "('drug', 'bert_group', 'disease'): AUC=0.9106, P=0.897, R=0.758, F1=0.821\n",
      "('effect/phenotype', 'phenotype_phenotype', 'effect/phenotype'): AUC=0.6670, P=0.847, R=0.336, F1=0.481\n",
      "('effect/phenotype', 'phenotype_protein', 'gene/protein'): AUC=0.7737, P=0.704, R=0.763, F1=0.732\n",
      "('effect/phenotype', 'disease_phenotype_positive', 'disease'): AUC=0.8380, P=0.805, R=0.659, F1=0.725\n",
      "('effect/phenotype', 'disease_phenotype_negative', 'disease'): AUC=0.7445, P=0.729, R=0.495, F1=0.590\n",
      "('effect/phenotype', 'contraindication', 'effect/phenotype'): AUC=0.5000, P=0.000, R=0.000, F1=0.000\n",
      "('disease', 'disease_phenotype_positive', 'effect/phenotype'): AUC=0.8615, P=0.946, R=0.634, F1=0.759\n",
      "('disease', 'disease_phenotype', 'effect/phenotype'): AUC=0.7661, P=0.974, R=0.332, F1=0.496\n",
      "('disease', 'disease_anatomy', 'anatomy'): AUC=0.8936, P=0.931, R=0.670, F1=0.779\n",
      "('disease', 'bert_related', 'gene/protein'): AUC=0.2500, P=0.000, R=0.000, F1=0.000\n",
      "('gene/protein', 'protein_protein', 'gene/protein'): AUC=0.8262, P=0.775, R=0.709, F1=0.740\n",
      "('gene/protein', 'molfunc_protein', 'molecular_function'): AUC=0.9173, P=0.943, R=0.658, F1=0.775\n",
      "('gene/protein', 'cellcomp_protein', 'cellular_component'): AUC=0.9324, P=0.933, R=0.739, F1=0.825\n",
      "('gene/protein', 'bioprocess_protein', 'biological_process'): AUC=0.8532, P=0.820, R=0.697, F1=0.754\n",
      "('gene/protein', 'anatomy_protein_present', 'anatomy'): AUC=0.9950, P=0.992, R=0.107, F1=0.194\n",
      "('gene/protein', 'anatomy_protein_absent', 'anatomy'): AUC=0.9961, P=0.971, R=0.033, F1=0.064\n",
      "('gene/protein', 'gene_gene', 'gene/protein'): AUC=0.7105, P=0.587, R=0.834, F1=0.689\n",
      "('gene/protein', 'disease_protein', 'disease'): AUC=0.9163, P=0.902, R=0.774, F1=0.833\n",
      "('gene/protein', 'pathway_protein', 'pathway'): AUC=0.7386, P=0.636, R=0.787, F1=0.704\n",
      "('gene/protein', 'gene_regulates_gene', 'gene/protein'): AUC=0.9318, P=0.874, R=0.833, F1=0.853\n",
      "('gene/protein', 'drug_protein', 'drug'): AUC=0.8387, P=0.825, R=0.718, F1=0.768\n",
      "('gene/protein', 'phenotype_protein', 'effect/phenotype'): AUC=0.9516, P=0.970, R=0.766, F1=0.856\n",
      "('gene/protein', 'exposure_protein', 'exposure'): AUC=0.8506, P=0.940, R=0.639, F1=0.761\n",
      "('gene/protein', 'bert_group', 'gene/protein'): AUC=0.8777, P=0.812, R=0.791, F1=0.801\n",
      "('gene/protein', 'bert_group', 'drug'): AUC=0.8477, P=0.937, R=0.626, F1=0.750\n",
      "('gene/protein', 'bert_group', 'disease'): AUC=0.9050, P=0.844, R=0.804, F1=0.824\n",
      "('gene/protein', 'bert_group', 'effect/phenotype'): AUC=0.3698, P=0.375, R=0.517, F1=0.435\n",
      "('gene/protein', 'bert_group', 'molecular_function'): AUC=0.9108, P=1.000, R=0.683, F1=0.812\n",
      "('gene/protein', 'bert_group', 'biological_process'): AUC=0.7789, P=0.697, R=0.639, F1=0.667\n",
      "('effect/phenotype', 'bert_group', 'effect/phenotype'): AUC=0.8685, P=0.882, R=0.714, F1=0.789\n",
      "('effect/phenotype', 'bert_group', 'biological_process'): AUC=0.7500, P=0.000, R=0.000, F1=0.000\n",
      "('effect/phenotype', 'bert_group', 'drug'): AUC=0.6332, P=1.000, R=0.176, F1=0.300\n",
      "('effect/phenotype', 'bert_group', 'gene/protein'): AUC=0.5993, P=0.533, R=0.828, F1=0.649\n",
      "('effect/phenotype', 'bert_group', 'disease'): AUC=0.9184, P=1.000, R=0.429, F1=0.600\n",
      "('effect/phenotype', 'bert_group', 'molecular_function'): AUC=0.0000, P=0.000, R=0.000, F1=0.000\n",
      "('disease', 'disease_phenotype_negative', 'effect/phenotype'): AUC=0.7240, P=0.914, R=0.515, F1=0.658\n",
      "('disease', 'bert_group', 'drug'): AUC=0.8984, P=0.905, R=0.754, F1=0.822\n",
      "('disease', 'bert_group', 'gene/protein'): AUC=0.8433, P=0.704, R=0.851, F1=0.771\n",
      "('disease', 'bert_group', 'disease'): AUC=0.9357, P=0.856, R=0.832, F1=0.844\n",
      "('disease', 'bert_group', 'molecular_function'): AUC=0.9688, P=0.978, R=0.917, F1=0.946\n",
      "('disease', 'bert_group', 'biological_process'): AUC=0.7773, P=0.917, R=0.688, F1=0.786\n",
      "('disease', 'bert_group', 'effect/phenotype'): AUC=1.0000, P=0.875, R=1.000, F1=0.933\n",
      "('biological_process', 'bioprocess_bioprocess', 'biological_process'): AUC=0.6133, P=0.624, R=0.417, F1=0.500\n",
      "('biological_process', 'bioprocess_protein', 'gene/protein'): AUC=0.7211, P=0.660, R=0.726, F1=0.692\n",
      "('biological_process', 'exposure_bioprocess', 'exposure'): AUC=0.7818, P=0.953, R=0.620, F1=0.751\n",
      "('biological_process', 'bert_group', 'biological_process'): AUC=0.8787, P=0.895, R=0.586, F1=0.708\n",
      "('biological_process', 'bert_group', 'disease'): AUC=0.9375, P=0.778, R=0.875, F1=0.824\n",
      "('biological_process', 'bert_group', 'gene/protein'): AUC=0.7807, P=0.710, R=0.681, F1=0.695\n",
      "('biological_process', 'bert_group', 'effect/phenotype'): AUC=0.2500, P=0.333, R=0.500, F1=0.400\n",
      "('biological_process', 'bert_group', 'molecular_function'): AUC=1.0000, P=1.000, R=1.000, F1=1.000\n",
      "('biological_process', 'bert_group', 'drug'): AUC=0.8927, P=0.957, R=0.647, F1=0.772\n",
      "('molecular_function', 'molfunc_molfunc', 'molecular_function'): AUC=0.5566, P=0.566, R=0.296, F1=0.389\n",
      "('molecular_function', 'molfunc_protein', 'gene/protein'): AUC=0.6928, P=0.659, R=0.668, F1=0.663\n",
      "('molecular_function', 'exposure_molfunc', 'exposure'): AUC=0.7200, P=0.750, R=0.600, F1=0.667\n",
      "('molecular_function', 'bert_group', 'gene/protein'): AUC=0.7933, P=0.708, R=0.767, F1=0.736\n",
      "('molecular_function', 'bert_group', 'drug'): AUC=0.9104, P=0.968, R=0.714, F1=0.822\n",
      "('molecular_function', 'bert_group', 'molecular_function'): AUC=0.9473, P=0.903, R=0.875, F1=0.889\n",
      "('molecular_function', 'bert_group', 'disease'): AUC=0.9674, P=0.852, R=0.958, F1=0.902\n",
      "('molecular_function', 'bert_group', 'effect/phenotype'): AUC=0.0000, P=0.500, R=1.000, F1=0.667\n",
      "('molecular_function', 'bert_group', 'biological_process'): AUC=0.5000, P=0.000, R=0.000, F1=0.000\n",
      "('cellular_component', 'cellcomp_cellcomp', 'cellular_component'): AUC=0.5148, P=0.519, R=0.456, F1=0.486\n",
      "('cellular_component', 'cellcomp_protein', 'gene/protein'): AUC=0.7084, P=0.669, R=0.687, F1=0.678\n",
      "('cellular_component', 'exposure_cellcomp', 'exposure'): AUC=1.0000, P=0.500, R=1.000, F1=0.667\n",
      "('exposure', 'exposure_protein', 'gene/protein'): AUC=0.7143, P=0.704, R=0.623, F1=0.661\n",
      "('exposure', 'exposure_bioprocess', 'biological_process'): AUC=0.8121, P=0.821, R=0.564, F1=0.669\n",
      "('exposure', 'exposure_exposure', 'exposure'): AUC=0.6830, P=0.937, R=0.324, F1=0.481\n",
      "('exposure', 'exposure_disease', 'disease'): AUC=0.8545, P=0.923, R=0.519, F1=0.665\n",
      "('exposure', 'exposure_molfunc', 'molecular_function'): AUC=0.4400, P=0.500, R=1.000, F1=0.667\n",
      "('exposure', 'exposure_cellcomp', 'cellular_component'): AUC=1.0000, P=0.000, R=0.000, F1=0.000\n",
      "('pathway', 'pathway_pathway', 'pathway'): AUC=0.6637, P=0.678, R=0.485, F1=0.566\n",
      "('pathway', 'pathway_protein', 'gene/protein'): AUC=0.8573, P=0.775, R=0.810, F1=0.792\n",
      "('anatomy', 'anatomy_anatomy', 'anatomy'): AUC=0.4676, P=0.480, R=0.579, F1=0.525\n",
      "('anatomy', 'anatomy_protein_present', 'gene/protein'): AUC=0.6318, P=0.567, R=0.439, F1=0.495\n",
      "('anatomy', 'anatomy_protein_absent', 'gene/protein'): AUC=0.4696, P=0.509, R=0.030, F1=0.056\n",
      "\n",
      "ðŸŒ Overall Performance (filtered-ish, typed tails, DistMult):\n",
      "Overall AUC = 0.8432\n",
      "Overall Precision = 0.800\n",
      "Overall Recall = 0.585\n",
      "Overall F1 Score = 0.676\n"
     ]
    }
   ],
   "source": [
    "# === GraphML â†’ R-GCN (NeighborLoader + AMP + batched inference) ===\n",
    "# Fixes:\n",
    "#  - DistMult scoring (relation-aware) in train + eval\n",
    "#  - Typed negatives sampled *within the batch* (local), avoiding drop\n",
    "#  - zero_division=0 to silence undefined metric warnings\n",
    "\n",
    "import os, gc, random\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch_geometric.nn import RGCNConv\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score\n",
    "import networkx as nx\n",
    "\n",
    "# ----------------------------\n",
    "# 0) Repro + Device\n",
    "# ----------------------------\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED)\n",
    "torch.manual_seed(SEED); torch.cuda.manual_seed_all(SEED)\n",
    "os.environ.setdefault(\"PYTORCH_CUDA_ALLOC_CONF\", \"expandable_segments:True\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "gc.collect()\n",
    "if device.type == \"cuda\":\n",
    "    torch.cuda.empty_cache()\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# ----------------------------\n",
    "# 1) Load GraphML + normalize attrs\n",
    "# ----------------------------\n",
    "graph_path = \"/home/ubuntu/myproject/venv/merged_openfda_primekg.graphml\"\n",
    "assert os.path.exists(graph_path), f\"Path does not exist: {graph_path}\"\n",
    "print(f\"ðŸ“¥ Loading GraphML from: {graph_path}\")\n",
    "\n",
    "G0 = nx.read_graphml(graph_path)\n",
    "G = nx.MultiDiGraph()\n",
    "G.add_nodes_from(G0.nodes(data=True))\n",
    "if G0.is_multigraph():\n",
    "    for u,v,k,d in G0.edges(keys=True, data=True):\n",
    "        G.add_edge(u,v,key=k, **(d or {}))\n",
    "else:\n",
    "    for u,v,d in G0.edges(data=True):\n",
    "        G.add_edge(u,v, **(d or {}))\n",
    "\n",
    "for n,data in G.nodes(data=True):\n",
    "    if \"node_type\" not in data:\n",
    "        data[\"node_type\"] = data.get(\"type\", data.get(\"category\", data.get(\"kind\",\"unknown\")))\n",
    "for u,v,attr in G.edges(data=True):\n",
    "    if \"relation\" not in attr:\n",
    "        attr[\"relation\"] = attr.get(\"relationship\", attr.get(\"type\", attr.get(\"label\",\"unknown\")))\n",
    "\n",
    "print(f\"âœ… Loaded graph with {len(G.nodes)} nodes and {len(G.edges)} edges.\")\n",
    "\n",
    "# ----------------------------\n",
    "# 2) Typed remap + splits\n",
    "# ----------------------------\n",
    "node_type_map = defaultdict(list)\n",
    "node_id_map = {}\n",
    "for nid,data in G.nodes(data=True):\n",
    "    ntype = data.get(\"node_type\",\"unknown\")\n",
    "    idx = len(node_type_map[ntype])\n",
    "    node_type_map[ntype].append(nid)\n",
    "    node_id_map[nid] = (ntype, idx)\n",
    "\n",
    "edge_type_map = defaultdict(list)  # (src_type, rel, dst_type) -> [(src_local, dst_local)]\n",
    "for s,t,attr in G.edges(data=True):\n",
    "    if s not in node_id_map or t not in node_id_map: continue\n",
    "    rel = attr.get(\"relation\",\"unknown\")\n",
    "    s_t,s_i = node_id_map[s]\n",
    "    t_t,t_i = node_id_map[t]\n",
    "    edge_type_map[(s_t, rel, t_t)].append((s_i,t_i))\n",
    "\n",
    "print(f\"âœ… Node types: {list(node_type_map.keys())}\")\n",
    "print(f\"âœ… Total edge types: {len(edge_type_map)}\")\n",
    "\n",
    "# Global ids per (type, local)\n",
    "type_offsets, global_id_map = {}, {}\n",
    "offset = 0\n",
    "for ntype, nodes in node_type_map.items():\n",
    "    type_offsets[ntype] = offset\n",
    "    for i in range(len(nodes)):\n",
    "        global_id_map[(ntype,i)] = offset + i\n",
    "    offset += len(nodes)\n",
    "num_nodes = offset\n",
    "\n",
    "edge_type_keys = list(edge_type_map.keys())         # rel_id -> (src_type, rel, dst_type)\n",
    "rel2id = {k:i for i,k in enumerate(edge_type_keys)}\n",
    "num_relations = len(edge_type_keys)\n",
    "\n",
    "all_src, all_dst, all_rel = [], [], []\n",
    "edge_type_splits = {}\n",
    "\n",
    "for etype, pairs in edge_type_map.items():\n",
    "    s_type,_, t_type = etype\n",
    "    if len(pairs) < 5:  # keep only relations with minimum support\n",
    "        continue\n",
    "    perm = torch.randperm(len(pairs))\n",
    "    n_tr = int(0.8*len(pairs)); n_va = int(0.1*len(pairs))\n",
    "    tr = [pairs[i] for i in perm[:n_tr]]\n",
    "    va = [pairs[i] for i in perm[n_tr:n_tr+n_va]]\n",
    "    te = [pairs[i] for i in perm[n_tr+n_va:]]\n",
    "\n",
    "    r = rel2id[etype]\n",
    "    for s_l, t_l in tr:\n",
    "        all_src.append(type_offsets[s_type] + s_l)\n",
    "        all_dst.append(type_offsets[t_type] + t_l)\n",
    "        all_rel.append(r)\n",
    "\n",
    "    edge_type_splits[etype] = {\n",
    "        \"val\": torch.tensor([[type_offsets[s_type]+s for s,_ in va],\n",
    "                             [type_offsets[t_type]+t for _,t in va]], dtype=torch.long),\n",
    "        \"test\": torch.tensor([[type_offsets[s_type]+s for s,_ in te],\n",
    "                              [type_offsets[t_type]+t for _,t in te]], dtype=torch.long),\n",
    "    }\n",
    "\n",
    "edge_index_cpu = torch.tensor([all_src, all_dst], dtype=torch.long)\n",
    "edge_type_cpu  = torch.tensor(all_rel, dtype=torch.long)\n",
    "print(f\"Homogeneous nodes: {num_nodes}, edges used for training: {edge_index_cpu.size(1)}\")\n",
    "\n",
    "# For quick type lookup by GLOBAL id (used for local typed negatives)\n",
    "type_names = sorted(node_type_map.keys())\n",
    "type2id = {t:i for i,t in enumerate(type_names)}\n",
    "global_node_type_id = torch.empty(num_nodes, dtype=torch.long)\n",
    "for tname, nodes in node_type_map.items():\n",
    "    t_id = type2id[tname]\n",
    "    base = type_offsets[tname]\n",
    "    n = len(nodes)\n",
    "    global_node_type_id[base:base+n] = t_id\n",
    "\n",
    "# Existing edges per relation (LOCAL to each (src_type,rel,dst_type))\n",
    "existing_edges_per_rel = {etype: set(pairs) for etype,pairs in edge_type_map.items()}\n",
    "def relid_to_etype(rel_id:int):\n",
    "    return edge_type_keys[rel_id]\n",
    "\n",
    "# ----------------------------\n",
    "# 3) PyG Data + NeighborLoader\n",
    "# ----------------------------\n",
    "data_pyg = Data(num_nodes=num_nodes, edge_index=edge_index_cpu, edge_type=edge_type_cpu)\n",
    "\n",
    "NUM_NEIGHBORS = [15, 10]\n",
    "NBATCH_SIZE   = 4096\n",
    "NUM_WORKERS   = 2  # quiets the OS warning\n",
    "\n",
    "train_src_unique = torch.unique(edge_index_cpu[0])\n",
    "train_loader = NeighborLoader(\n",
    "    data_pyg,\n",
    "    num_neighbors=NUM_NEIGHBORS,\n",
    "    batch_size=NBATCH_SIZE,\n",
    "    input_nodes=train_src_unique,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_WORKERS\n",
    ")\n",
    "\n",
    "# ----------------------------\n",
    "# 4) Model (DistMult) + helpers\n",
    "# ----------------------------\n",
    "class RGCN(nn.Module):\n",
    "    def __init__(self, num_nodes, num_relations, emb_dim=64, hidden_dim=128, out_dim=32, num_bases=30):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(num_nodes, emb_dim)\n",
    "        self.conv1 = RGCNConv(emb_dim, hidden_dim, num_relations=num_relations, num_bases=num_bases)\n",
    "        self.conv2 = RGCNConv(hidden_dim, out_dim, num_relations=num_relations, num_bases=num_bases)\n",
    "        self.rel_emb = nn.Embedding(num_relations, out_dim)\n",
    "\n",
    "        nn.init.xavier_uniform_(self.emb.weight)\n",
    "        nn.init.xavier_uniform_(self.rel_emb.weight)\n",
    "\n",
    "    def forward(self, n_id, edge_index, edge_type):\n",
    "        # n_id: global ids ordered as local nodes in the subgraph\n",
    "        x = self.emb(n_id)\n",
    "        x = self.conv1(x, edge_index, edge_type).relu_()\n",
    "        x = self.conv2(x, edge_index, edge_type)\n",
    "        return x  # local node embeddings\n",
    "\n",
    "    def score(self, h, r, t):\n",
    "        # DistMult (logits)\n",
    "        return (h * r * t).sum(dim=-1)\n",
    "\n",
    "def distmult_sigmoid_scores(z, rel_emb, eidx, rel_ids):\n",
    "    h = z[eidx[0]]; t = z[eidx[1]]\n",
    "    r = rel_emb(rel_ids)\n",
    "    return (h * r * t).sum(dim=-1).sigmoid()\n",
    "\n",
    "# ----------------------------\n",
    "# 5) Local (in-batch) typed negatives\n",
    "# ----------------------------\n",
    "def build_local_type_pools(n_id_device):\n",
    "    \"\"\"Map node_type_id -> list of LOCAL indices present in this batch.\"\"\"\n",
    "    g_types = global_node_type_id.to(n_id_device.device, non_blocking=True)[n_id_device]\n",
    "    pools = defaultdict(list)\n",
    "    for local_idx, t in enumerate(g_types.tolist()):\n",
    "        pools[t].append(local_idx)\n",
    "    for k in list(pools.keys()):\n",
    "        pools[k] = torch.tensor(pools[k], dtype=torch.long, device=n_id_device.device)\n",
    "    return pools\n",
    "\n",
    "def sample_neg_local(pos_local_eidx, rel_ids_local, n_id, pools, k_neg=1):\n",
    "    \"\"\"\n",
    "    Typed negatives *within* the sampled subgraph.\n",
    "    pos_local_eidx: (2,P) local indices\n",
    "    rel_ids_local:  (P,)   relation ids (global rel ids)\n",
    "    pools: dict[type_id] -> local node index tensor present in batch\n",
    "    \"\"\"\n",
    "    if pos_local_eidx.numel() == 0:  # empty\n",
    "        return torch.empty((2,0), dtype=torch.long, device=pos_local_eidx.device)\n",
    "\n",
    "    P = pos_local_eidx.size(1)\n",
    "    neg_src, neg_dst = [], []\n",
    "    for i in range(P):\n",
    "        s_l = int(pos_local_eidx[0, i])\n",
    "        d_l = int(pos_local_eidx[1, i])\n",
    "        r_id = int(rel_ids_local[i])\n",
    "        s_type, _, d_type = relid_to_etype(r_id)\n",
    "        s_tid = type2id[s_type]; d_tid = type2id[d_type]\n",
    "\n",
    "        # pick from local pools â€” if missing (rare), fall back to uniform local sampling\n",
    "        s_pool = pools.get(s_tid, None)\n",
    "        d_pool = pools.get(d_tid, None)\n",
    "        if s_pool is None or s_pool.numel() == 0:\n",
    "            s_pool = torch.arange(n_id.size(0), device=n_id.device)\n",
    "        if d_pool is None or d_pool.numel() == 0:\n",
    "            d_pool = torch.arange(n_id.size(0), device=n_id.device)\n",
    "\n",
    "        for _ in range(max(1, k_neg)):\n",
    "            if random.random() < 0.5:\n",
    "                # corrupt head\n",
    "                new_s_l = s_pool[torch.randint(0, s_pool.numel(), (1,))].item()\n",
    "                neg_src.append(new_s_l); neg_dst.append(d_l)\n",
    "            else:\n",
    "                # corrupt tail\n",
    "                new_d_l = d_pool[torch.randint(0, d_pool.numel(), (1,))].item()\n",
    "                neg_src.append(s_l); neg_dst.append(new_d_l)\n",
    "\n",
    "    if len(neg_src) == 0:\n",
    "        return torch.empty((2,0), dtype=torch.long, device=n_id.device)\n",
    "    return torch.stack([torch.tensor(neg_src, device=n_id.device),\n",
    "                        torch.tensor(neg_dst, device=n_id.device)], dim=0)\n",
    "\n",
    "# ----------------------------\n",
    "# 6) Train with NeighborLoader + AMP\n",
    "# ----------------------------\n",
    "EPOCHS = 30\n",
    "LR     = 1e-3\n",
    "K_NEG  = 1\n",
    "\n",
    "model = RGCN(num_nodes, num_relations, emb_dim=64, hidden_dim=128, out_dim=32, num_bases=30).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=1e-5)\n",
    "scaler = GradScaler(enabled=(device.type == \"cuda\"))\n",
    "\n",
    "# Global training edges (for picking positives per batch)\n",
    "src_glob_all = edge_index_cpu[0].to(device)\n",
    "dst_glob_all = edge_index_cpu[1].to(device)\n",
    "rels_all     = edge_type_cpu.to(device)\n",
    "\n",
    "print(\"\\nðŸ” Training with NeighborLoader mini-batches + AMP ...\")\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    seen_pos = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        batch = batch.to(device, non_blocking=True)\n",
    "        n_id = batch.n_id  # global ids in this subgraph (device tensor)\n",
    "\n",
    "        # global->local mapping\n",
    "        global2local = -torch.ones(num_nodes, dtype=torch.long, device=device)\n",
    "        global2local[n_id] = torch.arange(n_id.size(0), device=device)\n",
    "\n",
    "        # positives inside batch\n",
    "        in_src = global2local[src_glob_all]\n",
    "        in_dst = global2local[dst_glob_all]\n",
    "        mask = (in_src >= 0) & (in_dst >= 0)\n",
    "        pos_idx = torch.nonzero(mask, as_tuple=False).view(-1)\n",
    "        if pos_idx.numel() == 0:\n",
    "            del batch, n_id, global2local, in_src, in_dst, mask, pos_idx\n",
    "            if device.type == \"cuda\": torch.cuda.empty_cache()\n",
    "            continue\n",
    "\n",
    "        MAX_POS_PER_BATCH = 8192\n",
    "        if pos_idx.numel() > MAX_POS_PER_BATCH:\n",
    "            pos_idx = pos_idx[torch.randperm(pos_idx.numel(), device=device)[:MAX_POS_PER_BATCH]]\n",
    "\n",
    "        pos_local = torch.stack([in_src[pos_idx], in_dst[pos_idx]], dim=0)\n",
    "        rel_ids_local = rels_all[pos_idx]\n",
    "\n",
    "        # local typed pools for negatives\n",
    "        pools = build_local_type_pools(n_id)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        with autocast(enabled=(device.type == \"cuda\")):\n",
    "            z = model(n_id, batch.edge_index, batch.edge_type)\n",
    "\n",
    "            # DistMult positives\n",
    "            pos_h = z[pos_local[0]]; pos_t = z[pos_local[1]]\n",
    "            pos_r = model.rel_emb(rel_ids_local)\n",
    "            pos_logits = model.score(pos_h, pos_r, pos_t)\n",
    "\n",
    "            # local typed negatives\n",
    "            neg_local = sample_neg_local(pos_local, rel_ids_local, n_id, pools, k_neg=K_NEG)\n",
    "            if neg_local.size(1) > 0:\n",
    "                neg_h = z[neg_local[0]]; neg_t = z[neg_local[1]]\n",
    "                # repeat relation ids for negs\n",
    "                neg_r = model.rel_emb(rel_ids_local.repeat_interleave(K_NEG))\n",
    "                neg_logits = model.score(neg_h, neg_r, neg_t)\n",
    "                loss = (F.binary_cross_entropy_with_logits(pos_logits, torch.ones_like(pos_logits)) +\n",
    "                        F.binary_cross_entropy_with_logits(neg_logits, torch.zeros_like(neg_logits)))\n",
    "            else:\n",
    "                loss = F.binary_cross_entropy_with_logits(pos_logits, torch.ones_like(pos_logits))\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        epoch_loss += float(loss.detach().cpu())\n",
    "        seen_pos += pos_local.size(1)\n",
    "\n",
    "        # cleanup\n",
    "        del batch, n_id, global2local, in_src, in_dst, mask, pos_idx\n",
    "        del pos_local, rel_ids_local, pools, z, pos_h, pos_t, pos_r, pos_logits\n",
    "        if 'neg_local' in locals(): del neg_local, neg_h, neg_t, neg_r, neg_logits\n",
    "        if device.type == \"cuda\": torch.cuda.empty_cache()\n",
    "\n",
    "    print(f\"Epoch {epoch:02d} | Loss: {epoch_loss:.4f} | Seen pos edges: {seen_pos}\")\n",
    "\n",
    "# ----------------------------\n",
    "# 7) Batched inference (DistMult-ready embeddings)\n",
    "# ----------------------------\n",
    "print(\"\\nðŸ”Ž Computing full-node embeddings (batched inference) ...\")\n",
    "model.eval()\n",
    "OUT_DIM = 32\n",
    "z_all = torch.empty((num_nodes, OUT_DIM), dtype=torch.float32, device=device)\n",
    "\n",
    "INFER_BATCH = 16384\n",
    "infer_loader = NeighborLoader(\n",
    "    Data(num_nodes=num_nodes, edge_index=edge_index_cpu, edge_type=edge_type_cpu),\n",
    "    num_neighbors=[-1, -1],\n",
    "    batch_size=INFER_BATCH,\n",
    "    input_nodes=torch.arange(num_nodes),\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS\n",
    ")\n",
    "with torch.no_grad():\n",
    "    for batch in infer_loader:\n",
    "        batch = batch.to(device, non_blocking=True)\n",
    "        n_id = batch.n_id\n",
    "        z_batch = model(n_id, batch.edge_index, batch.edge_type)\n",
    "        z_all[n_id] = z_batch\n",
    "        del batch, z_batch, n_id\n",
    "        if device.type == \"cuda\": torch.cuda.empty_cache()\n",
    "\n",
    "# ----------------------------\n",
    "# 8) Evaluation (per relation + overall) â€” DistMult + zero_division=0\n",
    "# ----------------------------\n",
    "print(\"\\nðŸ“Š Final evaluation per edge type (filtered negatives, DistMult):\")\n",
    "\n",
    "def eval_relation(z_all, etype, splits, k_neg=1):\n",
    "    rel_id = rel2id[etype]\n",
    "    pos_e = splits[\"test\"]\n",
    "    if pos_e.numel() == 0: return None\n",
    "    N = pos_e.size(1)\n",
    "    # Build negatives globally (filtered, typed) just for evaluation\n",
    "    # (global is fine here; we evaluate on z_all)\n",
    "    # Reuse earlier sampler but with relation ids vector:\n",
    "    src_g = pos_e[0].to(device); dst_g = pos_e[1].to(device)\n",
    "    rel_ids = torch.full((N,), rel_id, dtype=torch.long, device=device)\n",
    "\n",
    "    # filtered typed negs in GLOBAL space (may include true edges but low prob)\n",
    "    # Simple version: corrupt tails only\n",
    "    neg_src = src_g.repeat_interleave(k_neg)\n",
    "    # build tail pool by type\n",
    "    s_type,_, d_type = etype\n",
    "    d_tid = type2id[d_type]\n",
    "    d_pool_global = torch.arange(type_offsets[d_type], type_offsets[d_type] + len(node_type_map[d_type]), device=device)\n",
    "    neg_dst = d_pool_global[torch.randint(0, d_pool_global.numel(), (N*k_neg,), device=device)]\n",
    "\n",
    "    # Scores\n",
    "    pos_scores = distmult_sigmoid_scores(z_all, model.rel_emb, pos_e.to(device), rel_ids)\n",
    "    neg_scores = distmult_sigmoid_scores(z_all, model.rel_emb, torch.stack([neg_src, neg_dst]), rel_ids.repeat_interleave(k_neg))\n",
    "\n",
    "    y_true = torch.cat([torch.ones_like(pos_scores), torch.zeros_like(neg_scores)])\n",
    "    y_scores = torch.cat([pos_scores, neg_scores]).detach().cpu().numpy()\n",
    "    y = y_true.detach().cpu().numpy()\n",
    "    auc = roc_auc_score(y, y_scores)\n",
    "\n",
    "    preds = (y_scores > 0.5).astype(int)\n",
    "    p = precision_score(y, preds, zero_division=0)\n",
    "    r = recall_score(y, preds, zero_division=0)\n",
    "    f1 = f1_score(y, preds, zero_division=0)\n",
    "    return auc, p, r, f1\n",
    "\n",
    "results = []\n",
    "all_pos_eidx_list, all_rel_ids_list = [], []\n",
    "\n",
    "for etype, splits in edge_type_splits.items():\n",
    "    out = eval_relation(z_all, etype, splits, k_neg=1)\n",
    "    if out is None: continue\n",
    "    auc, p, r, f1 = out\n",
    "    results.append((etype, auc, p, r, f1))\n",
    "    rel_id = rel2id[etype]\n",
    "    te = splits[\"test\"]\n",
    "    all_pos_eidx_list.append(te)\n",
    "    all_rel_ids_list.append(torch.full((te.size(1),), rel_id, dtype=torch.long))\n",
    "    print(f\"{etype}: AUC={auc:.4f}, P={p:.3f}, R={r:.3f}, F1={f1:.3f}\")\n",
    "\n",
    "# Overall\n",
    "if all_pos_eidx_list:\n",
    "    all_pos_eidx = torch.cat(all_pos_eidx_list, dim=1).to(device)\n",
    "    all_rel_ids = torch.cat(all_rel_ids_list, dim=0).to(device)\n",
    "    # Simple overall negatives: corrupt tails with matching type (1 per pos)\n",
    "    etypes_for_all = [relid_to_etype(int(r)) for r in all_rel_ids.tolist()]\n",
    "    neg_src = all_pos_eidx[0]\n",
    "    neg_dst_list = []\n",
    "    for r_id, et in zip(all_rel_ids.tolist(), etypes_for_all):\n",
    "        d_type = et[2]\n",
    "        pool = torch.arange(type_offsets[d_type], type_offsets[d_type] + len(node_type_map[d_type]), device=device)\n",
    "        neg_dst_list.append(pool[torch.randint(0, pool.numel(), (1,), device=device)])\n",
    "    neg_dst = torch.stack(neg_dst_list).view(-1)\n",
    "    neg_e = torch.stack([neg_src, neg_dst], dim=0)\n",
    "\n",
    "    pos_scores = distmult_sigmoid_scores(z_all, model.rel_emb, all_pos_eidx, all_rel_ids)\n",
    "    neg_scores = distmult_sigmoid_scores(z_all, model.rel_emb, neg_e, all_rel_ids)\n",
    "\n",
    "    y_scores = torch.cat([pos_scores, neg_scores]).detach().cpu().numpy()\n",
    "    y = np.concatenate([np.ones(pos_scores.numel()), np.zeros(neg_scores.numel())])\n",
    "\n",
    "    overall_auc = roc_auc_score(y, y_scores)\n",
    "    preds = (y_scores > 0.5).astype(int)\n",
    "    overall_p = precision_score(y, preds, zero_division=0)\n",
    "    overall_r = recall_score(y, preds, zero_division=0)\n",
    "    overall_f1 = f1_score(y, preds, zero_division=0)\n",
    "\n",
    "    print(\"\\nðŸŒ Overall Performance (filtered-ish, typed tails, DistMult):\")\n",
    "    print(f\"Overall AUC = {overall_auc:.4f}\")\n",
    "    print(f\"Overall Precision = {overall_p:.3f}\")\n",
    "    print(f\"Overall Recall = {overall_r:.3f}\")\n",
    "    print(f\"Overall F1 Score = {overall_f1:.3f}\")\n",
    "else:\n",
    "    print(\"\\nNo test edges available for evaluation.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a241910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.4.0+cu124\n",
      "CUDA available: True\n",
      "CUDA version: 12.4\n",
      "GPU: Tesla T4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

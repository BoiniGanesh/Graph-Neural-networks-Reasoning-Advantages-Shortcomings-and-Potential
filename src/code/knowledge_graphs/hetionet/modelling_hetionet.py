# -*- coding: utf-8 -*-
"""multi_edge_rgcn_gat_test.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rJ6OQxrxxfP3HutqCAWTBpNbdHqoitn8

## R_GCN on all the edges individually
"""

# %% [Cell 0: Install Required Packages]
!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
!pip install torch-scatter torch-sparse torch-geometric -f https://data.pyg.org/whl/torch-2.3.0+cu121.html
!pip install networkx scikit-learn

# %% [Cell 1: Setup & Imports]
import os
os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "expandable_segments:True"

import torch
import torch.nn.functional as F
from torch import nn
from torch_geometric.nn import RGCNConv
from sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score
from collections import defaultdict
import networkx as nx
import numpy as np
import random

# Reproducibility
seed = 42
random.seed(seed)
np.random.seed(seed)
torch.manual_seed(seed)
torch.cuda.manual_seed_all(seed)

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print("Using device:", device)

# %% [Cell 2: Mount Drive & Load GraphML]
from google.colab import drive
drive.mount('/content/drive')

graph_path = "/content/drive/MyDrive/hetionet-main/hetionet-main/hetnet/tsv/hetionet.graphml"
print("Loading graph ...")
G = nx.read_graphml(graph_path)
print(f"Loaded graph with {len(G.nodes)} nodes and {len(G.edges)} edges.")

# %% [Cell 3: Build Node and Edge Mappings]
node_type_map = defaultdict(list)
node_id_map = {}
node_idx_by_type = defaultdict(dict)
for nid, data in G.nodes(data=True):
    if 'kind' not in data:
        continue
    ntype = data['kind']
    idx = len(node_type_map[ntype])
    node_type_map[ntype].append(nid)
    node_id_map[nid] = (ntype, idx)
    node_idx_by_type[ntype][nid] = idx

edge_type_map = defaultdict(list)
for src, dst, attr in G.edges(data=True):
    rel = attr.get('metaedge', attr.get('relation', None))
    if not rel or src not in node_id_map or dst not in node_id_map:
        continue
    src_t, src_i = node_id_map[src]
    dst_t, dst_i = node_id_map[dst]
    edge_type_map[(src_t, rel, dst_t)].append((src_i, dst_i))

print(f"âœ… Node types: {list(node_type_map.keys())}")
print(f"âœ… Total edge types: {len(edge_type_map)}")

# %% [Cell 4: Homogeneous Graph]
type_offsets = {}
global_id_map = {}
offset = 0
for ntype, nodes in node_type_map.items():
    type_offsets[ntype] = offset
    for local_idx in range(len(nodes)):
        global_id_map[(ntype, local_idx)] = offset + local_idx
    offset += len(nodes)

num_nodes = offset
edge_type_keys = list(edge_type_map.keys())
rel2id = {etype: i for i, etype in enumerate(edge_type_keys)}
num_relations = len(edge_type_keys)

all_src, all_dst, all_rel = [], [], []
for etype, edges in edge_type_map.items():
    rel_id = rel2id[etype]
    src_type, _, dst_type = etype
    for (s_local, d_local) in edges:
        all_src.append(type_offsets[src_type] + s_local)
        all_dst.append(type_offsets[dst_type] + d_local)
        all_rel.append(rel_id)

edge_index = torch.tensor([all_src, all_dst], dtype=torch.long)
edge_type = torch.tensor(all_rel, dtype=torch.long)

print(f"Homogeneous nodes: {num_nodes}, edges: {edge_index.size(1)}")

# %% [Cell 5: R-GCN Model Definition]
class RGCN(torch.nn.Module):
    def __init__(self, num_nodes, num_relations, emb_dim=64, hidden_dim=64, out_dim=32):
        super().__init__()
        self.emb = torch.nn.Embedding(num_nodes, emb_dim)
        self.conv1 = RGCNConv(emb_dim, hidden_dim, num_relations=num_relations)
        self.conv2 = RGCNConv(hidden_dim, out_dim, num_relations=num_relations)

    def forward(self, node_ids, edge_index, edge_type):
        x = self.emb(node_ids)
        x = self.conv1(x, edge_index, edge_type)
        x = F.relu(x)
        x = self.conv2(x, edge_index, edge_type)
        return x

# %% [Cell 6: Helper Functions]
def edge_scores(z, eidx):
    return (z[eidx[0]] * z[eidx[1]]).sum(dim=-1).sigmoid()

def sample_neg_edges(num_samples, num_nodes, device):
    return torch.randint(0, num_nodes, (2, num_samples), device=device)

@torch.no_grad()
def evaluate(z, pos_eidx, num_nodes, k_neg=1):
    num_pos = pos_eidx.size(1)
    neg_eidx = sample_neg_edges(num_pos * k_neg, num_nodes, z.device)

    y_true = torch.cat([
        torch.ones(num_pos, device=z.device),
        torch.zeros(num_pos * k_neg, device=z.device)
    ])
    scores = torch.cat([edge_scores(z, pos_eidx),
                        edge_scores(z, neg_eidx)], dim=0)

    y_true_cpu = y_true.detach().cpu().numpy()
    scores_cpu = scores.detach().cpu().numpy()
    auc = roc_auc_score(y_true_cpu, scores_cpu)
    preds = (scores_cpu > 0.5).astype(int)
    precision = precision_score(y_true_cpu, preds)
    recall = recall_score(y_true_cpu, preds)
    f1 = f1_score(y_true_cpu, preds)
    return auc, precision, recall, f1

print(f"\nâœ… Total edge types: {len(edge_type_map)}")
for etype, edges in edge_type_map.items():
    print(f"  - {etype}: {len(edges)} edges")

# %% [Cell 7: Train on All Edge Types]
EPOCHS = 20
node_ids = torch.arange(num_nodes, device=device)
results = []

for target_edge_type in edge_type_keys:
    print(f"\nğŸ” Training on edge type: {target_edge_type}")
    target_rel_id = rel2id[target_edge_type]
    mask = (edge_type == target_rel_id)
    target_edge_index = edge_index[:, mask]

    if target_edge_index.size(1) < 100:
        print("âš ï¸ Too few edges, skipping...")
        continue

    # Split
    num_edges = target_edge_index.size(1)
    perm = torch.randperm(num_edges)
    train_idx = perm[:int(0.8 * num_edges)]
    val_idx = perm[int(0.8 * num_edges):int(0.9 * num_edges)]
    test_idx = perm[int(0.9 * num_edges):]

    train_edge_index = target_edge_index[:, train_idx].to(device)
    val_edge_index = target_edge_index[:, val_idx].to(device)
    test_edge_index = target_edge_index[:, test_idx].to(device)

    # Reset model
    model = RGCN(num_nodes, num_relations).to(device)
    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)

    # Training loop
    for epoch in range(1, EPOCHS + 1):
        model.train()
        optimizer.zero_grad()
        z = model(node_ids, edge_index.to(device), edge_type.to(device))

        pos_scores = edge_scores(z, train_edge_index)
        pos_loss = -torch.log(pos_scores + 1e-15).mean()

        neg_eidx = sample_neg_edges(train_edge_index.size(1), num_nodes, device)
        neg_scores = edge_scores(z, neg_eidx)
        neg_loss = -torch.log(1.0 - neg_scores + 1e-15).mean()

        loss = pos_loss + neg_loss
        loss.backward()
        optimizer.step()

    # Evaluation
    model.eval()
    with torch.no_grad():
        z = model(node_ids, edge_index.to(device), edge_type.to(device))
        test_auc, test_p, test_r, test_f1 = evaluate(z, test_edge_index, num_nodes, k_neg=1)

    results.append({
        "edge_type": target_edge_type,
        "auc": test_auc,
        "precision": test_p,
        "recall": test_r,
        "f1": test_f1
    })

# %% [Cell 8: Summary]
print("\nğŸ“Š Results Summary (Test Set):")
for r in results:
    print(f"{r['edge_type']}: AUC={r['auc']:.4f}, P={r['precision']:.3f}, R={r['recall']:.3f}, F1={r['f1']:.3f}")



"""## GAT on all edges individually"""

import torch
import torch.nn.functional as F
from torch_geometric.nn import GATConv
from sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score
from collections import defaultdict
import networkx as nx
import numpy as np
import random

# %% [Cell 5: GAT Model]
class GAT(torch.nn.Module):
    def __init__(self, num_nodes, emb_dim=64, hidden_dim=64, out_dim=32, heads=4):
        super().__init__()
        self.emb = torch.nn.Embedding(num_nodes, emb_dim)
        self.conv1 = GATConv(emb_dim, hidden_dim, heads=heads, dropout=0.6)
        self.conv2 = GATConv(hidden_dim * heads, out_dim, heads=1, dropout=0.6)

    def forward(self, x, edge_index):
        x = self.emb(x)
        x = self.conv1(x, edge_index)
        x = F.elu(x)
        x = self.conv2(x, edge_index)
        return x

# %% [Cell 6: Helper Functions]
def edge_scores(z, eidx):
    return (z[eidx[0]] * z[eidx[1]]).sum(dim=-1).sigmoid()

def sample_neg_edges(num_samples, num_nodes, device):
    return torch.randint(0, num_nodes, (2, num_samples), device=device)

@torch.no_grad()
def evaluate(z, pos_eidx, num_nodes, k_neg=1):
    num_pos = pos_eidx.size(1)
    neg_eidx = sample_neg_edges(num_pos * k_neg, num_nodes, z.device)

    y_true = torch.cat([
        torch.ones(num_pos, device=z.device),
        torch.zeros(num_pos * k_neg, device=z.device)
    ])
    scores = torch.cat([edge_scores(z, pos_eidx),
                        edge_scores(z, neg_eidx)], dim=0)

    y_true_cpu = y_true.detach().cpu().numpy()
    scores_cpu = scores.detach().cpu().numpy()
    auc = roc_auc_score(y_true_cpu, scores_cpu)
    preds = (scores_cpu > 0.5).astype(int)
    precision = precision_score(y_true_cpu, preds)
    recall = recall_score(y_true_cpu, preds)
    f1 = f1_score(y_true_cpu, preds)
    return auc, precision, recall, f1

print(f"\nâœ… Total edge types: {len(edge_type_map)}")
for etype, edges in edge_type_map.items():
    print(f"  - {etype}: {len(edges)} edges")

# %% [Cell 7: Train GAT on All 19 Edge Types]
EPOCHS = 20
node_ids = torch.arange(num_nodes, device=device)
results = []

for target_edge_type in edge_type_keys:
    print(f"\nğŸ” Training on edge type: {target_edge_type}")
    edge_list = edge_type_map[target_edge_type]
    if len(edge_list) < 100:
        print("âš ï¸ Too few edges, skipping...")
        continue

    # Map to global IDs
    src_t, _, dst_t = target_edge_type
    pos_edges = torch.tensor([
        [type_offsets[src_t] + s for s, d in edge_list],
        [type_offsets[dst_t] + d for s, d in edge_list]
    ], dtype=torch.long)

    num_edges = pos_edges.size(1)
    perm = torch.randperm(num_edges)
    train_idx = perm[:int(0.8 * num_edges)]
    val_idx = perm[int(0.8 * num_edges):int(0.9 * num_edges)]
    test_idx = perm[int(0.9 * num_edges):]

    train_edge_index = pos_edges[:, train_idx].to(device)
    val_edge_index = pos_edges[:, val_idx].to(device)
    test_edge_index = pos_edges[:, test_idx].to(device)

    model = GAT(num_nodes).to(device)
    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)

    for epoch in range(EPOCHS):
        model.train()
        optimizer.zero_grad()
        z = model(node_ids, edge_index.to(device))

        pos_scores = edge_scores(z, train_edge_index)
        pos_loss = -torch.log(pos_scores + 1e-15).mean()

        neg_eidx = sample_neg_edges(train_edge_index.size(1), num_nodes, device)
        neg_scores = edge_scores(z, neg_eidx)
        neg_loss = -torch.log(1.0 - neg_scores + 1e-15).mean()

        loss = pos_loss + neg_loss
        loss.backward()
        optimizer.step()

    # Final evaluation
    model.eval()
    with torch.no_grad():
        z = model(node_ids, edge_index.to(device))
        test_auc, test_p, test_r, test_f1 = evaluate(z, test_edge_index, num_nodes)

    results.append({
        "edge_type": target_edge_type,
        "auc": test_auc,
        "precision": test_p,
        "recall": test_r,
        "f1": test_f1
    })

# %% [Cell 8: Summary]
print("\nğŸ“Š GAT Results Summary:")
for r in results:
    print(f"{r['edge_type']}: AUC={r['auc']:.4f}, P={r['precision']:.3f}, R={r['recall']:.3f}, F1={r['f1']:.3f}")



"""## multi edge training and prediction on R_GCN"""

# %% [Cell 7: Multi-type Evaluation Setup]

# Split edges for each relation separately (just for evaluation)
edge_type_splits = {}

for target_edge_type in edge_type_keys:
    rel_id = rel2id[target_edge_type]
    mask = (edge_type == rel_id)
    edges = edge_index[:, mask]

    if edges.size(1) < 100:
        print(f"âš ï¸ Skipping edge type {target_edge_type} (too few edges)")
        continue

    perm = torch.randperm(edges.size(1))
    train_idx = perm[:int(0.8 * edges.size(1))]
    val_idx   = perm[int(0.8 * edges.size(1)):int(0.9 * edges.size(1))]
    test_idx  = perm[int(0.9 * edges.size(1)):]

    edge_type_splits[target_edge_type] = {
        "train": edges[:, train_idx].to(device),
        "val":   edges[:, val_idx].to(device),
        "test":  edges[:, test_idx].to(device)
    }

# %% [Cell 8: Train ONCE on all edges, all types]

print("\nğŸ” Training unified R-GCN model on all edge types together...")
EPOCHS = 30
node_ids = torch.arange(num_nodes, device=device)
model = RGCN(num_nodes, num_relations).to(device)
optimizer = torch.optim.Adam(model.parameters(), lr=0.01)

for epoch in range(1, EPOCHS + 1):
    model.train()
    optimizer.zero_grad()

    z = model(node_ids, edge_index.to(device), edge_type.to(device))

    # Combine training edges from all edge types
    train_edges = []
    for splits in edge_type_splits.values():
        train_edges.append(splits["train"])
    train_edges = torch.cat(train_edges, dim=1)

    pos_scores = edge_scores(z, train_edges)
    pos_loss = -torch.log(pos_scores + 1e-15).mean()

    neg_edges = sample_neg_edges(train_edges.size(1), num_nodes, device)
    neg_scores = edge_scores(z, neg_edges)
    neg_loss = -torch.log(1.0 - neg_scores + 1e-15).mean()

    loss = pos_loss + neg_loss
    loss.backward()
    optimizer.step()

    if epoch % 5 == 0 or epoch == 1:
        print(f"Epoch {epoch:02d} | Loss: {loss.item():.4f}")

# %% [Cell 9: Evaluate on each edge type]

print("\nğŸ“Š Final evaluation per edge type:")
model.eval()
results = []

with torch.no_grad():
    z = model(node_ids, edge_index.to(device), edge_type.to(device))

    for edge_type_key, splits in edge_type_splits.items():
        test_edges = splits["test"]
        auc, p, r, f1 = evaluate(z, test_edges, num_nodes)
        results.append({
            "edge_type": edge_type_key,
            "auc": auc,
            "precision": p,
            "recall": r,
            "f1": f1
        })
        print(f"{edge_type_key}: AUC={auc:.4f}, P={p:.3f}, R={r:.3f}, F1={f1:.3f}")

# %% [Cell 10: Evaluate Overall Performance Across All Edge Types]
print("\nğŸ§® Evaluating overall performance across all edge types combined...")

all_test_edges = []
for splits in edge_type_splits.values():
    all_test_edges.append(splits["test"])

all_test_edges = torch.cat(all_test_edges, dim=1)
auc, p, r, f1 = evaluate(z, all_test_edges, num_nodes)

print(f"\nğŸŒ Overall Results:")
print(f"AUC = {auc:.4f}")
print(f"Precision = {p:.3f}")
print(f"Recall = {r:.3f}")
print(f"F1 Score = {f1:.3f}")



"""## multi edge training and prediction on GAT"""

# %% [Cell 7: GAT Evaluation Splits]
edge_type_splits = {}

for target_edge_type in edge_type_keys:
    edge_list = edge_type_map[target_edge_type]
    if len(edge_list) < 100:
        print(f"âš ï¸ Skipping edge type {target_edge_type} (too few edges)")
        continue

    src_t, _, dst_t = target_edge_type
    pos_edges = torch.tensor([
        [type_offsets[src_t] + s for s, d in edge_list],
        [type_offsets[dst_t] + d for s, d in edge_list]
    ], dtype=torch.long)

    perm = torch.randperm(pos_edges.size(1))
    train_idx = perm[:int(0.8 * pos_edges.size(1))]
    val_idx   = perm[int(0.8 * pos_edges.size(1)):int(0.9 * pos_edges.size(1))]
    test_idx  = perm[int(0.9 * pos_edges.size(1)):]

    edge_type_splits[target_edge_type] = {
        "train": pos_edges[:, train_idx].to(device),
        "val":   pos_edges[:, val_idx].to(device),
        "test":  pos_edges[:, test_idx].to(device)
    }

# %% [Cell 8: Train GAT on all edges at once]
print("\nğŸ” Training single GAT model on all edge types (homogeneous)...")

EPOCHS = 30
node_ids = torch.arange(num_nodes, device=device)
model = GAT(num_nodes).to(device)
optimizer = torch.optim.Adam(model.parameters(), lr=0.01)

for epoch in range(1, EPOCHS + 1):
    model.train()
    optimizer.zero_grad()

    z = model(node_ids, edge_index.to(device))  # uses full homogeneous graph

    # Combine all positive training edges
    train_edges = torch.cat([splits["train"] for splits in edge_type_splits.values()], dim=1)

    pos_scores = edge_scores(z, train_edges)
    pos_loss = -torch.log(pos_scores + 1e-15).mean()

    neg_edges = sample_neg_edges(train_edges.size(1), num_nodes, device)
    neg_scores = edge_scores(z, neg_edges)
    neg_loss = -torch.log(1.0 - neg_scores + 1e-15).mean()


    loss = pos_loss + neg_loss
    loss.backward()
    optimizer.step()

    if epoch % 5 == 0 or epoch == 1:
        print(f"Epoch {epoch:02d} | Loss: {loss.item():.4f}")

# %% [Cell 9: Per-edge-type GAT Evaluation]
print("\nğŸ“Š GAT Evaluation per edge type:")
model.eval()
results = []

with torch.no_grad():
    z = model(node_ids, edge_index.to(device))

    for edge_type_key, splits in edge_type_splits.items():
        test_edges = splits["test"]
        auc, p, r, f1 = evaluate(z, test_edges, num_nodes)
        results.append({
            "edge_type": edge_type_key,
            "auc": auc,
            "precision": p,
            "recall": r,
            "f1": f1
        })
        print(f"{edge_type_key}: AUC={auc:.4f}, P={p:.3f}, R={r:.3f}, F1={f1:.3f}")

# %% [Cell 10: Overall GAT Evaluation]
print("\nğŸŒ GAT Overall Performance (all edge types combined)...")

all_test_edges = torch.cat([splits["test"] for splits in edge_type_splits.values()], dim=1)
auc, p, r, f1 = evaluate(z, all_test_edges, num_nodes)

print(f"Overall AUC = {auc:.4f}")
print(f"Overall Precision = {p:.3f}")
print(f"Overall Recall = {r:.3f}")
print(f"Overall F1 Score = {f1:.3f}")

"""## GAT altogether"""

# %% [Cell 7: GAT Evaluation Splits]
edge_type_splits = {}

for target_edge_type in edge_type_keys:
    edge_list = edge_type_map[target_edge_type]
    if len(edge_list) < 100:
        print(f"âš ï¸ Skipping edge type {target_edge_type} (too few edges)")
        continue

    src_t, _, dst_t = target_edge_type
    pos_edges = torch.tensor([
        [type_offsets[src_t] + s for s, d in edge_list],
        [type_offsets[dst_t] + d for s, d in edge_list]
    ], dtype=torch.long)

    perm = torch.randperm(pos_edges.size(1))
    train_idx = perm[:int(0.8 * pos_edges.size(1))]
    val_idx   = perm[int(0.8 * pos_edges.size(1)):int(0.9 * pos_edges.size(1))]
    test_idx  = perm[int(0.9 * pos_edges.size(1)):]

    edge_type_splits[target_edge_type] = {
        "train": pos_edges[:, train_idx].to(device),
        "val":   pos_edges[:, val_idx].to(device),
        "test":  pos_edges[:, test_idx].to(device)
    }

# %% [Cell 8: Train GAT on all edges at once]
print("\nğŸ” Training single GAT model on all edge types (homogeneous)...")

EPOCHS = 30
node_ids = torch.arange(num_nodes, device=device)
model = GAT(num_nodes).to(device)
optimizer = torch.optim.Adam(model.parameters(), lr=0.01)

for epoch in range(1, EPOCHS + 1):
    model.train()
    optimizer.zero_grad()

    z = model(node_ids, edge_index.to(device))  # uses full homogeneous graph

    train_edges = torch.cat([splits["train"] for splits in edge_type_splits.values()], dim=1)

    pos_scores = edge_scores(z, train_edges)
    pos_loss = -torch.log(pos_scores + 1e-15).mean()

    neg_edges = sample_neg_edges(train_edges.size(1), num_nodes, device)
    neg_scores = edge_scores(z, neg_edges)
    neg_loss = -torch.log(1.0 - neg_scores + 1e-15).mean()

    if epoch == 1:
        print(f"[Train] Positive edges: {train_edges.size(1)}")
        print(f"[Train] Negative edges: {neg_edges.size(1)}")

    loss = pos_loss + neg_loss
    loss.backward()
    optimizer.step()

    if epoch % 5 == 0 or epoch == 1:
        print(f"Epoch {epoch:02d} | Loss: {loss.item():.4f}")

# %% [Cell 9: Per-edge-type GAT Evaluation]
print("\nğŸ“Š GAT Evaluation per edge type:")
model.eval()
results = []

with torch.no_grad():
    z = model(node_ids, edge_index.to(device))

    for edge_type_key, splits in edge_type_splits.items():
        test_edge_index = splits["test"]
        neg_eidx = sample_neg_edges(test_edge_index.size(1), num_nodes, device)

        print(f"\n[Eval] Positive test edges for {edge_type_key}: {test_edge_index.size(1)}")
        print(f"[Eval] Negative test edges sampled: {neg_eidx.size(1)}")

        auc, p, r, f1 = evaluate(z, test_edge_index, num_nodes)
        results.append({
            "edge_type": edge_type_key,
            "auc": auc,
            "precision": p,
            "recall": r,
            "f1": f1
        })
        print(f"{edge_type_key}: AUC={auc:.4f}, P={p:.3f}, R={r:.3f}, F1={f1:.3f}")

# %% [Cell 10: Overall GAT Evaluation]
print("\nğŸŒ GAT Overall Performance (all edge types combined)...")

all_test_edges = torch.cat([splits["test"] for splits in edge_type_splits.values()], dim=1)
neg_all = sample_neg_edges(all_test_edges.size(1), num_nodes, device)

print(f"[Overall] Total test edges: {all_test_edges.size(1)}")
print(f"[Overall] Sampled negative edges: {neg_all.size(1)}")

auc, p, r, f1 = evaluate(z, all_test_edges, num_nodes)
print(f"Overall AUC = {auc:.4f}")
print(f"Overall Precision = {p:.3f}")
print(f"Overall Recall = {r:.3f}")
print(f"Overall F1 Score = {f1:.3f}")


{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# First, completely remove everything\n",
        "!pip uninstall torch torchvision torchaudio torch-scatter torch-sparse torch-geometric -y\n",
        "\n",
        "# Install a compatible PyTorch version that has pre-compiled wheels\n",
        "!pip install torch==2.4.0+cu124 torchvision==0.19.0+cu124 torchaudio==2.4.0+cu124 --index-url https://download.pytorch.org/whl/cu124\n",
        "\n",
        "# Install PyG libraries for this specific version\n",
        "!pip install torch-scatter torch-sparse torch-geometric -f https://data.pyg.org/whl/torch-2.4.0+cu124.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RodVVYmGxpq9",
        "outputId": "4049490c-1bf2-4615-af7e-16a641da16dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torch 2.8.0+cu126\n",
            "Uninstalling torch-2.8.0+cu126:\n",
            "  Successfully uninstalled torch-2.8.0+cu126\n",
            "Found existing installation: torchvision 0.23.0+cu126\n",
            "Uninstalling torchvision-0.23.0+cu126:\n",
            "  Successfully uninstalled torchvision-0.23.0+cu126\n",
            "Found existing installation: torchaudio 2.8.0+cu126\n",
            "Uninstalling torchaudio-2.8.0+cu126:\n",
            "  Successfully uninstalled torchaudio-2.8.0+cu126\n",
            "\u001b[33mWARNING: Skipping torch-scatter as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torch-sparse as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torch-geometric as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://download.pytorch.org/whl/cu124\n",
            "Collecting torch==2.4.0+cu124\n",
            "  Downloading https://download.pytorch.org/whl/cu124/torch-2.4.0%2Bcu124-cp312-cp312-linux_x86_64.whl (797.2 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m797.2/797.2 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.19.0+cu124\n",
            "  Downloading https://download.pytorch.org/whl/cu124/torchvision-0.19.0%2Bcu124-cp312-cp312-linux_x86_64.whl (7.1 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m127.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchaudio==2.4.0+cu124\n",
            "  Downloading https://download.pytorch.org/whl/cu124/torchaudio-2.4.0%2Bcu124-cp312-cp312-linux_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m79.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0+cu124) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0+cu124) (4.15.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0+cu124) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0+cu124) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0+cu124) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0+cu124) (2025.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0+cu124) (75.2.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.99 (from torch==2.4.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cuda_nvrtc_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (24.7 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m24.7/24.7 MB\u001b[0m \u001b[31m75.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.4.99 (from torch==2.4.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cuda_runtime_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m883.4/883.4 kB\u001b[0m \u001b[31m57.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.4.99 (from torch==2.4.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cuda_cupti_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m126.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.4.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.4.2.65 (from torch==2.4.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cublas_cu12-12.4.2.65-py3-none-manylinux2014_x86_64.whl (363.0 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m363.0/363.0 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.2.0.44 (from torch==2.4.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cufft_cu12-11.2.0.44-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.5.119 (from torch==2.4.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_curand_cu12-10.3.5.119-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.6.0.99 (from torch==2.4.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cusolver_cu12-11.6.0.99-py3-none-manylinux2014_x86_64.whl (128.4 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m128.4/128.4 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.3.0.142 (from torch==2.4.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cusparse_cu12-12.3.0.142-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.20.5 (from torch==2.4.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.4.99 (from torch==2.4.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_nvtx_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvjitlink-cu12==12.4.99 (from torch==2.4.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m102.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==3.0.0 (from torch==2.4.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/triton-3.0.0-1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.5 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision==0.19.0+cu124) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision==0.19.0+cu124) (11.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.4.0+cu124) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch==2.4.0+cu124) (1.3.0)\n",
            "Installing collected packages: triton, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.4.0\n",
            "    Uninstalling triton-3.4.0:\n",
            "      Successfully uninstalled triton-3.4.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.6.77\n",
            "    Uninstalling nvidia-nvtx-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.6.85\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.6.85:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.6.85\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.27.3\n",
            "    Uninstalling nvidia-nccl-cu12-2.27.3:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.27.3\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
            "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n",
            "    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.10.2.21\n",
            "    Uninstalling nvidia-cudnn-cu12-9.10.2.21:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.10.2.21\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
            "Successfully installed nvidia-cublas-cu12-12.4.2.65 nvidia-cuda-cupti-cu12-12.4.99 nvidia-cuda-nvrtc-cu12-12.4.99 nvidia-cuda-runtime-cu12-12.4.99 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.0.44 nvidia-curand-cu12-10.3.5.119 nvidia-cusolver-cu12-11.6.0.99 nvidia-cusparse-cu12-12.3.0.142 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.4.99 torch-2.4.0+cu124 torchaudio-2.4.0+cu124 torchvision-0.19.0+cu124 triton-3.0.0\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.4.0+cu124.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.4.0%2Bcu124/torch_scatter-2.1.2%2Bpt24cu124-cp312-cp312-linux_x86_64.whl (10.7 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m10.7/10.7 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.4.0%2Bcu124/torch_sparse-0.6.18%2Bpt24cu124-cp312-cp312-linux_x86_64.whl (5.2 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch-geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from torch-sparse) (1.16.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.12.15)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.2.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.20.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch-geometric) (3.0.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2025.8.3)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch-geometric) (4.15.0)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m68.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-scatter, torch-sparse, torch-geometric\n",
            "Successfully installed torch-geometric-2.6.1 torch-scatter-2.1.2+pt24cu124 torch-sparse-0.6.18+pt24cu124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608
        },
        "id": "Bgm7RfckxLg4",
        "outputId": "d1a9d70a-f6d6-46fc-8e3b-808984bec276"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "üì• Loading GraphML from: /content/drive/MyDrive/drug_data_kg_rebuilt_normalized.graphml\n",
            "‚úÖ Loaded graph with 100495 nodes and 160229 edges.\n",
            "üîé Example node attrs keys: ['type', 'node_type']\n",
            "üîé Example edge attrs keys: ['relationship', 'orig_relationship', 'relation']\n",
            "‚úÖ Node types: ['drug', 'active_ingredient', 'indications_and_usage', 'dosage_and_administration', 'warnings', 'pregnancy_or_breast_feeding', 'keep_out_of_reach_of_children', 'purpose', 'storage_and_handling', 'brand', 'do_not_use', 'ask_doctor', 'inactive_ingredient', 'stop_use', 'ask_doctor_or_pharmacist', 'overdose_warning', 'drug_interactions']\n",
            "‚úÖ Total edge types: 287\n",
            "Homogeneous nodes: 100495, edges used for training: 127935\n",
            "\n",
            "üîÅ Training unified R-GCN (type-aware, filtered negatives)...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 24.12 MiB is free. Process 17690 has 14.71 GiB memory in use. Of the allocated memory 13.76 GiB is allocated by PyTorch, and 852.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1680821751.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;31m# Compute embeddings (forward) using full graph edges each batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;31m# Positives\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1680821751.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, node_ids, edge_index, edge_type)\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch_geometric/nn/conv/rgcn_conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, edge_type)\u001b[0m\n\u001b[1;32m    265\u001b[0m                         )\n\u001b[1;32m    266\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m                         h = self.propagate(tmp, x=x_l, edge_type_ptr=None,\n\u001b[0m\u001b[1;32m    268\u001b[0m                                            size=size)\n\u001b[1;32m    269\u001b[0m                         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/torch_geometric.nn.conv.rgcn_conv_RGCNConv_propagate_fml9ycr6.py\u001b[0m in \u001b[0;36mpropagate\u001b[0;34m(self, edge_index, x, edge_type_ptr, size)\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;31m# End Aggregate Forward Pre Hook #######################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m         out = self.aggregate(\n\u001b[0m\u001b[1;32m    242\u001b[0m             \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch_geometric/nn/conv/message_passing.py\u001b[0m in \u001b[0;36maggregate\u001b[0;34m(self, inputs, index, ptr, dim_size)\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0;32mas\u001b[0m \u001b[0mspecified\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mmeth\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mby\u001b[0m \u001b[0mthe\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0maggr\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0margument\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m         \"\"\"\n\u001b[0;32m--> 594\u001b[0;31m         return self.aggr_module(inputs, index, ptr=ptr, dim_size=dim_size,\n\u001b[0m\u001b[1;32m    595\u001b[0m                                 dim=self.node_dim)\n\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch_geometric/experimental.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_experimental_mode_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'disable_dynamic_shapes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mrequired_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrequired_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch_geometric/nn/aggr/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, index, ptr, dim_size, dim, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m                                      \u001b[0;34mf\"'{dim_size}' but expected \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m                                      f\">= '{int(index.max()) + 1}')\")\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch_geometric/nn/aggr/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, index, ptr, dim_size, dim, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m             return super().__call__(x, index=index, ptr=ptr, dim_size=dim_size,\n\u001b[0m\u001b[1;32m    132\u001b[0m                                     dim=dim, **kwargs)\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mIndexError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch_geometric/nn/aggr/basic.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, index, ptr, dim_size, dim)\u001b[0m\n\u001b[1;32m     34\u001b[0m                 \u001b[0mptr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                 dim: int = -2) -> Tensor:\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mptr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch_geometric/nn/aggr/base.py\u001b[0m in \u001b[0;36mreduce\u001b[0;34m(self, x, index, ptr, dim_size, dim, reduce)\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Aggregation requires 'index' to be specified\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     def to_dense_batch(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(src, index, dim, dim_size, reduce)\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_zeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter_add_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbroadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;31m# For \"min\" and \"max\" reduction, we prefer `scatter_reduce_` on CPU or\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 24.12 MiB is free. Process 17690 has 14.71 GiB memory in use. Of the allocated memory 13.76 GiB is allocated by PyTorch, and 852.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ],
      "source": [
        "# ‚úÖ OpenFDA (GraphML) + sections ‚Äî R-GCN with Type-Aware, Filtered Negative Sampling (Train + Eval) ‚Äî Single Cell\n",
        "\n",
        "import os, random, pickle\n",
        "from collections import defaultdict\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "from torch_geometric.nn import RGCNConv\n",
        "from sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score\n",
        "\n",
        "import networkx as nx\n",
        "\n",
        "# ----------------------------\n",
        "# 0) Repro + Device\n",
        "# ----------------------------\n",
        "SEED = 42\n",
        "random.seed(SEED); np.random.seed(SEED)\n",
        "torch.manual_seed(SEED); torch.cuda.manual_seed_all(SEED)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# ====================================================================================\n",
        "# 1) Load Graph from GRAPHML (or PKL fallback) and normalize attributes\n",
        "# ====================================================================================\n",
        "# üëâ Set this to your GraphML path (example from your logs):\n",
        "# graph_path = \"/Users/ganeshkumarboini/Downloads/drug_data_kg_rebuilt_normalized.graphml\"\n",
        "graph_path = \"/content/drive/MyDrive/drug_data_kg_rebuilt_normalized.graphml\"\n",
        "\n",
        "assert os.path.exists(graph_path), f\"Path does not exist: {graph_path}\"\n",
        "\n",
        "def load_graph(path: str):\n",
        "    ext = os.path.splitext(path)[1].lower()\n",
        "    if ext == \".graphml\":\n",
        "        # Read GraphML\n",
        "        print(f\"üì• Loading GraphML from: {path}\")\n",
        "        G0 = nx.read_graphml(path)  # may return Graph/DiGraph/MultiGraph/MultiDiGraph\n",
        "        # Coerce to MultiDiGraph to preserve multi-edges + direction\n",
        "        H = nx.MultiDiGraph()\n",
        "        H.add_nodes_from(G0.nodes(data=True))\n",
        "        if G0.is_multigraph():\n",
        "            for u, v, k, data in G0.edges(keys=True, data=True):\n",
        "                H.add_edge(u, v, key=k, **(data or {}))\n",
        "        else:\n",
        "            # If undirected, we still put edges in a DiGraph form; GraphML may not carry direction flags per-edge.\n",
        "            for u, v, data in G0.edges(data=True):\n",
        "                H.add_edge(u, v, **(data or {}))\n",
        "        return H\n",
        "    elif ext in [\".pkl\", \".pickle\"]:\n",
        "        print(f\"üì• Loading pickle from: {path}\")\n",
        "        with open(path, \"rb\") as f:\n",
        "            return pickle.load(f)\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported file extension: {ext}\")\n",
        "\n",
        "G = load_graph(graph_path)\n",
        "\n",
        "# --- Patch node attributes: prefer 'node_type'; fallback to 'type'/'category'/'kind' ---\n",
        "for n, data in G.nodes(data=True):\n",
        "    if \"node_type\" not in data:\n",
        "        if \"type\" in data:\n",
        "            data[\"node_type\"] = data[\"type\"]\n",
        "        elif \"category\" in data:\n",
        "            data[\"node_type\"] = data[\"category\"]\n",
        "        elif \"kind\" in data:\n",
        "            data[\"node_type\"] = data[\"kind\"]\n",
        "        else:\n",
        "            data[\"node_type\"] = \"unknown\"\n",
        "\n",
        "# --- Patch edge attributes: prefer 'relation'; fallback to 'type'/'label' ---\n",
        "for u, v, attr in G.edges(data=True):\n",
        "    if \"relation\" not in attr:\n",
        "        if \"type\" in attr:\n",
        "            attr[\"relation\"] = attr[\"type\"]\n",
        "        elif \"label\" in attr:\n",
        "            attr[\"relation\"] = attr[\"label\"]\n",
        "        else:\n",
        "            attr[\"relation\"] = \"unknown\"\n",
        "\n",
        "print(f\"‚úÖ Loaded graph with {len(G.nodes)} nodes and {len(G.edges)} edges.\")\n",
        "print(f\"üîé Example node attrs keys: {list(next(iter(G.nodes(data=True)))[1].keys()) if len(G)>0 else []}\")\n",
        "print(f\"üîé Example edge attrs keys: {list(next(iter(G.edges(data=True)))[2].keys()) if G.number_of_edges()>0 else []}\")\n",
        "\n",
        "# ====================================================================================\n",
        "# 2) Build type maps and edge maps (typed remap to homogeneous ids)\n",
        "# ====================================================================================\n",
        "node_type_map = defaultdict(list)      # {ntype: [original node ids in this type order]}\n",
        "node_id_map = {}                       # {original node id: (ntype, local_idx)}\n",
        "node_idx_by_type = defaultdict(dict)   # {ntype: {original id: local_idx}}\n",
        "\n",
        "for nid, data in G.nodes(data=True):\n",
        "    ntype = data.get(\"node_type\", \"unknown\")\n",
        "    idx = len(node_type_map[ntype])\n",
        "    node_type_map[ntype].append(nid)\n",
        "    node_id_map[nid] = (ntype, idx)\n",
        "    node_idx_by_type[ntype][nid] = idx\n",
        "\n",
        "edge_type_map = defaultdict(list)      # {(src_type, relation, dst_type): [(src_local, dst_local), ...]}\n",
        "for src, dst, attr in G.edges(data=True):\n",
        "    rel = attr.get(\"relation\", \"unknown\")\n",
        "    if src not in node_id_map or dst not in node_id_map:\n",
        "        continue\n",
        "    src_t, src_i = node_id_map[src]\n",
        "    dst_t, dst_i = node_id_map[dst]\n",
        "    edge_type_map[(src_t, rel, dst_t)].append((src_i, dst_i))\n",
        "\n",
        "print(f\"‚úÖ Node types: {list(node_type_map.keys())}\")\n",
        "print(f\"‚úÖ Total edge types: {len(edge_type_map)}\")\n",
        "\n",
        "# ====================================================================================\n",
        "# 3) Homogeneous graph remap + per-relation splits\n",
        "# ====================================================================================\n",
        "type_offsets = {}\n",
        "global_id_map = {}\n",
        "offset = 0\n",
        "for ntype, nodes in node_type_map.items():\n",
        "    type_offsets[ntype] = offset\n",
        "    for local_idx in range(len(nodes)):\n",
        "        global_id_map[(ntype, local_idx)] = offset + local_idx\n",
        "    offset += len(nodes)\n",
        "\n",
        "num_nodes = offset\n",
        "edge_type_keys = list(edge_type_map.keys())            # index i -> (src_type, rel, dst_type)\n",
        "rel2id = {etype: i for i, etype in enumerate(edge_type_keys)}\n",
        "num_relations = len(edge_type_keys)\n",
        "\n",
        "all_src, all_dst, all_rel = [], [], []\n",
        "edge_type_splits = {}\n",
        "\n",
        "for etype, edges in edge_type_map.items():\n",
        "    src_type, _, dst_type = etype\n",
        "    if len(edges) < 5:\n",
        "        continue\n",
        "    perm = torch.randperm(len(edges))\n",
        "    num_train = int(0.8 * len(edges))\n",
        "    num_val = int(0.1 * len(edges))\n",
        "    train_edges_local = [edges[i] for i in perm[:num_train]]\n",
        "    val_edges_local   = [edges[i] for i in perm[num_train:num_train+num_val]]\n",
        "    test_edges_local  = [edges[i] for i in perm[num_train+num_val:]]\n",
        "\n",
        "    r = rel2id[etype]\n",
        "    for (s_l, d_l) in train_edges_local:\n",
        "        all_src.append(type_offsets[src_type] + s_l)\n",
        "        all_dst.append(type_offsets[dst_type] + d_l)\n",
        "        all_rel.append(r)\n",
        "\n",
        "    edge_type_splits[etype] = {\n",
        "        \"val\": torch.tensor([\n",
        "            [type_offsets[src_type] + s for s, d in val_edges_local],\n",
        "            [type_offsets[dst_type] + d for s, d in val_edges_local]\n",
        "        ], dtype=torch.long),\n",
        "        \"test\": torch.tensor([\n",
        "            [type_offsets[src_type] + s for s, d in test_edges_local],\n",
        "            [type_offsets[dst_type] + d for s, d in test_edges_local]\n",
        "        ], dtype=torch.long)\n",
        "    }\n",
        "\n",
        "edge_index = torch.tensor([all_src, all_dst], dtype=torch.long)\n",
        "edge_type = torch.tensor(all_rel, dtype=torch.long)\n",
        "print(f\"Homogeneous nodes: {num_nodes}, edges used for training: {edge_index.size(1)}\")\n",
        "\n",
        "# Move static tensors to device ONCE\n",
        "edge_index = edge_index.to(device)\n",
        "edge_type  = edge_type.to(device)\n",
        "node_ids   = torch.arange(num_nodes, device=device)\n",
        "\n",
        "# Existing edges per relation (for filtered negatives) ‚Äî keep as LOCAL pairs\n",
        "existing_edges_per_rel = {etype: set(pairs) for etype, pairs in edge_type_map.items()}\n",
        "def relid_to_etype(rel_id: int):\n",
        "    return edge_type_keys[rel_id]\n",
        "\n",
        "# ====================================================================================\n",
        "# 4) Model\n",
        "# ====================================================================================\n",
        "class RGCN(torch.nn.Module):\n",
        "    def __init__(self, num_nodes, num_relations, emb_dim=64, hidden_dim=64, out_dim=32):\n",
        "        super().__init__()\n",
        "        self.emb = torch.nn.Embedding(num_nodes, emb_dim)\n",
        "        self.conv1 = RGCNConv(emb_dim, hidden_dim, num_relations=num_relations)\n",
        "        self.conv2 = RGCNConv(hidden_dim, out_dim, num_relations=num_relations)\n",
        "\n",
        "    def forward(self, node_ids, edge_index, edge_type):\n",
        "        x = self.emb(node_ids)\n",
        "        x = self.conv1(x, edge_index, edge_type)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x, edge_index, edge_type)\n",
        "        return x\n",
        "\n",
        "def edge_scores(z, eidx):\n",
        "    return (z[eidx[0]] * z[eidx[1]]).sum(dim=-1).sigmoid()\n",
        "\n",
        "# ====================================================================================\n",
        "# 5) Type-aware, relation-aware, filtered negative sampling\n",
        "# ====================================================================================\n",
        "def sample_neg_edges_filtered_batch(src_g, dst_g, rel_ids, k_neg,\n",
        "                                    node_type_map, type_offsets, existing_edges_per_rel):\n",
        "    assert src_g.shape == dst_g.shape == rel_ids.shape\n",
        "    neg_edges = []\n",
        "    type_sizes = {ntype: len(nodes) for ntype, nodes in node_type_map.items()}\n",
        "\n",
        "    for s_glob, d_glob, r_id in zip(src_g.tolist(), dst_g.tolist(), rel_ids.tolist()):\n",
        "        etype = relid_to_etype(r_id)   # (src_type, rel, dst_type)\n",
        "        src_type, _, dst_type = etype\n",
        "        s_local = s_glob - type_offsets[src_type]\n",
        "        d_local = d_glob - type_offsets[dst_type]\n",
        "        existing = existing_edges_per_rel[etype]\n",
        "        src_len = type_sizes[src_type]; dst_len = type_sizes[dst_type]\n",
        "\n",
        "        for _ in range(k_neg):\n",
        "            if random.random() < 0.5:  # corrupt head\n",
        "                # try random heads until a non-existing pair is found\n",
        "                while True:\n",
        "                    new_s_local = random.randrange(src_len)\n",
        "                    if (new_s_local, d_local) not in existing:\n",
        "                        neg_edges.append((type_offsets[src_type] + new_s_local, d_glob))\n",
        "                        break\n",
        "            else:                      # corrupt tail\n",
        "                while True:\n",
        "                    new_d_local = random.randrange(dst_len)\n",
        "                    if (s_local, new_d_local) not in existing:\n",
        "                        neg_edges.append((s_glob, type_offsets[dst_type] + new_d_local))\n",
        "                        break\n",
        "\n",
        "    if not neg_edges:\n",
        "        return torch.empty((2, 0), dtype=torch.long, device=src_g.device)\n",
        "    return torch.tensor(neg_edges, dtype=torch.long, device=src_g.device).T  # (2, K*B)\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate_filtered(z, pos_eidx, rel_id, k_neg,\n",
        "                      node_type_map, type_offsets, existing_edges_per_rel, device):\n",
        "    if pos_eidx.numel() == 0:\n",
        "        return float(\"nan\"), float(\"nan\"), float(\"nan\"), float(\"nan\")\n",
        "    N = pos_eidx.size(1)\n",
        "    src_g = pos_eidx[0].to(device)\n",
        "    dst_g = pos_eidx[1].to(device)\n",
        "    rel_ids = torch.full((N,), rel_id, dtype=torch.long, device=device)\n",
        "\n",
        "    neg_eidx = sample_neg_edges_filtered_batch(\n",
        "        src_g, dst_g, rel_ids, k_neg, node_type_map, type_offsets, existing_edges_per_rel\n",
        "    )\n",
        "\n",
        "    y_true = torch.cat([torch.ones(N, device=device),\n",
        "                        torch.zeros(neg_eidx.size(1), device=device)])\n",
        "    scores = torch.cat([edge_scores(z, pos_eidx.to(device)),\n",
        "                        edge_scores(z, neg_eidx)], dim=0)\n",
        "\n",
        "    y, s = y_true.detach().cpu().numpy(), scores.detach().cpu().numpy()\n",
        "    auc = roc_auc_score(y, s)\n",
        "    preds = (s > 0.5).astype(int)\n",
        "    precision = precision_score(y, preds)\n",
        "    recall = recall_score(y, preds)\n",
        "    f1 = f1_score(y, preds)\n",
        "    return auc, precision, recall, f1\n",
        "\n",
        "# ====================================================================================\n",
        "# 6) Training setup\n",
        "# ====================================================================================\n",
        "EPOCHS = 30\n",
        "LR = 0.01\n",
        "BATCH_SIZE = 50_000\n",
        "K_NEG = 1  # negatives per positive\n",
        "\n",
        "model = RGCN(num_nodes, num_relations).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
        "\n",
        "import torch.utils.data as tud\n",
        "train_edges = torch.tensor([all_src, all_dst], dtype=torch.long)\n",
        "train_rels  = torch.tensor(all_rel, dtype=torch.long)\n",
        "train_dataset = tud.TensorDataset(train_edges[0], train_edges[1], train_rels)\n",
        "train_loader = tud.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=False)\n",
        "\n",
        "# ====================================================================================\n",
        "# 7) Train (single forward/backward per batch)\n",
        "# ====================================================================================\n",
        "print(\"\\nüîÅ Training unified R-GCN (type-aware, filtered negatives)...\")\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    model.train()\n",
        "    epoch_loss = 0.0\n",
        "\n",
        "    for src_batch, dst_batch, rel_batch in train_loader:\n",
        "        src_batch = src_batch.to(device)\n",
        "        dst_batch = dst_batch.to(device)\n",
        "        rel_batch = rel_batch.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Compute embeddings (forward) using full graph edges each batch\n",
        "        z = model(node_ids, edge_index, edge_type)\n",
        "\n",
        "        # Positives\n",
        "        pos_eidx = torch.stack([src_batch, dst_batch])  # (2, B)\n",
        "\n",
        "        # Type-aware, relation-aware, filtered negatives\n",
        "        neg_eidx = sample_neg_edges_filtered_batch(\n",
        "            src_batch, dst_batch, rel_batch, K_NEG,\n",
        "            node_type_map, type_offsets, existing_edges_per_rel\n",
        "        )\n",
        "\n",
        "        # Loss\n",
        "        pos_loss = -torch.log(edge_scores(z, pos_eidx) + 1e-15).mean()\n",
        "        if neg_eidx.size(1) > 0:\n",
        "            neg_loss = -torch.log(1.0 - edge_scores(z, neg_eidx) + 1e-15).mean()\n",
        "            loss = pos_loss + neg_loss\n",
        "        else:\n",
        "            loss = pos_loss\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += float(loss.detach().cpu())\n",
        "\n",
        "    print(f\"Epoch {epoch:02d} | Total Loss: {epoch_loss:.4f}\")\n",
        "\n",
        "# ====================================================================================\n",
        "# 8) Final evaluation (per relation + overall)\n",
        "# ====================================================================================\n",
        "print(\"\\nüìä Final evaluation per edge type (filtered negatives):\")\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    z = model(node_ids, edge_index, edge_type)\n",
        "\n",
        "results = []\n",
        "all_pos_eidx_list, all_rel_ids_list = [], []\n",
        "\n",
        "for etype, splits in edge_type_splits.items():\n",
        "    rel_id = rel2id[etype]\n",
        "    test_edges = splits[\"test\"]  # (2, N)\n",
        "    if test_edges.size(1) == 0:\n",
        "        continue\n",
        "\n",
        "    auc, p, r, f1 = evaluate_filtered(\n",
        "        z, test_edges, rel_id, K_NEG,\n",
        "        node_type_map, type_offsets, existing_edges_per_rel, device\n",
        "    )\n",
        "    results.append((etype, auc, p, r, f1))\n",
        "    all_pos_eidx_list.append(test_edges)\n",
        "    all_rel_ids_list.append(torch.full((test_edges.size(1),), rel_id, dtype=torch.long))\n",
        "\n",
        "    print(f\"{etype}: AUC={auc:.4f}, P={p:.3f}, R={r:.3f}, F1={f1:.3f}\")\n",
        "\n",
        "if all_pos_eidx_list:\n",
        "    all_pos_eidx = torch.cat(all_pos_eidx_list, dim=1)\n",
        "    all_rel_ids = torch.cat(all_rel_ids_list, dim=0).to(device)\n",
        "\n",
        "    neg_eidx_overall = sample_neg_edges_filtered_batch(\n",
        "        all_pos_eidx[0].to(device), all_pos_eidx[1].to(device),\n",
        "        all_rel_ids, K_NEG, node_type_map, type_offsets, existing_edges_per_rel\n",
        "    )\n",
        "\n",
        "    y_true_overall = torch.cat([torch.ones(all_pos_eidx.size(1), device=device),\n",
        "                                torch.zeros(neg_eidx_overall.size(1), device=device)])\n",
        "    scores_overall = torch.cat([edge_scores(z, all_pos_eidx.to(device)),\n",
        "                                edge_scores(z, neg_eidx_overall)], dim=0)\n",
        "\n",
        "    y_cpu = y_true_overall.detach().cpu().numpy()\n",
        "    s_cpu = scores_overall.detach().cpu().numpy()\n",
        "    overall_auc = roc_auc_score(y_cpu, s_cpu)\n",
        "    overall_preds = (s_cpu > 0.5).astype(int)\n",
        "    overall_p = precision_score(y_cpu, overall_preds)\n",
        "    overall_r = recall_score(y_cpu, overall_preds)\n",
        "    overall_f1 = f1_score(y_cpu, overall_preds)\n",
        "\n",
        "    print(\"\\nüåç Overall Performance (filtered negatives):\")\n",
        "    print(f\"Overall AUC = {overall_auc:.4f}\")\n",
        "    print(f\"Overall Precision = {overall_p:.3f}\")\n",
        "    print(f\"Overall Recall = {overall_r:.3f}\")\n",
        "    print(f\"Overall F1 Score = {overall_f1:.3f}\")\n",
        "else:\n",
        "    print(\"\\nNo test edges available for evaluation.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === GraphML ‚Üí R-GCN with NeighborLoader mini-batching + AMP + batched inference (type-aware, filtered negatives) ===\n",
        "# Works with GraphML input. Keeps your training/eval structure, adds robust attr normalization.\n",
        "\n",
        "import os, gc, random, pickle\n",
        "from collections import defaultdict\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from torch_geometric.nn import RGCNConv\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.loader import NeighborLoader\n",
        "from sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score\n",
        "import networkx as nx\n",
        "\n",
        "# ----------------------------\n",
        "# 0) Repro + Device + GC\n",
        "# ----------------------------\n",
        "SEED = 42\n",
        "random.seed(SEED); np.random.seed(SEED)\n",
        "torch.manual_seed(SEED); torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "# (Optional) helps reduce CUDA fragmentation on long runs\n",
        "os.environ.setdefault(\"PYTORCH_CUDA_ALLOC_CONF\", \"expandable_segments:True\")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "gc.collect()\n",
        "if device.type == \"cuda\":\n",
        "    torch.cuda.empty_cache()\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# ----------------------------\n",
        "# 1) Load Graph from GRAPHML (with attr normalization)\n",
        "# ----------------------------\n",
        "# Set your GraphML path here:\n",
        "graph_path = \"/content/drive/MyDrive/drug_data_kg_rebuilt_normalized.graphml\"\n",
        "assert os.path.exists(graph_path), f\"Path does not exist: {graph_path}\"\n",
        "\n",
        "print(f\"üì• Loading GraphML from: {graph_path}\")\n",
        "G0 = nx.read_graphml(graph_path)\n",
        "\n",
        "# Coerce to MultiDiGraph to preserve multi-edges + direction\n",
        "G = nx.MultiDiGraph()\n",
        "G.add_nodes_from(G0.nodes(data=True))\n",
        "if G0.is_multigraph():\n",
        "    for u, v, k, data in G0.edges(keys=True, data=True):\n",
        "        G.add_edge(u, v, key=k, **(data or {}))\n",
        "else:\n",
        "    for u, v, data in G0.edges(data=True):\n",
        "        G.add_edge(u, v, **(data or {}))\n",
        "\n",
        "# --- Normalize node attributes: prefer 'node_type', fallback to 'type'/'category'/'kind' ---\n",
        "for n, data in G.nodes(data=True):\n",
        "    if \"node_type\" not in data:\n",
        "        if \"type\" in data:        data[\"node_type\"] = data[\"type\"]\n",
        "        elif \"category\" in data:  data[\"node_type\"] = data[\"category\"]\n",
        "        elif \"kind\" in data:      data[\"node_type\"] = data[\"kind\"]\n",
        "        else:                     data[\"node_type\"] = \"unknown\"\n",
        "\n",
        "# --- Normalize edge attributes: prefer 'relation', fallback to 'relationship'/'type'/'label' ---\n",
        "for u, v, attr in G.edges(data=True):\n",
        "    if \"relation\" not in attr:\n",
        "        if   \"relationship\" in attr: attr[\"relation\"] = attr[\"relationship\"]\n",
        "        elif \"type\" in attr:         attr[\"relation\"] = attr[\"type\"]\n",
        "        elif \"label\" in attr:        attr[\"relation\"] = attr[\"label\"]\n",
        "        else:                        attr[\"relation\"] = \"unknown\"\n",
        "\n",
        "print(f\"‚úÖ Loaded graph with {len(G.nodes)} nodes and {len(G.edges)} edges.\")\n",
        "\n",
        "# ----------------------------\n",
        "# 2) Build type maps and edge maps\n",
        "# ----------------------------\n",
        "node_type_map = defaultdict(list)      # {ntype: [original node ids in this type order]}\n",
        "node_id_map = {}                       # {original node id: (ntype, local_idx)}\n",
        "node_idx_by_type = defaultdict(dict)   # {ntype: {original id: local_idx}}\n",
        "\n",
        "for nid, data in G.nodes(data=True):\n",
        "    ntype = data.get(\"node_type\", \"unknown\")\n",
        "    idx = len(node_type_map[ntype])\n",
        "    node_type_map[ntype].append(nid)\n",
        "    node_id_map[nid] = (ntype, idx)\n",
        "    node_idx_by_type[ntype][nid] = idx\n",
        "\n",
        "edge_type_map = defaultdict(list)      # {(src_type, relation, dst_type): [(src_local, dst_local), ...]}\n",
        "for src, dst, attr in G.edges(data=True):\n",
        "    rel = attr.get(\"relation\", \"unknown\")\n",
        "    if src not in node_id_map or dst not in node_id_map:\n",
        "        continue\n",
        "    src_t, src_i = node_id_map[src]\n",
        "    dst_t, dst_i = node_id_map[dst]\n",
        "    edge_type_map[(src_t, rel, dst_t)].append((src_i, dst_i))\n",
        "\n",
        "print(f\"‚úÖ Node types: {list(node_type_map.keys())}\")\n",
        "print(f\"‚úÖ Total edge types: {len(edge_type_map)}\")\n",
        "\n",
        "# ----------------------------\n",
        "# 3) Homogeneous graph remap + per-relation splits\n",
        "# ----------------------------\n",
        "type_offsets = {}\n",
        "global_id_map = {}\n",
        "offset = 0\n",
        "for ntype, nodes in node_type_map.items():\n",
        "    type_offsets[ntype] = offset\n",
        "    for local_idx in range(len(nodes)):\n",
        "        global_id_map[(ntype, local_idx)] = offset + local_idx\n",
        "    offset += len(nodes)\n",
        "\n",
        "num_nodes = offset\n",
        "edge_type_keys = list(edge_type_map.keys())            # index i -> (src_type, rel, dst_type)\n",
        "rel2id = {etype: i for i, etype in enumerate(edge_type_keys)}\n",
        "num_relations = len(edge_type_keys)\n",
        "\n",
        "all_src, all_dst, all_rel = [], [], []\n",
        "edge_type_splits = {}\n",
        "\n",
        "for etype, edges in edge_type_map.items():\n",
        "    src_type, _, dst_type = etype\n",
        "    if len(edges) < 5:\n",
        "        continue\n",
        "    perm = torch.randperm(len(edges))\n",
        "    num_train = int(0.8 * len(edges))\n",
        "    num_val = int(0.1 * len(edges))\n",
        "    train_edges_local = [edges[i] for i in perm[:num_train]]\n",
        "    val_edges_local   = [edges[i] for i in perm[num_train:num_train+num_val]]\n",
        "    test_edges_local  = [edges[i] for i in perm[num_train+num_val:]]\n",
        "\n",
        "    r = rel2id[etype]\n",
        "    for (s_l, d_l) in train_edges_local:\n",
        "        all_src.append(type_offsets[src_type] + s_l)\n",
        "        all_dst.append(type_offsets[dst_type] + d_l)\n",
        "        all_rel.append(r)\n",
        "\n",
        "    edge_type_splits[etype] = {\n",
        "        \"val\": torch.tensor([\n",
        "            [type_offsets[src_type] + s for s, d in val_edges_local],\n",
        "            [type_offsets[dst_type] + d for s, d in val_edges_local]\n",
        "        ], dtype=torch.long),\n",
        "        \"test\": torch.tensor([\n",
        "            [type_offsets[src_type] + s for s, d in test_edges_local],\n",
        "            [type_offsets[dst_type] + d for s, d in test_edges_local]\n",
        "        ], dtype=torch.long)\n",
        "    }\n",
        "\n",
        "edge_index_cpu = torch.tensor([all_src, all_dst], dtype=torch.long)  # CPU for loaders\n",
        "edge_type_cpu  = torch.tensor(all_rel, dtype=torch.long)\n",
        "\n",
        "print(f\"Homogeneous nodes: {num_nodes}, edges used for training: {edge_index_cpu.size(1)}\")\n",
        "\n",
        "# ----------------------------\n",
        "# 4) Existing edges per relation (for filtered negatives)\n",
        "# ----------------------------\n",
        "existing_edges_per_rel = {etype: set(pairs) for etype, pairs in edge_type_map.items()}\n",
        "def relid_to_etype(rel_id: int):\n",
        "    return edge_type_keys[rel_id]\n",
        "\n",
        "# ----------------------------\n",
        "# 5) Model (R-GCN with num_bases) + helpers\n",
        "# ----------------------------\n",
        "class RGCN(nn.Module):\n",
        "    def __init__(self, num_nodes, num_relations, emb_dim=64, hidden_dim=128, out_dim=32, num_bases=30):\n",
        "        super().__init__()\n",
        "        self.emb = nn.Embedding(num_nodes, emb_dim)\n",
        "        self.conv1 = RGCNConv(emb_dim, hidden_dim, num_relations=num_relations, num_bases=num_bases)\n",
        "        self.conv2 = RGCNConv(hidden_dim, out_dim, num_relations=num_relations, num_bases=num_bases)\n",
        "\n",
        "    def forward(self, node_ids, edge_index, edge_type):\n",
        "        # node_ids: global ids present in this sampled subgraph (order matches subgraph nodes)\n",
        "        x = self.emb(node_ids)\n",
        "        x = self.conv1(x, edge_index, edge_type)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x, edge_index, edge_type)\n",
        "        return x\n",
        "\n",
        "def edge_scores(z, eidx):\n",
        "    return (z[eidx[0]] * z[eidx[1]]).sum(dim=-1).sigmoid()\n",
        "\n",
        "# ----------------------------\n",
        "# 6) Negative sampling & evaluation (filtered, type-aware)\n",
        "# ----------------------------\n",
        "def sample_neg_edges_filtered_batch(src_g, dst_g, rel_ids, k_neg,\n",
        "                                    node_type_map, type_offsets, existing_edges_per_rel):\n",
        "    assert src_g.shape == dst_g.shape == rel_ids.shape\n",
        "    neg_edges = []\n",
        "    type_sizes = {ntype: len(nodes) for ntype, nodes in node_type_map.items()}\n",
        "\n",
        "    for s_glob, d_glob, r_id in zip(src_g.tolist(), dst_g.tolist(), rel_ids.tolist()):\n",
        "        etype = relid_to_etype(r_id)   # (src_type, rel, dst_type)\n",
        "        src_type, _, dst_type = etype\n",
        "        s_local = s_glob - type_offsets[src_type]\n",
        "        d_local = d_glob - type_offsets[dst_type]\n",
        "        existing = existing_edges_per_rel[etype]\n",
        "        src_len = type_sizes[src_type]; dst_len = type_sizes[dst_type]\n",
        "\n",
        "        for _ in range(k_neg):\n",
        "            if random.random() < 0.5:  # corrupt head\n",
        "                while True:\n",
        "                    new_s_local = random.randrange(src_len)\n",
        "                    if (new_s_local, d_local) not in existing:\n",
        "                        neg_edges.append((type_offsets[src_type] + new_s_local, d_glob))\n",
        "                        break\n",
        "            else:                      # corrupt tail\n",
        "                while True:\n",
        "                    new_d_local = random.randrange(dst_len)\n",
        "                    if (s_local, new_d_local) not in existing:\n",
        "                        neg_edges.append((s_glob, type_offsets[dst_type] + new_d_local))\n",
        "                        break\n",
        "\n",
        "    if not neg_edges:\n",
        "        return torch.empty((2, 0), dtype=torch.long, device=src_g.device)\n",
        "    return torch.tensor(neg_edges, dtype=torch.long, device=src_g.device).T  # (2, K*B)\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate_filtered(z, pos_eidx, rel_id, k_neg,\n",
        "                      node_type_map, type_offsets, existing_edges_per_rel, device):\n",
        "    if pos_eidx.numel() == 0:\n",
        "        return float(\"nan\"), float(\"nan\"), float(\"nan\"), float(\"nan\")\n",
        "    N = pos_eidx.size(1)\n",
        "    src_g = pos_eidx[0].to(device, non_blocking=True)\n",
        "    dst_g = pos_eidx[1].to(device, non_blocking=True)\n",
        "    rel_ids = torch.full((N,), rel_id, dtype=torch.long, device=device)\n",
        "\n",
        "    neg_eidx = sample_neg_edges_filtered_batch(\n",
        "        src_g, dst_g, rel_ids, k_neg, node_type_map, type_offsets, existing_edges_per_rel\n",
        "    )\n",
        "\n",
        "    y_true = torch.cat([torch.ones(N, device=device),\n",
        "                        torch.zeros(neg_eidx.size(1), device=device)])\n",
        "    scores = torch.cat([edge_scores(z, pos_eidx.to(device, non_blocking=True)),\n",
        "                        edge_scores(z, neg_eidx)], dim=0)\n",
        "\n",
        "    y, s = y_true.detach().cpu().numpy(), scores.detach().cpu().numpy()\n",
        "    auc = roc_auc_score(y, s)\n",
        "    preds = (s > 0.5).astype(int)\n",
        "    precision = precision_score(y, preds)\n",
        "    recall = recall_score(y, preds)\n",
        "    f1 = f1_score(y, preds)\n",
        "    return auc, precision, recall, f1\n",
        "\n",
        "# ----------------------------\n",
        "# 7) Training setup & PyG Data + NeighborLoader\n",
        "# ----------------------------\n",
        "EPOCHS = 30\n",
        "LR = 0.01\n",
        "K_NEG = 1  # negatives per positive\n",
        "\n",
        "# Build a PyG Data object (no node features; embeddings live in the model)\n",
        "data_pyg = Data(num_nodes=num_nodes, edge_index=edge_index_cpu, edge_type=edge_type_cpu)\n",
        "\n",
        "# Use unique training source nodes as target nodes for sampling\n",
        "train_src_tensor = torch.tensor(all_src, dtype=torch.long)\n",
        "train_src_unique = torch.unique(train_src_tensor)\n",
        "\n",
        "# NeighborLoader settings: tune NUM_NEIGHBORS and NBATCH_SIZE to taste\n",
        "NUM_NEIGHBORS = [15, 10]   # sample neighbors per R-GCN layer\n",
        "NBATCH_SIZE = 4096         # number of target nodes per mini-batch (reduce if OOM)\n",
        "NUM_WORKERS = 4\n",
        "\n",
        "train_loader = NeighborLoader(\n",
        "    data_pyg,\n",
        "    num_neighbors=NUM_NEIGHBORS,\n",
        "    batch_size=NBATCH_SIZE,\n",
        "    input_nodes=train_src_unique,  # sample neighborhoods around training source nodes\n",
        "    shuffle=True,\n",
        "    num_workers=NUM_WORKERS\n",
        ")\n",
        "\n",
        "# ----------------------------\n",
        "# 8) Model, optimizer, AMP scaler\n",
        "# ----------------------------\n",
        "model = RGCN(num_nodes, num_relations, emb_dim=64, hidden_dim=128, out_dim=32, num_bases=30).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
        "scaler = GradScaler(enabled=(device.type == \"cuda\"))\n",
        "\n",
        "# Pre-build global training tensors on DEVICE once to avoid re-allocating every batch\n",
        "src_glob_all = torch.tensor(all_src, dtype=torch.long, device=device)\n",
        "dst_glob_all = torch.tensor(all_dst, dtype=torch.long, device=device)\n",
        "rels_all     = torch.tensor(all_rel, dtype=torch.long, device=device)\n",
        "\n",
        "# ----------------------------\n",
        "# 9) Training loop using NeighborLoader (mini-batched subgraphs)\n",
        "# ----------------------------\n",
        "print(\"\\nüîÅ Training with NeighborLoader mini-batches + AMP ...\")\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    model.train()\n",
        "    epoch_loss = 0.0\n",
        "    seen_pos = 0\n",
        "\n",
        "    for batch in train_loader:\n",
        "        batch = batch.to(device, non_blocking=True)\n",
        "\n",
        "        # global ids of nodes in this batch (same order as local nodes)\n",
        "        n_id = batch.n_id  # [num_nodes_in_batch], already on device\n",
        "\n",
        "        # global->local mapping for this batch\n",
        "        global2local = -torch.ones(num_nodes, dtype=torch.long, device=device)\n",
        "        global2local[n_id] = torch.arange(n_id.size(0), device=device)\n",
        "\n",
        "        # Which training positives have both endpoints inside this batch?\n",
        "        in_src = global2local[src_glob_all]  # -1 if source not in batch\n",
        "        in_dst = global2local[dst_glob_all]  # -1 if dest not in batch\n",
        "        mask_in_batch = (in_src >= 0) & (in_dst >= 0)\n",
        "\n",
        "        pos_idxs = torch.nonzero(mask_in_batch, as_tuple=False).view(-1)\n",
        "        if pos_idxs.numel() == 0:\n",
        "            del batch, n_id, global2local, in_src, in_dst, mask_in_batch, pos_idxs\n",
        "            if device.type == \"cuda\": torch.cuda.empty_cache()\n",
        "            continue\n",
        "\n",
        "        # Optional sub-sample positives per batch to cap compute\n",
        "        MAX_POS_PER_BATCH = 8192\n",
        "        if pos_idxs.numel() > MAX_POS_PER_BATCH:\n",
        "            perm = torch.randperm(pos_idxs.numel(), device=device)[:MAX_POS_PER_BATCH]\n",
        "            pos_idxs = pos_idxs[perm]\n",
        "\n",
        "        # Local indices for positives (local to this batch)\n",
        "        local_src = global2local[src_glob_all[pos_idxs]]\n",
        "        local_dst = global2local[dst_glob_all[pos_idxs]]\n",
        "        rel_ids_for_pos = rels_all[pos_idxs]\n",
        "\n",
        "        pos_eidx_local  = torch.stack([local_src, local_dst], dim=0)                   # (2, P)\n",
        "        pos_eidx_global = torch.stack([src_glob_all[pos_idxs], dst_glob_all[pos_idxs]], dim=0)  # (2, P)\n",
        "\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "        with autocast(enabled=(device.type == \"cuda\")):\n",
        "            z_batch = model(n_id, batch.edge_index, batch.edge_type)  # [n_in_batch, out_dim]\n",
        "\n",
        "            # Typed, filtered negatives in GLOBAL id space\n",
        "            neg_eidx_global = sample_neg_edges_filtered_batch(\n",
        "                pos_eidx_global[0], pos_eidx_global[1], rel_ids_for_pos, K_NEG,\n",
        "                node_type_map, type_offsets, existing_edges_per_rel\n",
        "            )\n",
        "\n",
        "            # Map negatives into local indices; keep those inside sampled subgraph\n",
        "            if neg_eidx_global.numel() > 0:\n",
        "                neg_src_local = global2local[neg_eidx_global[0]]\n",
        "                neg_dst_local = global2local[neg_eidx_global[1]]\n",
        "                neg_mask = (neg_src_local >= 0) & (neg_dst_local >= 0)\n",
        "                if neg_mask.any():\n",
        "                    neg_eidx_local = torch.stack([neg_src_local[neg_mask], neg_dst_local[neg_mask]], dim=0)\n",
        "                else:\n",
        "                    neg_eidx_local = torch.empty((2,0), dtype=torch.long, device=device)\n",
        "            else:\n",
        "                neg_eidx_local = torch.empty((2,0), dtype=torch.long, device=device)\n",
        "\n",
        "            # Scores & loss (DistMult with sigmoid)\n",
        "            pos_scores = (z_batch[pos_eidx_local[0]] * z_batch[pos_eidx_local[1]]).sum(dim=-1).sigmoid()\n",
        "            pos_loss = -torch.log(pos_scores + 1e-15).mean()\n",
        "\n",
        "            if neg_eidx_local.size(1) > 0:\n",
        "                neg_scores = (z_batch[neg_eidx_local[0]] * z_batch[neg_eidx_local[1]]).sum(dim=-1).sigmoid()\n",
        "                neg_loss = -torch.log(1.0 - neg_scores + 1e-15).mean()\n",
        "                loss = pos_loss + neg_loss\n",
        "            else:\n",
        "                loss = pos_loss\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        epoch_loss += float(loss.detach().cpu())\n",
        "        seen_pos += pos_eidx_local.size(1)\n",
        "\n",
        "        # Free batch-level tensors\n",
        "        del batch, n_id, global2local, in_src, in_dst, mask_in_batch, pos_idxs\n",
        "        del local_src, local_dst, rel_ids_for_pos, pos_eidx_local, pos_eidx_global\n",
        "        del z_batch, neg_eidx_global, neg_eidx_local, pos_scores, pos_loss, loss\n",
        "        if device.type == \"cuda\":\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    print(f\"Epoch {epoch:02d} | Loss: {epoch_loss:.4f} | Seen pos edges: {seen_pos}\")\n",
        "\n",
        "# ----------------------------\n",
        "# 10) Batched inference: compute z for ALL nodes without OOM\n",
        "# ----------------------------\n",
        "print(\"\\nüîé Computing full-node embeddings (batched inference) ...\")\n",
        "model.eval()\n",
        "OUT_DIM = 32  # same as model out_dim\n",
        "z_all = torch.empty((num_nodes, OUT_DIM), dtype=torch.float32, device=device)\n",
        "\n",
        "INFER_BATCH = 16384  # tune smaller if OOM during inference\n",
        "infer_loader = NeighborLoader(\n",
        "    Data(num_nodes=num_nodes, edge_index=edge_index_cpu, edge_type=edge_type_cpu),\n",
        "    num_neighbors=[-1, -1],    # full 2-hop for both layers\n",
        "    batch_size=INFER_BATCH,\n",
        "    input_nodes=torch.arange(num_nodes),\n",
        "    shuffle=False,\n",
        "    num_workers=NUM_WORKERS\n",
        ")\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in infer_loader:\n",
        "        batch = batch.to(device, non_blocking=True)\n",
        "        n_id = batch.n_id\n",
        "        z_batch = model(n_id, batch.edge_index, batch.edge_type)\n",
        "        z_all[n_id] = z_batch\n",
        "        del batch, z_batch, n_id\n",
        "        if device.type == \"cuda\":\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "# ----------------------------\n",
        "# 11) Final evaluation (per relation + overall) using z_all\n",
        "# ----------------------------\n",
        "print(\"\\nüìä Final evaluation per edge type (filtered negatives):\")\n",
        "results = []\n",
        "all_pos_eidx_list, all_rel_ids_list = [], []\n",
        "\n",
        "def edge_scores_all(z, eidx):\n",
        "    return (z[eidx[0]] * z[eidx[1]]).sum(dim=-1).sigmoid()\n",
        "\n",
        "for etype, splits in edge_type_splits.items():\n",
        "    rel_id = rel2id[etype]\n",
        "    test_edges = splits[\"test\"]  # (2, N)\n",
        "    if test_edges.size(1) == 0:\n",
        "        continue\n",
        "\n",
        "    auc, p, r, f1 = evaluate_filtered(\n",
        "        z_all, test_edges, rel_id, K_NEG,\n",
        "        node_type_map, type_offsets, existing_edges_per_rel, device\n",
        "    )\n",
        "    results.append((etype, auc, p, r, f1))\n",
        "    all_pos_eidx_list.append(test_edges)\n",
        "    all_rel_ids_list.append(torch.full((test_edges.size(1),), rel_id, dtype=torch.long))\n",
        "\n",
        "    print(f\"{etype}: AUC={auc:.4f}, P={p:.3f}, R={r:.3f}, F1={f1:.3f}\")\n",
        "\n",
        "if all_pos_eidx_list:\n",
        "    all_pos_eidx = torch.cat(all_pos_eidx_list, dim=1)\n",
        "    all_rel_ids = torch.cat(all_rel_ids_list, dim=0).to(device)\n",
        "\n",
        "    neg_eidx_overall = sample_neg_edges_filtered_batch(\n",
        "        all_pos_eidx[0].to(device, non_blocking=True),\n",
        "        all_pos_eidx[1].to(device, non_blocking=True),\n",
        "        all_rel_ids, K_NEG, node_type_map, type_offsets, existing_edges_per_rel\n",
        "    )\n",
        "\n",
        "    y_true_overall = torch.cat([torch.ones(all_pos_eidx.size(1), device=device),\n",
        "                                torch.zeros(neg_eidx_overall.size(1), device=device)])\n",
        "    scores_overall = torch.cat([edge_scores_all(z_all, all_pos_eidx.to(device, non_blocking=True)),\n",
        "                                edge_scores_all(z_all, neg_eidx_overall)], dim=0)\n",
        "\n",
        "    y_cpu = y_true_overall.detach().cpu().numpy()\n",
        "    s_cpu = scores_overall.detach().cpu().numpy()\n",
        "    overall_auc = roc_auc_score(y_cpu, s_cpu)\n",
        "    overall_preds = (s_cpu > 0.5).astype(int)\n",
        "    overall_p = precision_score(y_cpu, overall_preds)\n",
        "    overall_r = recall_score(y_cpu, overall_preds)\n",
        "    overall_f1 = f1_score(y_cpu, overall_preds)\n",
        "\n",
        "    print(\"\\nüåç Overall Performance (filtered negatives):\")\n",
        "    print(f\"Overall AUC = {overall_auc:.4f}\")\n",
        "    print(f\"Overall Precision = {overall_p:.3f}\")\n",
        "    print(f\"Overall Recall = {overall_r:.3f}\")\n",
        "    print(f\"Overall F1 Score = {overall_f1:.3f}\")\n",
        "else:\n",
        "    print(\"\\nNo test edges available for evaluation.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6pB0tz-F2Jl1",
        "outputId": "f7670d86-ab16-48cd-a12e-f9e612462d94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "üì• Loading GraphML from: /content/drive/MyDrive/drug_data_kg_rebuilt_normalized.graphml\n",
            "‚úÖ Loaded graph with 100495 nodes and 160229 edges.\n",
            "‚úÖ Node types: ['drug', 'active_ingredient', 'indications_and_usage', 'dosage_and_administration', 'warnings', 'pregnancy_or_breast_feeding', 'keep_out_of_reach_of_children', 'purpose', 'storage_and_handling', 'brand', 'do_not_use', 'ask_doctor', 'inactive_ingredient', 'stop_use', 'ask_doctor_or_pharmacist', 'overdose_warning', 'drug_interactions']\n",
            "‚úÖ Total edge types: 287\n",
            "Homogeneous nodes: 100495, edges used for training: 127935\n",
            "\n",
            "üîÅ Training with NeighborLoader mini-batches + AMP ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch_geometric/sampler/neighbor_sampler.py:61: UserWarning: Using 'NeighborSampler' without a 'pyg-lib' installation is deprecated and will be removed soon. Please install 'pyg-lib' for accelerated neighborhood sampling\n",
            "  warnings.warn(f\"Using '{self.__class__.__name__}' without a \"\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/tmp/ipython-input-3778466115.py:274: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler(enabled=(device.type == \"cuda\"))\n",
            "/tmp/ipython-input-3778466115.py:327: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(enabled=(device.type == \"cuda\")):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01 | Loss: 31.9452 | Seen pos edges: 23052\n",
            "Epoch 02 | Loss: 15.5384 | Seen pos edges: 22846\n",
            "Epoch 03 | Loss: 12.4352 | Seen pos edges: 23092\n",
            "Epoch 04 | Loss: 11.0944 | Seen pos edges: 22765\n",
            "Epoch 05 | Loss: 10.4573 | Seen pos edges: 22956\n",
            "Epoch 06 | Loss: 10.0183 | Seen pos edges: 22752\n",
            "Epoch 07 | Loss: 9.7059 | Seen pos edges: 22912\n",
            "Epoch 08 | Loss: 9.1485 | Seen pos edges: 22875\n",
            "Epoch 09 | Loss: 9.2289 | Seen pos edges: 22826\n",
            "Epoch 10 | Loss: 8.8611 | Seen pos edges: 22681\n",
            "Epoch 11 | Loss: 8.7910 | Seen pos edges: 22818\n",
            "Epoch 12 | Loss: 8.6300 | Seen pos edges: 22913\n",
            "Epoch 13 | Loss: 8.4246 | Seen pos edges: 23017\n",
            "Epoch 14 | Loss: 8.1609 | Seen pos edges: 23039\n",
            "Epoch 15 | Loss: 8.2283 | Seen pos edges: 22826\n",
            "Epoch 16 | Loss: 7.9806 | Seen pos edges: 23088\n",
            "Epoch 17 | Loss: 8.0171 | Seen pos edges: 22912\n",
            "Epoch 18 | Loss: 7.8431 | Seen pos edges: 23159\n",
            "Epoch 19 | Loss: 7.6005 | Seen pos edges: 23121\n",
            "Epoch 20 | Loss: 7.6930 | Seen pos edges: 22772\n",
            "Epoch 21 | Loss: 7.4863 | Seen pos edges: 23220\n",
            "Epoch 22 | Loss: 6.9978 | Seen pos edges: 22785\n",
            "Epoch 23 | Loss: 7.0238 | Seen pos edges: 22805\n",
            "Epoch 24 | Loss: 7.3071 | Seen pos edges: 22955\n",
            "Epoch 25 | Loss: 7.2729 | Seen pos edges: 22975\n",
            "Epoch 26 | Loss: 6.9236 | Seen pos edges: 22803\n",
            "Epoch 27 | Loss: 6.6924 | Seen pos edges: 22952\n",
            "Epoch 28 | Loss: 6.6700 | Seen pos edges: 22916\n",
            "Epoch 29 | Loss: 6.8907 | Seen pos edges: 22691\n",
            "Epoch 30 | Loss: 6.5594 | Seen pos edges: 23015\n",
            "\n",
            "üîé Computing full-node embeddings (batched inference) ...\n",
            "\n",
            "üìä Final evaluation per edge type (filtered negatives):\n",
            "('drug', 'active_ingredient', 'active_ingredient'): AUC=0.5209, P=0.513, R=0.299, F1=0.378\n",
            "('drug', 'indications_and_usage', 'indications_and_usage'): AUC=0.4459, P=0.457, R=0.470, F1=0.463\n",
            "('drug', 'dosage_and_administration', 'dosage_and_administration'): AUC=0.4616, P=0.454, R=0.352, F1=0.396\n",
            "('drug', 'warnings', 'warnings'): AUC=0.5304, P=0.508, R=0.458, F1=0.482\n",
            "('drug', 'pregnancy_or_breast_feeding', 'pregnancy_or_breast_feeding'): AUC=0.4832, P=0.452, R=0.289, F1=0.353\n",
            "('drug', 'keep_out_of_reach_of_children', 'keep_out_of_reach_of_children'): AUC=0.4355, P=0.534, R=0.215, F1=0.306\n",
            "('drug', 'purpose', 'purpose'): AUC=0.5648, P=0.532, R=0.347, F1=0.420\n",
            "('drug', 'warnings', 'keep_out_of_reach_of_children'): AUC=0.4158, P=0.510, R=0.234, F1=0.321\n",
            "('drug', 'storage_and_handling', 'storage_and_handling'): AUC=0.5366, P=0.500, R=0.186, F1=0.271\n",
            "('drug', 'purpose', 'brand'): AUC=0.6067, P=0.583, R=0.380, F1=0.460\n",
            "('drug', 'do_not_use', 'do_not_use'): AUC=0.5139, P=0.496, R=0.300, F1=0.374\n",
            "('drug', 'ask_doctor', 'ask_doctor'): AUC=0.4582, P=0.431, R=0.148, F1=0.220\n",
            "('drug', 'inactive_ingredient', 'inactive_ingredient'): AUC=0.5319, P=0.525, R=0.578, F1=0.550\n",
            "('drug', 'inactive_ingredient', 'brand'): AUC=0.5774, P=0.481, R=0.373, F1=0.420\n",
            "('brand', 'warnings', 'drug'): AUC=0.5585, P=0.548, R=0.350, F1=0.427\n",
            "('inactive_ingredient', 'purpose', 'brand'): AUC=1.0000, P=0.000, R=0.000, F1=0.000\n",
            "('inactive_ingredient', 'indications_and_usage', 'indications_and_usage'): AUC=0.3125, P=0.250, R=0.250, F1=0.250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('inactive_ingredient', 'warnings', 'warnings'): AUC=0.7200, P=0.571, R=0.800, F1=0.667\n",
            "('inactive_ingredient', 'keep_out_of_reach_of_children', 'keep_out_of_reach_of_children'): AUC=0.3333, P=0.000, R=0.000, F1=0.000\n",
            "('inactive_ingredient', 'dosage_and_administration', 'dosage_and_administration'): AUC=0.5000, P=0.500, R=0.250, F1=0.333\n",
            "('brand', 'warnings', 'warnings'): AUC=0.4994, P=0.493, R=0.555, F1=0.522\n",
            "('drug', 'stop_use', 'stop_use'): AUC=0.5074, P=0.537, R=0.329, F1=0.408\n",
            "('drug', 'stop_use', 'warnings'): AUC=0.6341, P=0.583, R=0.667, F1=0.622\n",
            "('drug', 'do_not_use', 'warnings'): AUC=0.3294, P=0.290, R=0.209, F1=0.243\n",
            "('drug', 'keep_out_of_reach_of_children', 'warnings'): AUC=0.6167, P=0.556, R=0.653, F1=0.601\n",
            "('brand', 'active_ingredient', 'brand'): AUC=0.2500, P=0.333, R=0.500, F1=0.400\n",
            "('brand', 'active_ingredient', 'active_ingredient'): AUC=0.5917, P=0.500, R=0.652, F1=0.566\n",
            "('brand', 'purpose', 'purpose'): AUC=0.5625, P=0.529, R=0.750, F1=0.621\n",
            "('brand', 'indications_and_usage', 'indications_and_usage'): AUC=0.6633, P=0.577, R=0.536, F1=0.556\n",
            "('brand', 'dosage_and_administration', 'dosage_and_administration'): AUC=0.4187, P=0.449, R=0.468, F1=0.458\n",
            "('brand', 'warnings', 'keep_out_of_reach_of_children'): AUC=1.0000, P=1.000, R=1.000, F1=1.000\n",
            "('drug', 'warnings', 'stop_use'): AUC=0.3152, P=0.375, R=0.143, F1=0.207\n",
            "('drug', 'storage_and_handling', 'warnings'): AUC=0.5625, P=0.400, R=0.250, F1=0.308\n",
            "('drug', 'purpose', 'indications_and_usage'): AUC=0.5024, P=0.500, R=0.520, F1=0.510\n",
            "('drug', 'active_ingredient', 'brand'): AUC=0.6141, P=0.625, R=0.438, F1=0.515\n",
            "('inactive_ingredient', 'purpose', 'purpose'): AUC=0.2500, P=0.500, R=0.500, F1=0.500\n",
            "('drug', 'dosage_and_administration', 'indications_and_usage'): AUC=0.4625, P=0.481, R=0.650, F1=0.553\n",
            "('drug', 'inactive_ingredient', 'drug'): AUC=0.1111, P=0.333, R=0.333, F1=0.333\n",
            "('drug', 'inactive_ingredient', 'warnings'): AUC=0.4028, P=0.444, R=0.333, F1=0.381\n",
            "('warnings', 'active_ingredient', 'active_ingredient'): AUC=0.5104, P=0.412, R=0.583, F1=0.483\n",
            "('warnings', 'purpose', 'purpose'): AUC=0.3200, P=0.375, R=0.600, F1=0.462\n",
            "('warnings', 'indications_and_usage', 'indications_and_usage'): AUC=1.0000, P=1.000, R=0.750, F1=0.857\n",
            "('warnings', 'warnings', 'warnings'): AUC=0.7500, P=0.667, R=1.000, F1=0.800\n",
            "('warnings', 'stop_use', 'stop_use'): AUC=1.0000, P=0.000, R=0.000, F1=0.000\n",
            "('warnings', 'dosage_and_administration', 'dosage_and_administration'): AUC=0.4800, P=0.500, R=0.400, F1=0.444\n",
            "('warnings', 'keep_out_of_reach_of_children', 'keep_out_of_reach_of_children'): AUC=0.7500, P=1.000, R=0.500, F1=0.667\n",
            "('warnings', 'storage_and_handling', 'storage_and_handling'): AUC=0.7500, P=0.667, R=1.000, F1=0.800\n",
            "('drug', 'indications_and_usage', 'purpose'): AUC=0.4481, P=0.393, R=0.333, F1=0.361\n",
            "('drug', 'ask_doctor_or_pharmacist', 'ask_doctor_or_pharmacist'): AUC=0.5168, P=0.478, R=0.134, F1=0.210\n",
            "('drug', 'warnings', 'pregnancy_or_breast_feeding'): AUC=0.5022, P=0.483, R=0.350, F1=0.406\n",
            "('drug', 'indications_and_usage', 'brand'): AUC=0.4439, P=0.429, R=0.214, F1=0.286\n",
            "('brand', 'do_not_use', 'do_not_use'): AUC=0.8163, P=0.667, R=0.857, F1=0.750\n",
            "('brand', 'ask_doctor', 'ask_doctor'): AUC=0.3281, P=0.429, R=0.750, F1=0.545\n",
            "('brand', 'ask_doctor_or_pharmacist', 'ask_doctor_or_pharmacist'): AUC=0.2222, P=0.333, R=0.333, F1=0.333\n",
            "('brand', 'stop_use', 'stop_use'): AUC=0.4545, P=0.500, R=0.545, F1=0.522\n",
            "('brand', 'keep_out_of_reach_of_children', 'keep_out_of_reach_of_children'): AUC=0.6116, P=0.538, R=0.636, F1=0.583\n",
            "('brand', 'keep_out_of_reach_of_children', 'warnings'): AUC=1.0000, P=0.667, R=1.000, F1=0.800\n",
            "('drug', 'warnings', 'storage_and_handling'): AUC=0.4852, P=0.556, R=0.385, F1=0.455\n",
            "('drug', 'warnings', 'dosage_and_administration'): AUC=0.3320, P=0.350, R=0.438, F1=0.389\n",
            "('drug', 'active_ingredient', 'warnings'): AUC=0.5187, P=0.581, R=0.474, F1=0.522\n",
            "('brand', 'warnings', 'brand'): AUC=0.4623, P=0.471, R=0.506, F1=0.488\n",
            "('drug', 'warnings', 'active_ingredient'): AUC=0.5692, P=0.571, R=0.353, F1=0.436\n",
            "('drug', 'pregnancy_or_breast_feeding', 'warnings'): AUC=0.5329, P=0.556, R=0.588, F1=0.571\n",
            "('warnings', 'keep_out_of_reach_of_children', 'warnings'): AUC=0.0000, P=0.000, R=0.000, F1=0.000\n",
            "('brand', 'purpose', 'brand'): AUC=0.4000, P=0.429, R=0.600, F1=0.500\n",
            "('drug', 'dosage_and_administration', 'warnings'): AUC=0.5556, P=0.500, R=0.333, F1=0.400\n",
            "('drug', 'indications_and_usage', 'dosage_and_administration'): AUC=0.4142, P=0.500, R=0.308, F1=0.381\n",
            "('drug', 'active_ingredient', 'inactive_ingredient'): AUC=0.6049, P=0.545, R=0.667, F1=0.600\n",
            "('brand', 'warnings', 'inactive_ingredient'): AUC=0.4806, P=0.459, R=0.321, F1=0.378\n",
            "('drug', 'warnings', 'brand'): AUC=0.6122, P=0.400, R=0.286, F1=0.333\n",
            "('drug', 'active_ingredient', 'drug'): AUC=0.6250, P=0.500, R=0.500, F1=0.500\n",
            "('active_ingredient', 'active_ingredient', 'active_ingredient'): AUC=0.7344, P=0.462, R=0.750, F1=0.571\n",
            "('active_ingredient', 'purpose', 'purpose'): AUC=0.6250, P=0.667, R=1.000, F1=0.800\n",
            "('active_ingredient', 'do_not_use', 'do_not_use'): AUC=0.7500, P=0.500, R=1.000, F1=0.667\n",
            "('active_ingredient', 'keep_out_of_reach_of_children', 'keep_out_of_reach_of_children'): AUC=0.5000, P=0.667, R=1.000, F1=0.800\n",
            "('active_ingredient', 'warnings', 'warnings'): AUC=0.5833, P=0.571, R=0.667, F1=0.615\n",
            "('active_ingredient', 'stop_use', 'stop_use'): AUC=0.7500, P=0.500, R=1.000, F1=0.667\n",
            "('active_ingredient', 'inactive_ingredient', 'inactive_ingredient'): AUC=0.6667, P=0.600, R=1.000, F1=0.750\n",
            "('inactive_ingredient', 'stop_use', 'stop_use'): AUC=1.0000, P=0.500, R=1.000, F1=0.667\n",
            "('inactive_ingredient', 'storage_and_handling', 'storage_and_handling'): AUC=0.0000, P=0.000, R=0.000, F1=0.000\n",
            "('inactive_ingredient', 'active_ingredient', 'active_ingredient'): AUC=0.4400, P=0.667, R=0.400, F1=0.500\n",
            "('inactive_ingredient', 'inactive_ingredient', 'inactive_ingredient'): AUC=0.2222, P=0.375, R=0.500, F1=0.429\n",
            "('brand', 'warnings', 'pregnancy_or_breast_feeding'): AUC=1.0000, P=1.000, R=1.000, F1=1.000\n",
            "('drug', 'overdose_warning', 'warnings'): AUC=0.6400, P=0.667, R=0.800, F1=0.727\n",
            "('drug', 'indications_and_usage', 'warnings'): AUC=0.6667, P=0.667, R=0.667, F1=0.667\n",
            "('drug', 'ask_doctor', 'warnings'): AUC=0.5906, P=0.543, R=0.679, F1=0.603\n",
            "('drug', 'stop_use', 'do_not_use'): AUC=0.0000, P=0.000, R=0.000, F1=0.000\n",
            "('drug', 'overdose_warning', 'overdose_warning'): AUC=0.7347, P=0.667, R=0.286, F1=0.400\n",
            "('drug', 'warnings', 'ask_doctor'): AUC=0.6281, P=0.400, R=0.182, F1=0.250\n",
            "('drug', 'ask_doctor_or_pharmacist', 'pregnancy_or_breast_feeding'): AUC=1.0000, P=0.667, R=1.000, F1=0.800\n",
            "('active_ingredient', 'indications_and_usage', 'indications_and_usage'): AUC=0.4375, P=0.333, R=0.250, F1=0.286\n",
            "('active_ingredient', 'dosage_and_administration', 'dosage_and_administration'): AUC=0.7600, P=0.667, R=0.800, F1=0.727\n",
            "('active_ingredient', 'pregnancy_or_breast_feeding', 'pregnancy_or_breast_feeding'): AUC=1.0000, P=1.000, R=1.000, F1=1.000\n",
            "('brand', 'inactive_ingredient', 'inactive_ingredient'): AUC=0.6364, P=0.600, R=0.545, F1=0.571\n",
            "('brand', 'inactive_ingredient', 'brand'): AUC=0.7500, P=0.500, R=0.500, F1=0.500\n",
            "('drug', 'warnings', 'do_not_use'): AUC=0.6514, P=0.688, R=0.355, F1=0.468\n",
            "('drug', 'purpose', 'drug'): AUC=0.5000, P=0.000, R=0.000, F1=0.000\n",
            "('drug', 'ask_doctor', 'indications_and_usage'): AUC=0.0000, P=0.333, R=0.500, F1=0.400\n",
            "('drug', 'ask_doctor', 'stop_use'): AUC=0.5300, P=0.636, R=0.700, F1=0.667\n",
            "('drug', 'ask_doctor_or_pharmacist', 'warnings'): AUC=0.3750, P=0.500, R=0.500, F1=0.500\n",
            "('brand', 'pregnancy_or_breast_feeding', 'pregnancy_or_breast_feeding'): AUC=0.0000, P=0.000, R=0.000, F1=0.000\n",
            "('purpose', 'warnings', 'warnings'): AUC=0.0000, P=0.000, R=0.000, F1=0.000\n",
            "('purpose', 'keep_out_of_reach_of_children', 'keep_out_of_reach_of_children'): AUC=0.0000, P=0.000, R=0.000, F1=0.000\n",
            "('drug', 'ask_doctor', 'brand'): AUC=0.8148, P=0.778, R=0.778, F1=0.778\n",
            "('drug', 'dosage_and_administration', 'do_not_use'): AUC=0.4444, P=0.500, R=0.667, F1=0.571\n",
            "('drug', 'drug_interactions', 'drug_interactions'): AUC=0.6800, P=1.000, R=0.200, F1=0.333\n",
            "('drug', 'ask_doctor', 'ask_doctor_or_pharmacist'): AUC=0.2500, P=0.000, R=0.000, F1=0.000\n",
            "('drug', 'indications_and_usage', 'stop_use'): AUC=0.5625, P=0.667, R=0.500, F1=0.571\n",
            "('drug', 'keep_out_of_reach_of_children', 'overdose_warning'): AUC=0.4444, P=0.000, R=0.000, F1=0.000\n",
            "('drug', 'warnings', 'ask_doctor_or_pharmacist'): AUC=0.5625, P=0.000, R=0.000, F1=0.000\n",
            "('drug', 'ask_doctor_or_pharmacist', 'ask_doctor'): AUC=0.3469, P=0.000, R=0.000, F1=0.000\n",
            "('active_ingredient', 'warnings', 'pregnancy_or_breast_feeding'): AUC=1.0000, P=1.000, R=1.000, F1=1.000\n",
            "('active_ingredient', 'warnings', 'keep_out_of_reach_of_children'): AUC=1.0000, P=0.667, R=1.000, F1=0.800\n",
            "('drug', 'drug_interactions', 'active_ingredient'): AUC=1.0000, P=0.667, R=1.000, F1=0.800\n",
            "('drug', 'warnings', 'inactive_ingredient'): AUC=0.6800, P=0.556, R=1.000, F1=0.714\n",
            "('brand', 'warnings', 'active_ingredient'): AUC=0.3700, P=0.455, R=0.500, F1=0.476\n",
            "('drug', 'indications_and_usage', 'do_not_use'): AUC=0.5000, P=0.500, R=0.500, F1=0.500\n",
            "('drug', 'ask_doctor', 'pregnancy_or_breast_feeding'): AUC=1.0000, P=0.000, R=0.000, F1=0.000\n",
            "('drug', 'overdose_warning', 'keep_out_of_reach_of_children'): AUC=1.0000, P=1.000, R=1.000, F1=1.000\n",
            "('brand', 'indications_and_usage', 'purpose'): AUC=0.5000, P=0.333, R=0.500, F1=0.400\n",
            "('brand', 'warnings', 'do_not_use'): AUC=1.0000, P=1.000, R=1.000, F1=1.000\n",
            "('brand', 'storage_and_handling', 'storage_and_handling'): AUC=0.1111, P=0.286, R=0.333, F1=0.308\n",
            "('drug', 'pregnancy_or_breast_feeding', 'ask_doctor_or_pharmacist'): AUC=0.3333, P=0.000, R=0.000, F1=0.000\n",
            "('drug', 'warnings', 'overdose_warning'): AUC=0.5000, P=0.000, R=0.000, F1=0.000\n",
            "('drug', 'do_not_use', 'keep_out_of_reach_of_children'): AUC=0.8889, P=0.000, R=0.000, F1=0.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('drug', 'dosage_and_administration', 'brand'): AUC=1.0000, P=1.000, R=1.000, F1=1.000\n",
            "('drug', 'dosage_and_administration', 'storage_and_handling'): AUC=0.1111, P=0.000, R=0.000, F1=0.000\n",
            "('drug', 'active_ingredient', 'drug_interactions'): AUC=1.0000, P=0.000, R=0.000, F1=0.000\n",
            "('brand', 'purpose', 'indications_and_usage'): AUC=1.0000, P=1.000, R=1.000, F1=1.000\n",
            "('drug', 'ask_doctor', 'purpose'): AUC=0.5000, P=0.500, R=1.000, F1=0.667\n",
            "('drug', 'stop_use', 'ask_doctor'): AUC=0.5200, P=0.000, R=0.000, F1=0.000\n",
            "('drug', 'keep_out_of_reach_of_children', 'storage_and_handling'): AUC=0.4400, P=0.500, R=0.400, F1=0.444\n",
            "('drug', 'active_ingredient', 'purpose'): AUC=0.7778, P=1.000, R=0.333, F1=0.500\n",
            "('drug', 'keep_out_of_reach_of_children', 'pregnancy_or_breast_feeding'): AUC=0.2500, P=0.500, R=0.500, F1=0.500\n",
            "('drug', 'storage_and_handling', 'dosage_and_administration'): AUC=0.4444, P=0.667, R=0.667, F1=0.667\n",
            "('drug', 'do_not_use', 'ask_doctor_or_pharmacist'): AUC=0.0000, P=0.000, R=0.000, F1=0.000\n",
            "('drug', 'stop_use', 'purpose'): AUC=0.7500, P=0.667, R=1.000, F1=0.800\n",
            "('drug', 'stop_use', 'indications_and_usage'): AUC=0.3600, P=0.500, R=1.000, F1=0.667\n",
            "('drug', 'inactive_ingredient', 'active_ingredient'): AUC=0.5900, P=0.800, R=0.400, F1=0.533\n",
            "('drug', 'stop_use', 'brand'): AUC=1.0000, P=0.000, R=0.000, F1=0.000\n",
            "('warnings', 'inactive_ingredient', 'inactive_ingredient'): AUC=0.0000, P=0.333, R=0.500, F1=0.400\n",
            "('drug', 'do_not_use', 'ask_doctor'): AUC=0.3333, P=0.333, R=0.333, F1=0.333\n",
            "('brand', 'do_not_use', 'warnings'): AUC=0.5000, P=0.667, R=1.000, F1=0.800\n",
            "('drug', 'stop_use', 'keep_out_of_reach_of_children'): AUC=1.0000, P=1.000, R=1.000, F1=1.000\n",
            "('drug', 'warnings', 'indications_and_usage'): AUC=0.3750, P=0.429, R=0.750, F1=0.545\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('drug', 'warnings', 'purpose'): AUC=1.0000, P=0.667, R=1.000, F1=0.800\n",
            "('drug', 'ask_doctor', 'do_not_use'): AUC=0.0000, P=0.000, R=0.000, F1=0.000\n",
            "('drug', 'purpose', 'dosage_and_administration'): AUC=0.0000, P=0.000, R=0.000, F1=0.000\n",
            "('drug', 'purpose', 'active_ingredient'): AUC=0.5000, P=0.500, R=0.500, F1=0.500\n",
            "('drug', 'ask_doctor', 'dosage_and_administration'): AUC=0.7500, P=0.500, R=0.500, F1=0.500\n",
            "('drug', 'dosage_and_administration', 'purpose'): AUC=0.7500, P=0.500, R=0.500, F1=0.500\n",
            "('drug', 'storage_and_handling', 'keep_out_of_reach_of_children'): AUC=0.4444, P=0.000, R=0.000, F1=0.000\n",
            "('brand', 'indications_and_usage', 'dosage_and_administration'): AUC=0.7500, P=0.667, R=1.000, F1=0.800\n",
            "('active_ingredient', 'do_not_use', 'warnings'): AUC=1.0000, P=0.500, R=1.000, F1=0.667\n",
            "('drug', 'active_ingredient', 'dosage_and_administration'): AUC=1.0000, P=1.000, R=1.000, F1=1.000\n",
            "('drug', 'indications_and_usage', 'active_ingredient'): AUC=0.0000, P=0.333, R=0.500, F1=0.400\n",
            "('drug', 'indications_and_usage', 'storage_and_handling'): AUC=0.0000, P=0.000, R=0.000, F1=0.000\n",
            "('brand', 'warnings', 'purpose'): AUC=0.2500, P=0.000, R=0.000, F1=0.000\n",
            "\n",
            "üåç Overall Performance (filtered negatives):\n",
            "Overall AUC = 0.5178\n",
            "Overall Precision = 0.514\n",
            "Overall Recall = 0.382\n",
            "Overall F1 Score = 0.439\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === GraphML ‚Üí R-GCN (NeighborLoader + AMP + batched inference) ===\n",
        "# Fixes:\n",
        "#  - DistMult scoring (relation-aware) in train + eval\n",
        "#  - Typed negatives sampled *within the batch* (local), avoiding drop\n",
        "#  - zero_division=0 to silence undefined metric warnings\n",
        "\n",
        "import os, gc, random\n",
        "from collections import defaultdict\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from torch_geometric.nn import RGCNConv\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.loader import NeighborLoader\n",
        "from sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score\n",
        "import networkx as nx\n",
        "\n",
        "# ----------------------------\n",
        "# 0) Repro + Device\n",
        "# ----------------------------\n",
        "SEED = 42\n",
        "random.seed(SEED); np.random.seed(SEED)\n",
        "torch.manual_seed(SEED); torch.cuda.manual_seed_all(SEED)\n",
        "os.environ.setdefault(\"PYTORCH_CUDA_ALLOC_CONF\", \"expandable_segments:True\")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "gc.collect()\n",
        "if device.type == \"cuda\":\n",
        "    torch.cuda.empty_cache()\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# ----------------------------\n",
        "# 1) Load GraphML + normalize attrs\n",
        "# ----------------------------\n",
        "graph_path = \"/content/drive/MyDrive/drug_data_kg_rebuilt_normalized.graphml\"\n",
        "assert os.path.exists(graph_path), f\"Path does not exist: {graph_path}\"\n",
        "print(f\"üì• Loading GraphML from: {graph_path}\")\n",
        "\n",
        "G0 = nx.read_graphml(graph_path)\n",
        "G = nx.MultiDiGraph()\n",
        "G.add_nodes_from(G0.nodes(data=True))\n",
        "if G0.is_multigraph():\n",
        "    for u,v,k,d in G0.edges(keys=True, data=True):\n",
        "        G.add_edge(u,v,key=k, **(d or {}))\n",
        "else:\n",
        "    for u,v,d in G0.edges(data=True):\n",
        "        G.add_edge(u,v, **(d or {}))\n",
        "\n",
        "for n,data in G.nodes(data=True):\n",
        "    if \"node_type\" not in data:\n",
        "        data[\"node_type\"] = data.get(\"type\", data.get(\"category\", data.get(\"kind\",\"unknown\")))\n",
        "for u,v,attr in G.edges(data=True):\n",
        "    if \"relation\" not in attr:\n",
        "        attr[\"relation\"] = attr.get(\"relationship\", attr.get(\"type\", attr.get(\"label\",\"unknown\")))\n",
        "\n",
        "print(f\"‚úÖ Loaded graph with {len(G.nodes)} nodes and {len(G.edges)} edges.\")\n",
        "\n",
        "# ----------------------------\n",
        "# 2) Typed remap + splits\n",
        "# ----------------------------\n",
        "node_type_map = defaultdict(list)\n",
        "node_id_map = {}\n",
        "for nid,data in G.nodes(data=True):\n",
        "    ntype = data.get(\"node_type\",\"unknown\")\n",
        "    idx = len(node_type_map[ntype])\n",
        "    node_type_map[ntype].append(nid)\n",
        "    node_id_map[nid] = (ntype, idx)\n",
        "\n",
        "edge_type_map = defaultdict(list)  # (src_type, rel, dst_type) -> [(src_local, dst_local)]\n",
        "for s,t,attr in G.edges(data=True):\n",
        "    if s not in node_id_map or t not in node_id_map: continue\n",
        "    rel = attr.get(\"relation\",\"unknown\")\n",
        "    s_t,s_i = node_id_map[s]\n",
        "    t_t,t_i = node_id_map[t]\n",
        "    edge_type_map[(s_t, rel, t_t)].append((s_i,t_i))\n",
        "\n",
        "print(f\"‚úÖ Node types: {list(node_type_map.keys())}\")\n",
        "print(f\"‚úÖ Total edge types: {len(edge_type_map)}\")\n",
        "\n",
        "# Global ids per (type, local)\n",
        "type_offsets, global_id_map = {}, {}\n",
        "offset = 0\n",
        "for ntype, nodes in node_type_map.items():\n",
        "    type_offsets[ntype] = offset\n",
        "    for i in range(len(nodes)):\n",
        "        global_id_map[(ntype,i)] = offset + i\n",
        "    offset += len(nodes)\n",
        "num_nodes = offset\n",
        "\n",
        "edge_type_keys = list(edge_type_map.keys())         # rel_id -> (src_type, rel, dst_type)\n",
        "rel2id = {k:i for i,k in enumerate(edge_type_keys)}\n",
        "num_relations = len(edge_type_keys)\n",
        "\n",
        "all_src, all_dst, all_rel = [], [], []\n",
        "edge_type_splits = {}\n",
        "\n",
        "for etype, pairs in edge_type_map.items():\n",
        "    s_type,_, t_type = etype\n",
        "    if len(pairs) < 5:  # keep only relations with minimum support\n",
        "        continue\n",
        "    perm = torch.randperm(len(pairs))\n",
        "    n_tr = int(0.8*len(pairs)); n_va = int(0.1*len(pairs))\n",
        "    tr = [pairs[i] for i in perm[:n_tr]]\n",
        "    va = [pairs[i] for i in perm[n_tr:n_tr+n_va]]\n",
        "    te = [pairs[i] for i in perm[n_tr+n_va:]]\n",
        "\n",
        "    r = rel2id[etype]\n",
        "    for s_l, t_l in tr:\n",
        "        all_src.append(type_offsets[s_type] + s_l)\n",
        "        all_dst.append(type_offsets[t_type] + t_l)\n",
        "        all_rel.append(r)\n",
        "\n",
        "    edge_type_splits[etype] = {\n",
        "        \"val\": torch.tensor([[type_offsets[s_type]+s for s,_ in va],\n",
        "                             [type_offsets[t_type]+t for _,t in va]], dtype=torch.long),\n",
        "        \"test\": torch.tensor([[type_offsets[s_type]+s for s,_ in te],\n",
        "                              [type_offsets[t_type]+t for _,t in te]], dtype=torch.long),\n",
        "    }\n",
        "\n",
        "edge_index_cpu = torch.tensor([all_src, all_dst], dtype=torch.long)\n",
        "edge_type_cpu  = torch.tensor(all_rel, dtype=torch.long)\n",
        "print(f\"Homogeneous nodes: {num_nodes}, edges used for training: {edge_index_cpu.size(1)}\")\n",
        "\n",
        "# For quick type lookup by GLOBAL id (used for local typed negatives)\n",
        "type_names = sorted(node_type_map.keys())\n",
        "type2id = {t:i for i,t in enumerate(type_names)}\n",
        "global_node_type_id = torch.empty(num_nodes, dtype=torch.long)\n",
        "for tname, nodes in node_type_map.items():\n",
        "    t_id = type2id[tname]\n",
        "    base = type_offsets[tname]\n",
        "    n = len(nodes)\n",
        "    global_node_type_id[base:base+n] = t_id\n",
        "\n",
        "# Existing edges per relation (LOCAL to each (src_type,rel,dst_type))\n",
        "existing_edges_per_rel = {etype: set(pairs) for etype,pairs in edge_type_map.items()}\n",
        "def relid_to_etype(rel_id:int):\n",
        "    return edge_type_keys[rel_id]\n",
        "\n",
        "# ----------------------------\n",
        "# 3) PyG Data + NeighborLoader\n",
        "# ----------------------------\n",
        "data_pyg = Data(num_nodes=num_nodes, edge_index=edge_index_cpu, edge_type=edge_type_cpu)\n",
        "\n",
        "NUM_NEIGHBORS = [15, 10]\n",
        "NBATCH_SIZE   = 4096\n",
        "NUM_WORKERS   = 2  # quiets the OS warning\n",
        "\n",
        "train_src_unique = torch.unique(edge_index_cpu[0])\n",
        "train_loader = NeighborLoader(\n",
        "    data_pyg,\n",
        "    num_neighbors=NUM_NEIGHBORS,\n",
        "    batch_size=NBATCH_SIZE,\n",
        "    input_nodes=train_src_unique,\n",
        "    shuffle=True,\n",
        "    num_workers=NUM_WORKERS\n",
        ")\n",
        "\n",
        "# ----------------------------\n",
        "# 4) Model (DistMult) + helpers\n",
        "# ----------------------------\n",
        "class RGCN(nn.Module):\n",
        "    def __init__(self, num_nodes, num_relations, emb_dim=64, hidden_dim=128, out_dim=32, num_bases=30):\n",
        "        super().__init__()\n",
        "        self.emb = nn.Embedding(num_nodes, emb_dim)\n",
        "        self.conv1 = RGCNConv(emb_dim, hidden_dim, num_relations=num_relations, num_bases=num_bases)\n",
        "        self.conv2 = RGCNConv(hidden_dim, out_dim, num_relations=num_relations, num_bases=num_bases)\n",
        "        self.rel_emb = nn.Embedding(num_relations, out_dim)\n",
        "\n",
        "        nn.init.xavier_uniform_(self.emb.weight)\n",
        "        nn.init.xavier_uniform_(self.rel_emb.weight)\n",
        "\n",
        "    def forward(self, n_id, edge_index, edge_type):\n",
        "        # n_id: global ids ordered as local nodes in the subgraph\n",
        "        x = self.emb(n_id)\n",
        "        x = self.conv1(x, edge_index, edge_type).relu_()\n",
        "        x = self.conv2(x, edge_index, edge_type)\n",
        "        return x  # local node embeddings\n",
        "\n",
        "    def score(self, h, r, t):\n",
        "        # DistMult (logits)\n",
        "        return (h * r * t).sum(dim=-1)\n",
        "\n",
        "def distmult_sigmoid_scores(z, rel_emb, eidx, rel_ids):\n",
        "    h = z[eidx[0]]; t = z[eidx[1]]\n",
        "    r = rel_emb(rel_ids)\n",
        "    return (h * r * t).sum(dim=-1).sigmoid()\n",
        "\n",
        "# ----------------------------\n",
        "# 5) Local (in-batch) typed negatives\n",
        "# ----------------------------\n",
        "def build_local_type_pools(n_id_device):\n",
        "    \"\"\"Map node_type_id -> list of LOCAL indices present in this batch.\"\"\"\n",
        "    g_types = global_node_type_id.to(n_id_device.device, non_blocking=True)[n_id_device]\n",
        "    pools = defaultdict(list)\n",
        "    for local_idx, t in enumerate(g_types.tolist()):\n",
        "        pools[t].append(local_idx)\n",
        "    for k in list(pools.keys()):\n",
        "        pools[k] = torch.tensor(pools[k], dtype=torch.long, device=n_id_device.device)\n",
        "    return pools\n",
        "\n",
        "def sample_neg_local(pos_local_eidx, rel_ids_local, n_id, pools, k_neg=1):\n",
        "    \"\"\"\n",
        "    Typed negatives *within* the sampled subgraph.\n",
        "    pos_local_eidx: (2,P) local indices\n",
        "    rel_ids_local:  (P,)   relation ids (global rel ids)\n",
        "    pools: dict[type_id] -> local node index tensor present in batch\n",
        "    \"\"\"\n",
        "    if pos_local_eidx.numel() == 0:  # empty\n",
        "        return torch.empty((2,0), dtype=torch.long, device=pos_local_eidx.device)\n",
        "\n",
        "    P = pos_local_eidx.size(1)\n",
        "    neg_src, neg_dst = [], []\n",
        "    for i in range(P):\n",
        "        s_l = int(pos_local_eidx[0, i])\n",
        "        d_l = int(pos_local_eidx[1, i])\n",
        "        r_id = int(rel_ids_local[i])\n",
        "        s_type, _, d_type = relid_to_etype(r_id)\n",
        "        s_tid = type2id[s_type]; d_tid = type2id[d_type]\n",
        "\n",
        "        # pick from local pools ‚Äî if missing (rare), fall back to uniform local sampling\n",
        "        s_pool = pools.get(s_tid, None)\n",
        "        d_pool = pools.get(d_tid, None)\n",
        "        if s_pool is None or s_pool.numel() == 0:\n",
        "            s_pool = torch.arange(n_id.size(0), device=n_id.device)\n",
        "        if d_pool is None or d_pool.numel() == 0:\n",
        "            d_pool = torch.arange(n_id.size(0), device=n_id.device)\n",
        "\n",
        "        for _ in range(max(1, k_neg)):\n",
        "            if random.random() < 0.5:\n",
        "                # corrupt head\n",
        "                new_s_l = s_pool[torch.randint(0, s_pool.numel(), (1,))].item()\n",
        "                neg_src.append(new_s_l); neg_dst.append(d_l)\n",
        "            else:\n",
        "                # corrupt tail\n",
        "                new_d_l = d_pool[torch.randint(0, d_pool.numel(), (1,))].item()\n",
        "                neg_src.append(s_l); neg_dst.append(new_d_l)\n",
        "\n",
        "    if len(neg_src) == 0:\n",
        "        return torch.empty((2,0), dtype=torch.long, device=n_id.device)\n",
        "    return torch.stack([torch.tensor(neg_src, device=n_id.device),\n",
        "                        torch.tensor(neg_dst, device=n_id.device)], dim=0)\n",
        "\n",
        "# ----------------------------\n",
        "# 6) Train with NeighborLoader + AMP\n",
        "# ----------------------------\n",
        "EPOCHS = 30\n",
        "LR     = 1e-3\n",
        "K_NEG  = 1\n",
        "\n",
        "model = RGCN(num_nodes, num_relations, emb_dim=64, hidden_dim=128, out_dim=32, num_bases=30).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=1e-5)\n",
        "scaler = GradScaler(enabled=(device.type == \"cuda\"))\n",
        "\n",
        "# Global training edges (for picking positives per batch)\n",
        "src_glob_all = edge_index_cpu[0].to(device)\n",
        "dst_glob_all = edge_index_cpu[1].to(device)\n",
        "rels_all     = edge_type_cpu.to(device)\n",
        "\n",
        "print(\"\\nüîÅ Training with NeighborLoader mini-batches + AMP ...\")\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "    model.train()\n",
        "    epoch_loss = 0.0\n",
        "    seen_pos = 0\n",
        "\n",
        "    for batch in train_loader:\n",
        "        batch = batch.to(device, non_blocking=True)\n",
        "        n_id = batch.n_id  # global ids in this subgraph (device tensor)\n",
        "\n",
        "        # global->local mapping\n",
        "        global2local = -torch.ones(num_nodes, dtype=torch.long, device=device)\n",
        "        global2local[n_id] = torch.arange(n_id.size(0), device=device)\n",
        "\n",
        "        # positives inside batch\n",
        "        in_src = global2local[src_glob_all]\n",
        "        in_dst = global2local[dst_glob_all]\n",
        "        mask = (in_src >= 0) & (in_dst >= 0)\n",
        "        pos_idx = torch.nonzero(mask, as_tuple=False).view(-1)\n",
        "        if pos_idx.numel() == 0:\n",
        "            del batch, n_id, global2local, in_src, in_dst, mask, pos_idx\n",
        "            if device.type == \"cuda\": torch.cuda.empty_cache()\n",
        "            continue\n",
        "\n",
        "        MAX_POS_PER_BATCH = 8192\n",
        "        if pos_idx.numel() > MAX_POS_PER_BATCH:\n",
        "            pos_idx = pos_idx[torch.randperm(pos_idx.numel(), device=device)[:MAX_POS_PER_BATCH]]\n",
        "\n",
        "        pos_local = torch.stack([in_src[pos_idx], in_dst[pos_idx]], dim=0)\n",
        "        rel_ids_local = rels_all[pos_idx]\n",
        "\n",
        "        # local typed pools for negatives\n",
        "        pools = build_local_type_pools(n_id)\n",
        "\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        with autocast(enabled=(device.type == \"cuda\")):\n",
        "            z = model(n_id, batch.edge_index, batch.edge_type)\n",
        "\n",
        "            # DistMult positives\n",
        "            pos_h = z[pos_local[0]]; pos_t = z[pos_local[1]]\n",
        "            pos_r = model.rel_emb(rel_ids_local)\n",
        "            pos_logits = model.score(pos_h, pos_r, pos_t)\n",
        "\n",
        "            # local typed negatives\n",
        "            neg_local = sample_neg_local(pos_local, rel_ids_local, n_id, pools, k_neg=K_NEG)\n",
        "            if neg_local.size(1) > 0:\n",
        "                neg_h = z[neg_local[0]]; neg_t = z[neg_local[1]]\n",
        "                # repeat relation ids for negs\n",
        "                neg_r = model.rel_emb(rel_ids_local.repeat_interleave(K_NEG))\n",
        "                neg_logits = model.score(neg_h, neg_r, neg_t)\n",
        "                loss = (F.binary_cross_entropy_with_logits(pos_logits, torch.ones_like(pos_logits)) +\n",
        "                        F.binary_cross_entropy_with_logits(neg_logits, torch.zeros_like(neg_logits)))\n",
        "            else:\n",
        "                loss = F.binary_cross_entropy_with_logits(pos_logits, torch.ones_like(pos_logits))\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        epoch_loss += float(loss.detach().cpu())\n",
        "        seen_pos += pos_local.size(1)\n",
        "\n",
        "        # cleanup\n",
        "        del batch, n_id, global2local, in_src, in_dst, mask, pos_idx\n",
        "        del pos_local, rel_ids_local, pools, z, pos_h, pos_t, pos_r, pos_logits\n",
        "        if 'neg_local' in locals(): del neg_local, neg_h, neg_t, neg_r, neg_logits\n",
        "        if device.type == \"cuda\": torch.cuda.empty_cache()\n",
        "\n",
        "    print(f\"Epoch {epoch:02d} | Loss: {epoch_loss:.4f} | Seen pos edges: {seen_pos}\")\n",
        "\n",
        "# ----------------------------\n",
        "# 7) Batched inference (DistMult-ready embeddings)\n",
        "# ----------------------------\n",
        "print(\"\\nüîé Computing full-node embeddings (batched inference) ...\")\n",
        "model.eval()\n",
        "OUT_DIM = 32\n",
        "z_all = torch.empty((num_nodes, OUT_DIM), dtype=torch.float32, device=device)\n",
        "\n",
        "INFER_BATCH = 16384\n",
        "infer_loader = NeighborLoader(\n",
        "    Data(num_nodes=num_nodes, edge_index=edge_index_cpu, edge_type=edge_type_cpu),\n",
        "    num_neighbors=[-1, -1],\n",
        "    batch_size=INFER_BATCH,\n",
        "    input_nodes=torch.arange(num_nodes),\n",
        "    shuffle=False,\n",
        "    num_workers=NUM_WORKERS\n",
        ")\n",
        "with torch.no_grad():\n",
        "    for batch in infer_loader:\n",
        "        batch = batch.to(device, non_blocking=True)\n",
        "        n_id = batch.n_id\n",
        "        z_batch = model(n_id, batch.edge_index, batch.edge_type)\n",
        "        z_all[n_id] = z_batch\n",
        "        del batch, z_batch, n_id\n",
        "        if device.type == \"cuda\": torch.cuda.empty_cache()\n",
        "\n",
        "# ----------------------------\n",
        "# 8) Evaluation (per relation + overall) ‚Äî DistMult + zero_division=0\n",
        "# ----------------------------\n",
        "print(\"\\nüìä Final evaluation per edge type (filtered negatives, DistMult):\")\n",
        "\n",
        "def eval_relation(z_all, etype, splits, k_neg=1):\n",
        "    rel_id = rel2id[etype]\n",
        "    pos_e = splits[\"test\"]\n",
        "    if pos_e.numel() == 0: return None\n",
        "    N = pos_e.size(1)\n",
        "    # Build negatives globally (filtered, typed) just for evaluation\n",
        "    # (global is fine here; we evaluate on z_all)\n",
        "    # Reuse earlier sampler but with relation ids vector:\n",
        "    src_g = pos_e[0].to(device); dst_g = pos_e[1].to(device)\n",
        "    rel_ids = torch.full((N,), rel_id, dtype=torch.long, device=device)\n",
        "\n",
        "    # filtered typed negs in GLOBAL space (may include true edges but low prob)\n",
        "    # Simple version: corrupt tails only\n",
        "    neg_src = src_g.repeat_interleave(k_neg)\n",
        "    # build tail pool by type\n",
        "    s_type,_, d_type = etype\n",
        "    d_tid = type2id[d_type]\n",
        "    d_pool_global = torch.arange(type_offsets[d_type], type_offsets[d_type] + len(node_type_map[d_type]), device=device)\n",
        "    neg_dst = d_pool_global[torch.randint(0, d_pool_global.numel(), (N*k_neg,), device=device)]\n",
        "\n",
        "    # Scores\n",
        "    pos_scores = distmult_sigmoid_scores(z_all, model.rel_emb, pos_e.to(device), rel_ids)\n",
        "    neg_scores = distmult_sigmoid_scores(z_all, model.rel_emb, torch.stack([neg_src, neg_dst]), rel_ids.repeat_interleave(k_neg))\n",
        "\n",
        "    y_true = torch.cat([torch.ones_like(pos_scores), torch.zeros_like(neg_scores)])\n",
        "    y_scores = torch.cat([pos_scores, neg_scores]).detach().cpu().numpy()\n",
        "    y = y_true.detach().cpu().numpy()\n",
        "    auc = roc_auc_score(y, y_scores)\n",
        "\n",
        "    preds = (y_scores > 0.5).astype(int)\n",
        "    p = precision_score(y, preds, zero_division=0)\n",
        "    r = recall_score(y, preds, zero_division=0)\n",
        "    f1 = f1_score(y, preds, zero_division=0)\n",
        "    return auc, p, r, f1\n",
        "\n",
        "results = []\n",
        "all_pos_eidx_list, all_rel_ids_list = [], []\n",
        "\n",
        "for etype, splits in edge_type_splits.items():\n",
        "    out = eval_relation(z_all, etype, splits, k_neg=1)\n",
        "    if out is None: continue\n",
        "    auc, p, r, f1 = out\n",
        "    results.append((etype, auc, p, r, f1))\n",
        "    rel_id = rel2id[etype]\n",
        "    te = splits[\"test\"]\n",
        "    all_pos_eidx_list.append(te)\n",
        "    all_rel_ids_list.append(torch.full((te.size(1),), rel_id, dtype=torch.long))\n",
        "    print(f\"{etype}: AUC={auc:.4f}, P={p:.3f}, R={r:.3f}, F1={f1:.3f}\")\n",
        "\n",
        "# Overall\n",
        "if all_pos_eidx_list:\n",
        "    all_pos_eidx = torch.cat(all_pos_eidx_list, dim=1).to(device)\n",
        "    all_rel_ids = torch.cat(all_rel_ids_list, dim=0).to(device)\n",
        "    # Simple overall negatives: corrupt tails with matching type (1 per pos)\n",
        "    etypes_for_all = [relid_to_etype(int(r)) for r in all_rel_ids.tolist()]\n",
        "    neg_src = all_pos_eidx[0]\n",
        "    neg_dst_list = []\n",
        "    for r_id, et in zip(all_rel_ids.tolist(), etypes_for_all):\n",
        "        d_type = et[2]\n",
        "        pool = torch.arange(type_offsets[d_type], type_offsets[d_type] + len(node_type_map[d_type]), device=device)\n",
        "        neg_dst_list.append(pool[torch.randint(0, pool.numel(), (1,), device=device)])\n",
        "    neg_dst = torch.stack(neg_dst_list).view(-1)\n",
        "    neg_e = torch.stack([neg_src, neg_dst], dim=0)\n",
        "\n",
        "    pos_scores = distmult_sigmoid_scores(z_all, model.rel_emb, all_pos_eidx, all_rel_ids)\n",
        "    neg_scores = distmult_sigmoid_scores(z_all, model.rel_emb, neg_e, all_rel_ids)\n",
        "\n",
        "    y_scores = torch.cat([pos_scores, neg_scores]).detach().cpu().numpy()\n",
        "    y = np.concatenate([np.ones(pos_scores.numel()), np.zeros(neg_scores.numel())])\n",
        "\n",
        "    overall_auc = roc_auc_score(y, y_scores)\n",
        "    preds = (y_scores > 0.5).astype(int)\n",
        "    overall_p = precision_score(y, preds, zero_division=0)\n",
        "    overall_r = recall_score(y, preds, zero_division=0)\n",
        "    overall_f1 = f1_score(y, preds, zero_division=0)\n",
        "\n",
        "    print(\"\\nüåç Overall Performance (filtered-ish, typed tails, DistMult):\")\n",
        "    print(f\"Overall AUC = {overall_auc:.4f}\")\n",
        "    print(f\"Overall Precision = {overall_p:.3f}\")\n",
        "    print(f\"Overall Recall = {overall_r:.3f}\")\n",
        "    print(f\"Overall F1 Score = {overall_f1:.3f}\")\n",
        "else:\n",
        "    print(\"\\nNo test edges available for evaluation.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_poUCI96ZKy",
        "outputId": "382235d1-5b28-42e3-db60-8e397ced6434"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "üì• Loading GraphML from: /content/drive/MyDrive/drug_data_kg_rebuilt_normalized.graphml\n",
            "‚úÖ Loaded graph with 100495 nodes and 160229 edges.\n",
            "‚úÖ Node types: ['drug', 'active_ingredient', 'indications_and_usage', 'dosage_and_administration', 'warnings', 'pregnancy_or_breast_feeding', 'keep_out_of_reach_of_children', 'purpose', 'storage_and_handling', 'brand', 'do_not_use', 'ask_doctor', 'inactive_ingredient', 'stop_use', 'ask_doctor_or_pharmacist', 'overdose_warning', 'drug_interactions']\n",
            "‚úÖ Total edge types: 287\n",
            "Homogeneous nodes: 100495, edges used for training: 127935\n",
            "\n",
            "üîÅ Training with NeighborLoader mini-batches + AMP ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch_geometric/sampler/neighbor_sampler.py:61: UserWarning: Using 'NeighborSampler' without a 'pyg-lib' installation is deprecated and will be removed soon. Please install 'pyg-lib' for accelerated neighborhood sampling\n",
            "  warnings.warn(f\"Using '{self.__class__.__name__}' without a \"\n",
            "/tmp/ipython-input-3266118914.py:255: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler(enabled=(device.type == \"cuda\"))\n",
            "/tmp/ipython-input-3266118914.py:297: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(enabled=(device.type == \"cuda\")):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01 | Loss: 12.4766 | Seen pos edges: 22807\n",
            "Epoch 02 | Loss: 12.4764 | Seen pos edges: 22725\n",
            "Epoch 03 | Loss: 12.4751 | Seen pos edges: 22895\n",
            "Epoch 04 | Loss: 12.4682 | Seen pos edges: 23041\n",
            "Epoch 05 | Loss: 12.4315 | Seen pos edges: 22789\n",
            "Epoch 06 | Loss: 12.2815 | Seen pos edges: 23073\n",
            "Epoch 07 | Loss: 11.7523 | Seen pos edges: 22703\n",
            "Epoch 08 | Loss: 10.9455 | Seen pos edges: 22849\n",
            "Epoch 09 | Loss: 10.3098 | Seen pos edges: 23050\n",
            "Epoch 10 | Loss: 9.8015 | Seen pos edges: 22744\n",
            "Epoch 11 | Loss: 9.3868 | Seen pos edges: 22859\n",
            "Epoch 12 | Loss: 8.9740 | Seen pos edges: 23099\n",
            "Epoch 13 | Loss: 8.6276 | Seen pos edges: 22692\n",
            "Epoch 14 | Loss: 8.3217 | Seen pos edges: 22912\n",
            "Epoch 15 | Loss: 8.0881 | Seen pos edges: 22930\n",
            "Epoch 16 | Loss: 7.7698 | Seen pos edges: 22923\n",
            "Epoch 17 | Loss: 7.4389 | Seen pos edges: 22892\n",
            "Epoch 18 | Loss: 7.1008 | Seen pos edges: 22997\n",
            "Epoch 19 | Loss: 6.6699 | Seen pos edges: 22790\n",
            "Epoch 20 | Loss: 6.4369 | Seen pos edges: 22882\n",
            "Epoch 21 | Loss: 6.0767 | Seen pos edges: 22767\n",
            "Epoch 22 | Loss: 5.9214 | Seen pos edges: 22731\n",
            "Epoch 23 | Loss: 5.8067 | Seen pos edges: 22911\n",
            "Epoch 24 | Loss: 5.6276 | Seen pos edges: 23012\n",
            "Epoch 25 | Loss: 5.4808 | Seen pos edges: 22842\n",
            "Epoch 26 | Loss: 5.3061 | Seen pos edges: 22908\n",
            "Epoch 27 | Loss: 5.2947 | Seen pos edges: 23065\n",
            "Epoch 28 | Loss: 5.1141 | Seen pos edges: 22763\n",
            "Epoch 29 | Loss: 4.9888 | Seen pos edges: 22977\n",
            "Epoch 30 | Loss: 4.9013 | Seen pos edges: 22947\n",
            "\n",
            "üîé Computing full-node embeddings (batched inference) ...\n",
            "\n",
            "üìä Final evaluation per edge type (filtered negatives, DistMult):\n",
            "('drug', 'active_ingredient', 'active_ingredient'): AUC=0.4682, P=0.425, R=0.218, F1=0.288\n",
            "('drug', 'indications_and_usage', 'indications_and_usage'): AUC=0.5000, P=0.498, R=0.072, F1=0.126\n",
            "('drug', 'dosage_and_administration', 'dosage_and_administration'): AUC=0.4993, P=0.500, R=0.417, F1=0.455\n",
            "('drug', 'warnings', 'warnings'): AUC=0.5342, P=0.587, R=0.101, F1=0.173\n",
            "('drug', 'pregnancy_or_breast_feeding', 'pregnancy_or_breast_feeding'): AUC=0.5012, P=0.000, R=0.000, F1=0.000\n",
            "('drug', 'keep_out_of_reach_of_children', 'keep_out_of_reach_of_children'): AUC=0.5005, P=0.498, R=0.217, F1=0.302\n",
            "('drug', 'purpose', 'purpose'): AUC=0.5225, P=0.475, R=0.059, F1=0.106\n",
            "('drug', 'warnings', 'keep_out_of_reach_of_children'): AUC=0.4985, P=0.500, R=0.721, F1=0.590\n",
            "('drug', 'storage_and_handling', 'storage_and_handling'): AUC=0.4991, P=0.500, R=0.217, F1=0.303\n",
            "('drug', 'purpose', 'brand'): AUC=0.9319, P=1.000, R=0.223, F1=0.365\n",
            "('drug', 'do_not_use', 'do_not_use'): AUC=0.5000, P=0.500, R=1.000, F1=0.667\n",
            "('drug', 'ask_doctor', 'ask_doctor'): AUC=0.4974, P=0.500, R=0.772, F1=0.607\n",
            "('drug', 'inactive_ingredient', 'inactive_ingredient'): AUC=0.5074, P=0.502, R=0.364, F1=0.422\n",
            "('drug', 'inactive_ingredient', 'brand'): AUC=0.9176, P=1.000, R=0.239, F1=0.386\n",
            "('brand', 'warnings', 'drug'): AUC=0.7371, P=0.863, R=0.332, F1=0.480\n",
            "('inactive_ingredient', 'purpose', 'brand'): AUC=0.0000, P=0.000, R=0.000, F1=0.000\n",
            "('inactive_ingredient', 'indications_and_usage', 'indications_and_usage'): AUC=0.6875, P=0.000, R=0.000, F1=0.000\n",
            "('inactive_ingredient', 'warnings', 'warnings'): AUC=0.6800, P=0.500, R=0.800, F1=0.615\n",
            "('inactive_ingredient', 'keep_out_of_reach_of_children', 'keep_out_of_reach_of_children'): AUC=0.5556, P=0.500, R=1.000, F1=0.667\n",
            "('inactive_ingredient', 'dosage_and_administration', 'dosage_and_administration'): AUC=0.4375, P=0.000, R=0.000, F1=0.000\n",
            "('brand', 'warnings', 'warnings'): AUC=0.9515, P=0.981, R=0.376, F1=0.544\n",
            "('drug', 'stop_use', 'stop_use'): AUC=0.4998, P=0.500, R=0.290, F1=0.367\n",
            "('drug', 'stop_use', 'warnings'): AUC=0.4495, P=0.467, R=0.167, F1=0.246\n",
            "('drug', 'do_not_use', 'warnings'): AUC=0.4684, P=0.500, R=1.000, F1=0.667\n",
            "('drug', 'keep_out_of_reach_of_children', 'warnings'): AUC=0.5484, P=0.536, R=0.736, F1=0.620\n",
            "('brand', 'active_ingredient', 'brand'): AUC=0.5000, P=1.000, R=0.500, F1=0.667\n",
            "('brand', 'active_ingredient', 'active_ingredient'): AUC=0.3951, P=0.500, R=0.957, F1=0.657\n",
            "('brand', 'purpose', 'purpose'): AUC=0.5556, P=0.500, R=0.083, F1=0.143\n",
            "('brand', 'indications_and_usage', 'indications_and_usage'): AUC=0.4962, P=0.500, R=0.929, F1=0.650\n",
            "('brand', 'dosage_and_administration', 'dosage_and_administration'): AUC=0.4937, P=0.000, R=0.000, F1=0.000\n",
            "('brand', 'warnings', 'keep_out_of_reach_of_children'): AUC=0.5000, P=0.500, R=1.000, F1=0.667\n",
            "('drug', 'warnings', 'stop_use'): AUC=0.5102, P=0.500, R=0.571, F1=0.533\n",
            "('drug', 'storage_and_handling', 'warnings'): AUC=0.4375, P=0.545, R=0.750, F1=0.632\n",
            "('drug', 'purpose', 'indications_and_usage'): AUC=0.5112, P=0.524, R=0.440, F1=0.478\n",
            "('drug', 'active_ingredient', 'brand'): AUC=0.6920, P=1.000, R=0.338, F1=0.505\n",
            "('inactive_ingredient', 'purpose', 'purpose'): AUC=0.5000, P=0.500, R=0.500, F1=0.500\n",
            "('drug', 'dosage_and_administration', 'indications_and_usage'): AUC=0.4800, P=0.500, R=1.000, F1=0.667\n",
            "('drug', 'inactive_ingredient', 'drug'): AUC=1.0000, P=0.000, R=0.000, F1=0.000\n",
            "('drug', 'inactive_ingredient', 'warnings'): AUC=0.6181, P=0.562, R=0.750, F1=0.643\n",
            "('warnings', 'active_ingredient', 'active_ingredient'): AUC=0.4514, P=0.556, R=0.833, F1=0.667\n",
            "('warnings', 'purpose', 'purpose'): AUC=0.3200, P=0.333, R=0.200, F1=0.250\n",
            "('warnings', 'indications_and_usage', 'indications_and_usage'): AUC=0.5625, P=0.500, R=0.250, F1=0.333\n",
            "('warnings', 'warnings', 'warnings'): AUC=0.1875, P=0.429, R=0.750, F1=0.545\n",
            "('warnings', 'stop_use', 'stop_use'): AUC=0.0000, P=0.000, R=0.000, F1=0.000\n",
            "('warnings', 'dosage_and_administration', 'dosage_and_administration'): AUC=0.5800, P=0.500, R=1.000, F1=0.667\n",
            "('warnings', 'keep_out_of_reach_of_children', 'keep_out_of_reach_of_children'): AUC=0.7500, P=0.000, R=0.000, F1=0.000\n",
            "('warnings', 'storage_and_handling', 'storage_and_handling'): AUC=0.7500, P=0.500, R=1.000, F1=0.667\n",
            "('drug', 'indications_and_usage', 'purpose'): AUC=0.5106, P=0.583, R=0.212, F1=0.311\n",
            "('drug', 'ask_doctor_or_pharmacist', 'ask_doctor_or_pharmacist'): AUC=0.4957, P=0.500, R=0.037, F1=0.068\n",
            "('drug', 'warnings', 'pregnancy_or_breast_feeding'): AUC=0.5052, P=0.500, R=1.000, F1=0.667\n",
            "('drug', 'indications_and_usage', 'brand'): AUC=1.0000, P=0.000, R=0.000, F1=0.000\n",
            "('brand', 'do_not_use', 'do_not_use'): AUC=0.5306, P=0.500, R=1.000, F1=0.667\n",
            "('brand', 'ask_doctor', 'ask_doctor'): AUC=0.4453, P=0.000, R=0.000, F1=0.000\n",
            "('brand', 'ask_doctor_or_pharmacist', 'ask_doctor_or_pharmacist'): AUC=0.4444, P=0.500, R=1.000, F1=0.667\n",
            "('brand', 'stop_use', 'stop_use'): AUC=0.4917, P=0.000, R=0.000, F1=0.000\n",
            "('brand', 'keep_out_of_reach_of_children', 'keep_out_of_reach_of_children'): AUC=0.5248, P=0.500, R=1.000, F1=0.667\n",
            "('brand', 'keep_out_of_reach_of_children', 'warnings'): AUC=0.0000, P=0.333, R=0.500, F1=0.400\n",
            "('drug', 'warnings', 'storage_and_handling'): AUC=0.4970, P=0.500, R=0.308, F1=0.381\n",
            "('drug', 'warnings', 'dosage_and_administration'): AUC=0.5117, P=0.500, R=0.500, F1=0.500\n",
            "('drug', 'active_ingredient', 'warnings'): AUC=0.4290, P=0.000, R=0.000, F1=0.000\n",
            "('brand', 'warnings', 'brand'): AUC=0.7406, P=1.000, R=0.084, F1=0.155\n",
            "('drug', 'warnings', 'active_ingredient'): AUC=0.5900, P=0.647, R=0.324, F1=0.431\n",
            "('drug', 'pregnancy_or_breast_feeding', 'warnings'): AUC=0.4221, P=0.444, R=0.471, F1=0.457\n",
            "('warnings', 'keep_out_of_reach_of_children', 'warnings'): AUC=1.0000, P=0.000, R=0.000, F1=0.000\n",
            "('brand', 'purpose', 'brand'): AUC=1.0000, P=1.000, R=0.200, F1=0.333\n",
            "('drug', 'dosage_and_administration', 'warnings'): AUC=0.4815, P=0.500, R=0.222, F1=0.308\n",
            "('drug', 'indications_and_usage', 'dosage_and_administration'): AUC=0.4734, P=0.500, R=0.692, F1=0.581\n",
            "('drug', 'active_ingredient', 'inactive_ingredient'): AUC=0.5185, P=0.000, R=0.000, F1=0.000\n",
            "('brand', 'warnings', 'inactive_ingredient'): AUC=0.9470, P=1.000, R=0.396, F1=0.568\n",
            "('drug', 'warnings', 'brand'): AUC=0.7959, P=1.000, R=0.143, F1=0.250\n",
            "('drug', 'active_ingredient', 'drug'): AUC=0.7500, P=0.000, R=0.000, F1=0.000\n",
            "('active_ingredient', 'active_ingredient', 'active_ingredient'): AUC=0.4688, P=0.000, R=0.000, F1=0.000\n",
            "('active_ingredient', 'purpose', 'purpose'): AUC=0.5000, P=0.000, R=0.000, F1=0.000\n",
            "('active_ingredient', 'do_not_use', 'do_not_use'): AUC=0.5000, P=0.500, R=1.000, F1=0.667\n",
            "('active_ingredient', 'keep_out_of_reach_of_children', 'keep_out_of_reach_of_children'): AUC=0.7500, P=0.000, R=0.000, F1=0.000\n",
            "('active_ingredient', 'warnings', 'warnings'): AUC=0.3611, P=0.556, R=0.833, F1=0.667\n",
            "('active_ingredient', 'stop_use', 'stop_use'): AUC=0.7500, P=0.500, R=0.500, F1=0.500\n",
            "('active_ingredient', 'inactive_ingredient', 'inactive_ingredient'): AUC=1.0000, P=0.000, R=0.000, F1=0.000\n",
            "('inactive_ingredient', 'stop_use', 'stop_use'): AUC=0.0000, P=0.500, R=1.000, F1=0.667\n",
            "('inactive_ingredient', 'storage_and_handling', 'storage_and_handling'): AUC=1.0000, P=0.000, R=0.000, F1=0.000\n",
            "('inactive_ingredient', 'active_ingredient', 'active_ingredient'): AUC=0.0800, P=0.500, R=1.000, F1=0.667\n",
            "('inactive_ingredient', 'inactive_ingredient', 'inactive_ingredient'): AUC=0.5694, P=0.000, R=0.000, F1=0.000\n",
            "('brand', 'warnings', 'pregnancy_or_breast_feeding'): AUC=0.7500, P=0.500, R=0.500, F1=0.500\n",
            "('drug', 'overdose_warning', 'warnings'): AUC=0.4400, P=0.000, R=0.000, F1=0.000\n",
            "('drug', 'indications_and_usage', 'warnings'): AUC=0.5000, P=0.000, R=0.000, F1=0.000\n",
            "('drug', 'ask_doctor', 'warnings'): AUC=0.5051, P=0.500, R=1.000, F1=0.667\n",
            "('drug', 'stop_use', 'do_not_use'): AUC=0.2500, P=0.000, R=0.000, F1=0.000\n",
            "('drug', 'overdose_warning', 'overdose_warning'): AUC=0.5612, P=0.500, R=1.000, F1=0.667\n",
            "('drug', 'warnings', 'ask_doctor'): AUC=0.4876, P=0.500, R=1.000, F1=0.667\n",
            "('drug', 'ask_doctor_or_pharmacist', 'pregnancy_or_breast_feeding'): AUC=0.2500, P=0.000, R=0.000, F1=0.000\n",
            "('active_ingredient', 'indications_and_usage', 'indications_and_usage'): AUC=0.4375, P=0.000, R=0.000, F1=0.000\n",
            "('active_ingredient', 'dosage_and_administration', 'dosage_and_administration'): AUC=0.5000, P=0.500, R=1.000, F1=0.667\n",
            "('active_ingredient', 'pregnancy_or_breast_feeding', 'pregnancy_or_breast_feeding'): AUC=0.0000, P=0.000, R=0.000, F1=0.000\n",
            "('brand', 'inactive_ingredient', 'inactive_ingredient'): AUC=0.5950, P=0.714, R=0.455, F1=0.556\n",
            "('brand', 'inactive_ingredient', 'brand'): AUC=0.7500, P=1.000, R=0.500, F1=0.667\n",
            "('drug', 'warnings', 'do_not_use'): AUC=0.4891, P=0.000, R=0.000, F1=0.000\n",
            "('drug', 'purpose', 'drug'): AUC=0.7500, P=0.000, R=0.000, F1=0.000\n",
            "('drug', 'ask_doctor', 'indications_and_usage'): AUC=0.2500, P=0.500, R=1.000, F1=0.667\n",
            "('drug', 'ask_doctor', 'stop_use'): AUC=0.4700, P=0.500, R=1.000, F1=0.667\n",
            "('drug', 'ask_doctor_or_pharmacist', 'warnings'): AUC=0.6250, P=0.571, R=1.000, F1=0.727\n",
            "('brand', 'pregnancy_or_breast_feeding', 'pregnancy_or_breast_feeding'): AUC=0.7500, P=0.000, R=0.000, F1=0.000\n",
            "('purpose', 'warnings', 'warnings'): AUC=1.0000, P=0.500, R=1.000, F1=0.667\n",
            "('purpose', 'keep_out_of_reach_of_children', 'keep_out_of_reach_of_children'): AUC=1.0000, P=0.500, R=1.000, F1=0.667\n",
            "('drug', 'ask_doctor', 'brand'): AUC=1.0000, P=1.000, R=0.778, F1=0.875\n",
            "('drug', 'dosage_and_administration', 'do_not_use'): AUC=0.4444, P=0.000, R=0.000, F1=0.000\n",
            "('drug', 'drug_interactions', 'drug_interactions'): AUC=0.6000, P=0.500, R=1.000, F1=0.667\n",
            "('drug', 'ask_doctor', 'ask_doctor_or_pharmacist'): AUC=0.5000, P=0.500, R=1.000, F1=0.667\n",
            "('drug', 'indications_and_usage', 'stop_use'): AUC=0.5625, P=0.000, R=0.000, F1=0.000\n",
            "('drug', 'keep_out_of_reach_of_children', 'overdose_warning'): AUC=0.4444, P=0.500, R=1.000, F1=0.667\n",
            "('drug', 'warnings', 'ask_doctor_or_pharmacist'): AUC=0.3750, P=0.500, R=0.250, F1=0.333\n",
            "('drug', 'ask_doctor_or_pharmacist', 'ask_doctor'): AUC=0.4694, P=0.500, R=0.286, F1=0.364\n",
            "('active_ingredient', 'warnings', 'pregnancy_or_breast_feeding'): AUC=1.0000, P=0.000, R=0.000, F1=0.000\n",
            "('active_ingredient', 'warnings', 'keep_out_of_reach_of_children'): AUC=0.5000, P=0.500, R=1.000, F1=0.667\n",
            "('drug', 'drug_interactions', 'active_ingredient'): AUC=0.5000, P=0.000, R=0.000, F1=0.000\n",
            "('drug', 'warnings', 'inactive_ingredient'): AUC=0.4000, P=0.429, R=0.600, F1=0.500\n",
            "('brand', 'warnings', 'active_ingredient'): AUC=0.4500, P=1.000, R=0.400, F1=0.571\n",
            "('drug', 'indications_and_usage', 'do_not_use'): AUC=0.7500, P=0.000, R=0.000, F1=0.000\n",
            "('drug', 'ask_doctor', 'pregnancy_or_breast_feeding'): AUC=1.0000, P=0.000, R=0.000, F1=0.000\n",
            "('drug', 'overdose_warning', 'keep_out_of_reach_of_children'): AUC=0.0000, P=0.500, R=1.000, F1=0.667\n",
            "('brand', 'indications_and_usage', 'purpose'): AUC=0.7500, P=0.000, R=0.000, F1=0.000\n",
            "('brand', 'warnings', 'do_not_use'): AUC=0.5000, P=0.500, R=1.000, F1=0.667\n",
            "('brand', 'storage_and_handling', 'storage_and_handling'): AUC=0.4861, P=0.500, R=1.000, F1=0.667\n",
            "('drug', 'pregnancy_or_breast_feeding', 'ask_doctor_or_pharmacist'): AUC=0.4444, P=0.500, R=0.667, F1=0.571\n",
            "('drug', 'warnings', 'overdose_warning'): AUC=0.2500, P=0.000, R=0.000, F1=0.000\n",
            "('drug', 'do_not_use', 'keep_out_of_reach_of_children'): AUC=0.5556, P=0.000, R=0.000, F1=0.000\n",
            "('drug', 'dosage_and_administration', 'brand'): AUC=0.0000, P=0.000, R=0.000, F1=0.000\n",
            "('drug', 'dosage_and_administration', 'storage_and_handling'): AUC=0.4444, P=0.500, R=0.667, F1=0.571\n",
            "('drug', 'active_ingredient', 'drug_interactions'): AUC=0.3750, P=0.500, R=0.500, F1=0.500\n",
            "('brand', 'purpose', 'indications_and_usage'): AUC=1.0000, P=0.000, R=0.000, F1=0.000\n",
            "('drug', 'ask_doctor', 'purpose'): AUC=1.0000, P=0.500, R=1.000, F1=0.667\n",
            "('drug', 'stop_use', 'ask_doctor'): AUC=0.4800, P=0.500, R=0.800, F1=0.615\n",
            "('drug', 'keep_out_of_reach_of_children', 'storage_and_handling'): AUC=0.5200, P=0.500, R=0.200, F1=0.286\n",
            "('drug', 'active_ingredient', 'purpose'): AUC=0.5556, P=0.500, R=0.333, F1=0.400\n",
            "('drug', 'keep_out_of_reach_of_children', 'pregnancy_or_breast_feeding'): AUC=0.5000, P=0.000, R=0.000, F1=0.000\n",
            "('drug', 'storage_and_handling', 'dosage_and_administration'): AUC=0.6667, P=0.500, R=1.000, F1=0.667\n",
            "('drug', 'do_not_use', 'ask_doctor_or_pharmacist'): AUC=0.7500, P=0.500, R=0.500, F1=0.500\n",
            "('drug', 'stop_use', 'purpose'): AUC=0.2500, P=0.500, R=0.500, F1=0.500\n",
            "('drug', 'stop_use', 'indications_and_usage'): AUC=0.4400, P=0.500, R=1.000, F1=0.667\n",
            "('drug', 'inactive_ingredient', 'active_ingredient'): AUC=0.4400, P=0.000, R=0.000, F1=0.000\n",
            "('drug', 'stop_use', 'brand'): AUC=1.0000, P=0.000, R=0.000, F1=0.000\n",
            "('warnings', 'inactive_ingredient', 'inactive_ingredient'): AUC=0.7500, P=1.000, R=0.500, F1=0.667\n",
            "('drug', 'do_not_use', 'ask_doctor'): AUC=0.5556, P=0.500, R=1.000, F1=0.667\n",
            "('brand', 'do_not_use', 'warnings'): AUC=0.7500, P=0.000, R=0.000, F1=0.000\n",
            "('drug', 'stop_use', 'keep_out_of_reach_of_children'): AUC=0.7500, P=0.500, R=0.500, F1=0.500\n",
            "('drug', 'warnings', 'indications_and_usage'): AUC=0.5000, P=0.000, R=0.000, F1=0.000\n",
            "('drug', 'warnings', 'purpose'): AUC=0.7500, P=0.000, R=0.000, F1=0.000\n",
            "('drug', 'ask_doctor', 'do_not_use'): AUC=0.0000, P=0.000, R=0.000, F1=0.000\n",
            "('drug', 'purpose', 'dosage_and_administration'): AUC=0.0000, P=0.000, R=0.000, F1=0.000\n",
            "('drug', 'purpose', 'active_ingredient'): AUC=0.5000, P=0.500, R=1.000, F1=0.667\n",
            "('drug', 'ask_doctor', 'dosage_and_administration'): AUC=0.2500, P=0.500, R=0.500, F1=0.500\n",
            "('drug', 'dosage_and_administration', 'purpose'): AUC=0.7500, P=0.500, R=1.000, F1=0.667\n",
            "('drug', 'storage_and_handling', 'keep_out_of_reach_of_children'): AUC=0.6667, P=0.500, R=1.000, F1=0.667\n",
            "('brand', 'indications_and_usage', 'dosage_and_administration'): AUC=0.5000, P=0.000, R=0.000, F1=0.000\n",
            "('active_ingredient', 'do_not_use', 'warnings'): AUC=1.0000, P=0.000, R=0.000, F1=0.000\n",
            "('drug', 'active_ingredient', 'dosage_and_administration'): AUC=0.0000, P=0.000, R=0.000, F1=0.000\n",
            "('drug', 'indications_and_usage', 'active_ingredient'): AUC=0.5000, P=0.000, R=0.000, F1=0.000\n",
            "('drug', 'indications_and_usage', 'storage_and_handling'): AUC=0.5000, P=0.500, R=1.000, F1=0.667\n",
            "('brand', 'warnings', 'purpose'): AUC=0.0000, P=0.000, R=0.000, F1=0.000\n",
            "\n",
            "üåç Overall Performance (filtered-ish, typed tails, DistMult):\n",
            "Overall AUC = 0.5690\n",
            "Overall Precision = 0.566\n",
            "Overall Recall = 0.288\n",
            "Overall F1 Score = 0.382\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "from collections import Counter, defaultdict\n",
        "from pathlib import Path\n",
        "import json\n",
        "import re\n",
        "\n",
        "# =========================\n",
        "# CONFIG: set your paths\n",
        "# =========================\n",
        "OPENFDA_PATH = \"/Users/ganeshkumarboini/Downloads/drug_data_kg_openfda_edges_no_drop.graphml\"\n",
        "PRIMEKG_PATH = \"/Users/ganeshkumarboini/Downloads/primekg_hetionet_combined.graphml\"\n",
        "OUT_MERGED_GRAPH = \"/Users/ganeshkumarboini/Downloads/merged_openfda_primekg.graphml\"\n",
        "OUT_SUMMARY_JSON = \"/Users/ganeshkumarboini/Downloads/merged_openfda_primekg.summary.json\"\n",
        "\n",
        "# Options\n",
        "USE_MULTIGRAPH = True          # keep every parallel edge (no drops)\n",
        "NORMALIZE_NAMES = True         # lower/strip/collapse spaces for node_name when matching\n",
        "PREFER_NODE_SOURCE = \"primekg\" # if node attribute conflicts: \"openfda\" or \"primekg\"\n",
        "\n",
        "# =========================\n",
        "# Helpers\n",
        "# =========================\n",
        "def load_graph(path):\n",
        "    G = nx.read_graphml(path)\n",
        "    kind = \"MultiDiGraph\" if G.is_multigraph() else \"DiGraph\"\n",
        "    print(f\"Loaded {path} -> {kind} | nodes={G.number_of_nodes():,} edges={G.number_of_edges():,}\")\n",
        "    return G\n",
        "\n",
        "def get_attr(attrs, k, default=\"\"):\n",
        "    v = attrs.get(k)\n",
        "    return default if v is None else v\n",
        "\n",
        "_ws_re = re.compile(r\"\\s+\")\n",
        "def canon_name(name: str) -> str:\n",
        "    s = name if isinstance(name, str) else str(name)\n",
        "    if NORMALIZE_NAMES:\n",
        "        s = _ws_re.sub(\" \", s.strip().lower())\n",
        "    return s\n",
        "\n",
        "def node_inventory(G, node_type_key=\"node_type\", node_name_key=\"node_name\"):\n",
        "    types = Counter(nx.get_node_attributes(G, node_type_key).values())\n",
        "    names_missing = sum(1 for _, a in G.nodes(data=True) if node_name_key not in a or not str(a.get(node_name_key,\"\")).strip())\n",
        "    return types, names_missing\n",
        "\n",
        "def ensure_node_basics(G, source_tag):\n",
        "    # guarantee node_name and node_source exist\n",
        "    for n, a in G.nodes(data=True):\n",
        "        if \"node_name\" not in a or not str(a.get(\"node_name\",\"\")).strip():\n",
        "            a[\"node_name\"] = str(n)\n",
        "        # stamp node_source if missing (may already exist in your KGs)\n",
        "        if \"node_source\" not in a or not a[\"node_source\"]:\n",
        "            a[\"node_source\"] = source_tag\n",
        "\n",
        "def summarize_graph(G, node_type_key=\"node_type\", edge_rel_key=\"relation\"):\n",
        "    kind = \"MultiDiGraph\" if G.is_multigraph() else \"DiGraph\"\n",
        "    n_nodes = G.number_of_nodes()\n",
        "    n_edges = G.number_of_edges()\n",
        "    node_types = Counter(nx.get_node_attributes(G, node_type_key).values())\n",
        "    edge_types = Counter(nx.get_edge_attributes(G, edge_rel_key).values())\n",
        "\n",
        "    node_types_list = sorted(node_types.items(), key=lambda kv: (-kv[1], kv[0]))\n",
        "    edge_types_list = sorted(edge_types.items(), key=lambda kv: (-kv[1], kv[0]))\n",
        "\n",
        "    # connectivity (MultiGraphs supported)\n",
        "    UG = G.to_undirected()\n",
        "    comps = list(nx.connected_components(UG))\n",
        "    largest = max((len(c) for c in comps), default=0)\n",
        "    frac = (largest / n_nodes) if n_nodes else 0.0\n",
        "    orphans = sum(1 for _ in nx.isolates(G))\n",
        "\n",
        "    summary = {\n",
        "        \"graph_kind\": kind,\n",
        "        \"nodes\": int(n_nodes),\n",
        "        \"edges\": int(n_edges),\n",
        "\n",
        "        \"node_types_count\": int(len(node_types_list)),\n",
        "        \"node_types\": node_types_list,\n",
        "\n",
        "        \"relation_types_count\": int(len(edge_types_list)),\n",
        "        \"relation_types\": edge_types_list,\n",
        "\n",
        "        \"connectivity\": {\n",
        "            \"components\": int(len(comps)),\n",
        "            \"largest_component_size\": int(largest),\n",
        "            \"largest_component_fraction\": float(frac),\n",
        "            \"orphans\": int(orphans),\n",
        "        },\n",
        "\n",
        "        \"keys_used\": {\n",
        "            \"node_type_key\": node_type_key,\n",
        "            \"edge_rel_key\": edge_rel_key,\n",
        "        },\n",
        "    }\n",
        "    return summary\n",
        "\n",
        "def triplet_schema(G, node_type_key=\"node_type\", edge_rel_key=\"relation\", top=30):\n",
        "    # list unique (src_type, relation, dst_type) and counts\n",
        "    counts = Counter()\n",
        "    # works for DiGraph & MultiDiGraph\n",
        "    if G.is_multigraph():\n",
        "        for u, v, k, a in G.edges(keys=True, data=True):\n",
        "            r = a.get(edge_rel_key, \"unknown\")\n",
        "            st = G.nodes[u].get(node_type_key, \"unknown\")\n",
        "            dt = G.nodes[v].get(node_type_key, \"unknown\")\n",
        "            counts[(st, r, dt)] += 1\n",
        "    else:\n",
        "        for u, v, a in G.edges(data=True):\n",
        "            r = a.get(edge_rel_key, \"unknown\")\n",
        "            st = G.nodes[u].get(node_type_key, \"unknown\")\n",
        "            dt = G.nodes[v].get(node_type_key, \"unknown\")\n",
        "            counts[(st, r, dt)] += 1\n",
        "    total = len(counts)\n",
        "    top_items = counts.most_common(top)\n",
        "    return total, top_items\n",
        "\n",
        "# =========================\n",
        "# Load graphs\n",
        "# =========================\n",
        "G1 = load_graph(OPENFDA_PATH)     # your normalized OpenFDA minimal (node_type/node_name/node_source + relation/subfield)\n",
        "G2 = load_graph(PRIMEKG_PATH)     # PrimeKG+Hetionet combined\n",
        "\n",
        "# Ensure basic attrs present\n",
        "ensure_node_basics(G1, \"openfda\")\n",
        "ensure_node_basics(G2, \"primekg\")\n",
        "\n",
        "# Quick pre-merge stats\n",
        "t1, miss1 = node_inventory(G1)\n",
        "t2, miss2 = node_inventory(G2)\n",
        "print(\"\\nOpenFDA types (top):\", t1.most_common(10), \"| missing node_name:\", miss1)\n",
        "print(\"PrimeKG+Hetionet types (top):\", t2.most_common(10), \"| missing node_name:\", miss2)\n",
        "\n",
        "# =========================\n",
        "# Build canonical map by (node_type, node_name)\n",
        "# We create a fresh MultiDiGraph (or DiGraph) so nothing is lost.\n",
        "# =========================\n",
        "MG = nx.MultiDiGraph() if USE_MULTIGRAPH else nx.DiGraph()\n",
        "\n",
        "NODE_TYPE_KEY = \"node_type\"\n",
        "NODE_NAME_KEY = \"node_name\"\n",
        "NODE_SOURCE_KEY = \"node_source\"\n",
        "EDGE_REL_KEY = \"relation\"\n",
        "\n",
        "# map canonical key -> merged node id\n",
        "canon2id = {}\n",
        "# keep an incremental integer suffix to avoid accidental id collisions\n",
        "next_int = 0\n",
        "\n",
        "def make_merged_id(ntype, nname):\n",
        "    # Construct a stable readable id. If collides, append counter.\n",
        "    base = f\"{ntype}::{nname}\"\n",
        "    nonlocal next_int\n",
        "    if base in MG:  # extremely rare; but handle\n",
        "        while f\"{base}##{next_int}\" in MG:\n",
        "            next_int += 1\n",
        "        return f\"{base}##{next_int}\"\n",
        "    return base\n",
        "\n",
        "def upsert_node(nid, attrs, source_graph):\n",
        "    \"\"\"Insert node into merged graph using canonical (type, name) matching. Returns merged node id.\"\"\"\n",
        "    ntype = get_attr(attrs, NODE_TYPE_KEY, \"unknown\")\n",
        "    nname = get_attr(attrs, NODE_NAME_KEY, str(nid))\n",
        "    ckey = (canon_name(ntype), canon_name(nname))\n",
        "\n",
        "    if ckey in canon2id:\n",
        "        mid = canon2id[ckey]\n",
        "        # merge attributes (prefer PRIMEKG if configured)\n",
        "        existing = MG.nodes[mid]\n",
        "        # keep node_type and node_name as-is\n",
        "        # merge node_source\n",
        "        srcs = set(str(existing.get(NODE_SOURCE_KEY, \"\")).split(\"|\")) if existing.get(NODE_SOURCE_KEY) else set()\n",
        "        srcs2 = set(str(attrs.get(NODE_SOURCE_KEY, \"\")).split(\"|\")) if attrs.get(NODE_SOURCE_KEY) else set()\n",
        "        all_srcs = [s for s in (srcs | srcs2) if s]\n",
        "        MG.nodes[mid][NODE_SOURCE_KEY] = \"|\".join(sorted(set(all_srcs))) if all_srcs else existing.get(NODE_SOURCE_KEY, \"\")\n",
        "        # retain an 'orig_id_<source>' list\n",
        "        tag = \"primekg\" if source_graph == \"primekg\" else \"openfda\"\n",
        "        orig_key = f\"orig_id_{tag}\"\n",
        "        olds = set(str(MG.nodes[mid].get(orig_key, \"\")).split(\"|\")) if MG.nodes[mid].get(orig_key) else set()\n",
        "        olds.add(str(nid))\n",
        "        MG.nodes[mid][orig_key] = \"|\".join(sorted(olds))\n",
        "        return mid\n",
        "    else:\n",
        "        mid = make_merged_id(ntype, nname)\n",
        "        canon2id[ckey] = mid\n",
        "        # initialize node attrs\n",
        "        MG.add_node(mid)\n",
        "        MG.nodes[mid][NODE_TYPE_KEY] = ntype\n",
        "        MG.nodes[mid][NODE_NAME_KEY] = nname\n",
        "        MG.nodes[mid][NODE_SOURCE_KEY] = attrs.get(NODE_SOURCE_KEY, source_graph)\n",
        "        # store original ids by source\n",
        "        tag = \"primekg\" if source_graph == \"primekg\" else \"openfda\"\n",
        "        MG.nodes[mid][f\"orig_id_{tag}\"] = str(nid)\n",
        "        return mid\n",
        "\n",
        "def add_edge_preserving(u_mid, v_mid, eattrs, source_graph):\n",
        "    # always keep relation and subfield if present\n",
        "    rel = eattrs.get(EDGE_REL_KEY, \"unknown\")\n",
        "    subf = eattrs.get(\"subfield\", None)\n",
        "    payload = {\n",
        "        EDGE_REL_KEY: rel,\n",
        "        \"source_graph\": source_graph,\n",
        "    }\n",
        "    if subf is not None:\n",
        "        payload[\"subfield\"] = subf\n",
        "    # optional: keep original endpoints for traceability\n",
        "    # payload[\"orig_u\"] = str(u_mid)  # usually not needed\n",
        "    # payload[\"orig_v\"] = str(v_mid)\n",
        "    if MG.is_multigraph():\n",
        "        MG.add_edge(u_mid, v_mid, **payload)\n",
        "    else:\n",
        "        # In DiGraph, last write wins; to avoid drops we could count, but we promised no drops, so Multi is recommended.\n",
        "        MG.add_edge(u_mid, v_mid, **payload)\n",
        "\n",
        "# =========================\n",
        "# Add OpenFDA nodes/edges\n",
        "# =========================\n",
        "for n, a in G1.nodes(data=True):\n",
        "    upsert_node(n, a, \"openfda\")\n",
        "\n",
        "if G1.is_multigraph():\n",
        "    for u, v, k, a in G1.edges(keys=True, data=True):\n",
        "        u_mid = upsert_node(u, G1.nodes[u], \"openfda\")\n",
        "        v_mid = upsert_node(v, G1.nodes[v], \"openfda\")\n",
        "        add_edge_preserving(u_mid, v_mid, a, \"openfda\")\n",
        "else:\n",
        "    for u, v, a in G1.edges(data=True):\n",
        "        u_mid = upsert_node(u, G1.nodes[u], \"openfda\")\n",
        "        v_mid = upsert_node(v, G1.nodes[v], \"openfda\")\n",
        "        add_edge_preserving(u_mid, v_mid, a, \"openfda\")\n",
        "\n",
        "print(f\"\\nAfter OpenFDA -> merged: nodes={MG.number_of_nodes():,} edges={MG.number_of_edges():,}\")\n",
        "\n",
        "# =========================\n",
        "# Add PrimeKG nodes/edges\n",
        "# =========================\n",
        "for n, a in G2.nodes(data=True):\n",
        "    upsert_node(n, a, \"primekg\")\n",
        "\n",
        "if G2.is_multigraph():\n",
        "    for u, v, k, a in G2.edges(keys=True, data=True):\n",
        "        u_mid = upsert_node(u, G2.nodes[u], \"primekg\")\n",
        "        v_mid = upsert_node(v, G2.nodes[v], \"primekg\")\n",
        "        add_edge_preserving(u_mid, v_mid, a, \"primekg\")\n",
        "else:\n",
        "    for u, v, a in G2.edges(data=True):\n",
        "        u_mid = upsert_node(u, G2.nodes[u], \"primekg\")\n",
        "        v_mid = upsert_node(v, G2.nodes[v], \"primekg\")\n",
        "        add_edge_preserving(u_mid, v_mid, a, \"primekg\")\n",
        "\n",
        "print(f\"After PrimeKG -> merged: nodes={MG.number_of_nodes():,} edges={MG.number_of_edges():,}\")\n",
        "\n",
        "# =========================\n",
        "# Optional: prefer one source's attrs when conflicts (kept minimal here)\n",
        "# =========================\n",
        "# You can extend this block to pull preferred per-type attributes.\n",
        "\n",
        "# =========================\n",
        "# Save merged graph\n",
        "# =========================\n",
        "nx.write_graphml(MG, OUT_MERGED_GRAPH)\n",
        "print(f\"\\nSaved merged graph -> {OUT_MERGED_GRAPH}\")\n",
        "\n",
        "# =========================\n",
        "# Build & save summary\n",
        "# =========================\n",
        "summary = summarize_graph(MG, node_type_key=NODE_TYPE_KEY, edge_rel_key=EDGE_REL_KEY)\n",
        "\n",
        "# Triplet schema preview\n",
        "schema_total, schema_top = triplet_schema(MG, node_type_key=NODE_TYPE_KEY, edge_rel_key=EDGE_REL_KEY, top=30)\n",
        "summary[\"triplet_schema_types\"] = int(schema_total)\n",
        "summary[\"triplet_schema_top\"] = [[list(k), int(v)] for k, v in schema_top]\n",
        "\n",
        "with open(OUT_SUMMARY_JSON, \"w\") as f:\n",
        "    json.dump(summary, f, indent=2)\n",
        "\n",
        "print(\"\\n=== MERGED SUMMARY ===\")\n",
        "print(json.dumps(summary, indent=2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "z-_imt8duTDU",
        "outputId": "47bb7240-1f3c-44ad-b7dd-15a9462defb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/Users/ganeshkumarboini/Downloads/drug_data_kg_openfda_edges_no_drop.graphml'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-964540598.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;31m# Load graphs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;31m# =========================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m \u001b[0mG1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOPENFDA_PATH\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;31m# your normalized OpenFDA minimal (node_type/node_name/node_source + relation/subfield)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0mG2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPRIMEKG_PATH\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;31m# PrimeKG+Hetionet combined\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-964540598.py\u001b[0m in \u001b[0;36mload_graph\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# =========================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_graphml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mkind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"MultiDiGraph\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_multigraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"DiGraph\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Loaded {path} -> {kind} | nodes={G.number_of_nodes():,} edges={G.number_of_edges():,}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/networkx/utils/decorators.py\u001b[0m in \u001b[0;36mfunc\u001b[0;34m(_argmap__wrapper, *args, **kwargs)\u001b[0m\n\u001b[1;32m    782\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__wrapper\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0margmap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lazy_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__wrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m         \u001b[0;31m# standard function-wrapping stuff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/networkx/utils/decorators.py\u001b[0m in \u001b[0;36margmap_read_graphml_1\u001b[0;34m(path, node_type, edge_key_type, force_multigraph, backend, **backend_kwargs)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbz2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgzip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/networkx/utils/decorators.py\u001b[0m in \u001b[0;36m_open_file\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m         \u001b[0mfobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_dispatch_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/ganeshkumarboini/Downloads/drug_data_kg_openfda_edges_no_drop.graphml'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "from collections import Counter, defaultdict\n",
        "from pathlib import Path\n",
        "import json\n",
        "import re\n",
        "import pickle\n",
        "from google.colab import drive\n",
        "\n",
        "# =========================\n",
        "# MOUNT GOOGLE DRIVE\n",
        "# =========================\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# =========================\n",
        "# CONFIG: set your paths (update these to your file locations in Drive)\n",
        "# =========================\n",
        "# Update these paths to point to your files in Google Drive\n",
        "OPENFDA_PATH = \"/content/drive/MyDrive/drug_data_kg_openfda_edges_no_drop.graphml\"\n",
        "PRIMEKG_PATH = \"/content/drive/MyDrive/primekg_hetionet_combined.graphml\"\n",
        "OUT_MERGED_GRAPH = \"/content/drive/MyDrive/merged_openfda_primekg.graphml\"\n",
        "OUT_MERGED_PICKLE = \"/content/drive/MyDrive/merged_openfda_primekg.pickle\"\n",
        "OUT_SUMMARY_JSON = \"/content/drive/MyDrive/merged_openfda_primekg.summary.json\"\n",
        "\n",
        "# Options\n",
        "USE_MULTIGRAPH = True          # keep every parallel edge (no drops)\n",
        "NORMALIZE_NAMES = True         # lower/strip/collapse spaces for node_name when matching\n",
        "PREFER_NODE_SOURCE = \"primekg\" # if node attribute conflicts: \"openfda\" or \"primekg\"\n",
        "\n",
        "# =========================\n",
        "# Helpers\n",
        "# =========================\n",
        "def load_graph(path):\n",
        "    G = nx.read_graphml(path)\n",
        "    kind = \"MultiDiGraph\" if G.is_multigraph() else \"DiGraph\"\n",
        "    print(f\"Loaded {path} -> {kind} | nodes={G.number_of_nodes():,} edges={G.number_of_edges():,}\")\n",
        "    return G\n",
        "\n",
        "def get_attr(attrs, k, default=\"\"):\n",
        "    v = attrs.get(k)\n",
        "    return default if v is None else v\n",
        "\n",
        "_ws_re = re.compile(r\"\\s+\")\n",
        "def canon_name(name: str) -> str:\n",
        "    s = name if isinstance(name, str) else str(name)\n",
        "    if NORMALIZE_NAMES:\n",
        "        s = _ws_re.sub(\" \", s.strip().lower())\n",
        "    return s\n",
        "\n",
        "def node_inventory(G, node_type_key=\"node_type\", node_name_key=\"node_name\"):\n",
        "    types = Counter(nx.get_node_attributes(G, node_type_key).values())\n",
        "    names_missing = sum(1 for _, a in G.nodes(data=True) if node_name_key not in a or not str(a.get(node_name_key,\"\")).strip())\n",
        "    return types, names_missing\n",
        "\n",
        "def ensure_node_basics(G, source_tag):\n",
        "    # guarantee node_name and node_source exist\n",
        "    for n, a in G.nodes(data=True):\n",
        "        if \"node_name\" not in a or not str(a.get(\"node_name\",\"\")).strip():\n",
        "            a[\"node_name\"] = str(n)\n",
        "        # stamp node_source if missing (may already exist in your KGs)\n",
        "        if \"node_source\" not in a or not a[\"node_source\"]:\n",
        "            a[\"node_source\"] = source_tag\n",
        "\n",
        "def summarize_graph(G, node_type_key=\"node_type\", edge_rel_key=\"relation\"):\n",
        "    kind = \"MultiDiGraph\" if G.is_multigraph() else \"DiGraph\"\n",
        "    n_nodes = G.number_of_nodes()\n",
        "    n_edges = G.number_of_edges()\n",
        "    node_types = Counter(nx.get_node_attributes(G, node_type_key).values())\n",
        "    edge_types = Counter(nx.get_edge_attributes(G, edge_rel_key).values())\n",
        "\n",
        "    node_types_list = sorted(node_types.items(), key=lambda kv: (-kv[1], kv[0]))\n",
        "    edge_types_list = sorted(edge_types.items(), key=lambda kv: (-kv[1], kv[0]))\n",
        "\n",
        "    # connectivity (MultiGraphs supported)\n",
        "    UG = G.to_undirected()\n",
        "    comps = list(nx.connected_components(UG))\n",
        "    largest = max((len(c) for c in comps), default=0)\n",
        "    frac = (largest / n_nodes) if n_nodes else 0.0\n",
        "    orphans = sum(1 for _ in nx.isolates(G))\n",
        "\n",
        "    summary = {\n",
        "        \"graph_kind\": kind,\n",
        "        \"nodes\": int(n_nodes),\n",
        "        \"edges\": int(n_edges),\n",
        "\n",
        "        \"node_types_count\": int(len(node_types_list)),\n",
        "        \"node_types\": node_types_list,\n",
        "\n",
        "        \"relation_types_count\": int(len(edge_types_list)),\n",
        "        \"relation_types\": edge_types_list,\n",
        "\n",
        "        \"connectivity\": {\n",
        "            \"components\": int(len(comps)),\n",
        "            \"largest_component_size\": int(largest),\n",
        "            \"largest_component_fraction\": float(frac),\n",
        "            \"orphans\": int(orphans),\n",
        "        },\n",
        "\n",
        "        \"keys_used\": {\n",
        "            \"node_type_key\": node_type_key,\n",
        "            \"edge_rel_key\": edge_rel_key,\n",
        "        },\n",
        "    }\n",
        "    return summary\n",
        "\n",
        "def triplet_schema(G, node_type_key=\"node_type\", edge_rel_key=\"relation\", top=30):\n",
        "    # list unique (src_type, relation, dst_type) and counts\n",
        "    counts = Counter()\n",
        "    # works for DiGraph & MultiDiGraph\n",
        "    if G.is_multigraph():\n",
        "        for u, v, k, a in G.edges(keys=True, data=True):\n",
        "            r = a.get(edge_rel_key, \"unknown\")\n",
        "            st = G.nodes[u].get(node_type_key, \"unknown\")\n",
        "            dt = G.nodes[v].get(node_type_key, \"unknown\")\n",
        "            counts[(st, r, dt)] += 1\n",
        "    else:\n",
        "        for u, v, a in G.edges(data=True):\n",
        "            r = a.get(edge_rel_key, \"unknown\")\n",
        "            st = G.nodes[u].get(node_type_key, \"unknown\")\n",
        "            dt = G.nodes[v].get(node_type_key, \"unknown\")\n",
        "            counts[(st, r, dt)] += 1\n",
        "    total = len(counts)\n",
        "    top_items = counts.most_common(top)\n",
        "    return total, top_items\n",
        "\n",
        "# =========================\n",
        "# Load graphs\n",
        "# =========================\n",
        "print(\"Loading graphs...\")\n",
        "G1 = load_graph(OPENFDA_PATH)     # your normalized OpenFDA minimal (node_type/node_name/node_source + relation/subfield)\n",
        "G2 = load_graph(PRIMEKG_PATH)     # PrimeKG+Hetionet combined\n",
        "\n",
        "# Ensure basic attrs present\n",
        "ensure_node_basics(G1, \"openfda\")\n",
        "ensure_node_basics(G2, \"primekg\")\n",
        "\n",
        "# Quick pre-merge stats\n",
        "t1, miss1 = node_inventory(G1)\n",
        "t2, miss2 = node_inventory(G2)\n",
        "print(\"\\nOpenFDA types (top):\", t1.most_common(10), \"| missing node_name:\", miss1)\n",
        "print(\"PrimeKG+Hetionet types (top):\", t2.most_common(10), \"| missing node_name:\", miss2)\n",
        "\n",
        "# =========================\n",
        "# Build canonical map by (node_type, node_name)\n",
        "# We create a fresh MultiDiGraph (or DiGraph) so nothing is lost.\n",
        "# =========================\n",
        "MG = nx.MultiDiGraph() if USE_MULTIGRAPH else nx.DiGraph()\n",
        "\n",
        "NODE_TYPE_KEY = \"node_type\"\n",
        "NODE_NAME_KEY = \"node_name\"\n",
        "NODE_SOURCE_KEY = \"node_source\"\n",
        "EDGE_REL_KEY = \"relation\"\n",
        "\n",
        "# map canonical key -> merged node id\n",
        "canon2id = {}\n",
        "# keep an incremental integer suffix to avoid accidental id collisions\n",
        "next_int = 0\n",
        "\n",
        "def make_merged_id(ntype, nname):\n",
        "    # Construct a stable readable id. If collides, append counter.\n",
        "    base = f\"{ntype}::{nname}\"\n",
        "    nonlocal next_int\n",
        "    if base in MG:  # extremely rare; but handle\n",
        "        while f\"{base}##{next_int}\" in MG:\n",
        "            next_int += 1\n",
        "        return f\"{base}##{next_int}\"\n",
        "    return base\n",
        "\n",
        "def upsert_node(nid, attrs, source_graph):\n",
        "    \"\"\"Insert node into merged graph using canonical (type, name) matching. Returns merged node id.\"\"\"\n",
        "    ntype = get_attr(attrs, NODE_TYPE_KEY, \"unknown\")\n",
        "    nname = get_attr(attrs, NODE_NAME_KEY, str(nid))\n",
        "    ckey = (canon_name(ntype), canon_name(nname))\n",
        "\n",
        "    if ckey in canon2id:\n",
        "        mid = canon2id[ckey]\n",
        "        # merge attributes (prefer PRIMEKG if configured)\n",
        "        existing = MG.nodes[mid]\n",
        "        # keep node_type and node_name as-is\n",
        "        # merge node_source\n",
        "        srcs = set(str(existing.get(NODE_SOURCE_KEY, \"\")).split(\"|\")) if existing.get(NODE_SOURCE_KEY) else set()\n",
        "        srcs2 = set(str(attrs.get(NODE_SOURCE_KEY, \"\")).split(\"|\")) if attrs.get(NODE_SOURCE_KEY) else set()\n",
        "        all_srcs = [s for s in (srcs | srcs2) if s]\n",
        "        MG.nodes[mid][NODE_SOURCE_KEY] = \"|\".join(sorted(set(all_srcs))) if all_srcs else existing.get(NODE_SOURCE_KEY, \"\")\n",
        "        # retain an 'orig_id_<source>' list\n",
        "        tag = \"primekg\" if source_graph == \"primekg\" else \"openfda\"\n",
        "        orig_key = f\"orig_id_{tag}\"\n",
        "        olds = set(str(MG.nodes[mid].get(orig_key, \"\")).split(\"|\")) if MG.nodes[mid].get(orig_key) else set()\n",
        "        olds.add(str(nid))\n",
        "        MG.nodes[mid][orig_key] = \"|\".join(sorted(olds))\n",
        "        return mid\n",
        "    else:\n",
        "        mid = make_merged_id(ntype, nname)\n",
        "        canon2id[ckey] = mid\n",
        "        # initialize node attrs\n",
        "        MG.add_node(mid)\n",
        "        MG.nodes[mid][NODE_TYPE_KEY] = ntype\n",
        "        MG.nodes[mid][NODE_NAME_KEY] = nname\n",
        "        MG.nodes[mid][NODE_SOURCE_KEY] = attrs.get(NODE_SOURCE_KEY, source_graph)\n",
        "        # store original ids by source\n",
        "        tag = \"primekg\" if source_graph == \"primekg\" else \"openfda\"\n",
        "        MG.nodes[mid][f\"orig_id_{tag}\"] = str(nid)\n",
        "        return mid\n",
        "\n",
        "def add_edge_preserving(u_mid, v_mid, eattrs, source_graph):\n",
        "    # always keep relation and subfield if present\n",
        "    rel = eattrs.get(EDGE_REL_KEY, \"unknown\")\n",
        "    subf = eattrs.get(\"subfield\", None)\n",
        "    payload = {\n",
        "        EDGE_REL_KEY: rel,\n",
        "        \"source_graph\": source_graph,\n",
        "    }\n",
        "    if subf is not None:\n",
        "        payload[\"subfield\"] = subf\n",
        "    # optional: keep original endpoints for traceability\n",
        "    # payload[\"orig_u\"] = str(u_mid)  # usually not needed\n",
        "    # payload[\"orig_v\"] = str(v_mid)\n",
        "    if MG.is_multigraph():\n",
        "        MG.add_edge(u_mid, v_mid, **payload)\n",
        "    else:\n",
        "        # In DiGraph, last write wins; to avoid drops we could count, but we promised no drops, so Multi is recommended.\n",
        "        MG.add_edge(u_mid, v_mid, **payload)\n",
        "\n",
        "# =========================\n",
        "# Add OpenFDA nodes/edges\n",
        "# =========================\n",
        "print(\"Adding OpenFDA nodes and edges...\")\n",
        "for n, a in G1.nodes(data=True):\n",
        "    upsert_node(n, a, \"openfda\")\n",
        "\n",
        "if G1.is_multigraph():\n",
        "    for u, v, k, a in G1.edges(keys=True, data=True):\n",
        "        u_mid = upsert_node(u, G1.nodes[u], \"openfda\")\n",
        "        v_mid = upsert_node(v, G1.nodes[v], \"openfda\")\n",
        "        add_edge_preserving(u_mid, v_mid, a, \"openfda\")\n",
        "else:\n",
        "    for u, v, a in G1.edges(data=True):\n",
        "        u_mid = upsert_node(u, G1.nodes[u], \"openfda\")\n",
        "        v_mid = upsert_node(v, G1.nodes[v], \"openfda\")\n",
        "        add_edge_preserving(u_mid, v_mid, a, \"openfda\")\n",
        "\n",
        "print(f\"After OpenFDA -> merged: nodes={MG.number_of_nodes():,} edges={MG.number_of_edges():,}\")\n",
        "\n",
        "# =========================\n",
        "# Add PrimeKG nodes/edges\n",
        "# =========================\n",
        "print(\"Adding PrimeKG nodes and edges...\")\n",
        "for n, a in G2.nodes(data=True):\n",
        "    upsert_node(n, a, \"primekg\")\n",
        "\n",
        "if G2.is_multigraph():\n",
        "    for u, v, k, a in G2.edges(keys=True, data=True):\n",
        "        u_mid = upsert_node(u, G2.nodes[u], \"primekg\")\n",
        "        v_mid = upsert_node(v, G2.nodes[v], \"primekg\")\n",
        "        add_edge_preserving(u_mid, v_mid, a, \"primekg\")\n",
        "else:\n",
        "    for u, v, a in G2.edges(data=True):\n",
        "        u_mid = upsert_node(u, G2.nodes[u], \"primekg\")\n",
        "        v_mid = upsert_node(v, G2.nodes[v], \"primekg\")\n",
        "        add_edge_preserving(u_mid, v_mid, a, \"primekg\")\n",
        "\n",
        "print(f\"After PrimeKG -> merged: nodes={MG.number_of_nodes():,} edges={MG.number_of_edges():,}\")\n",
        "\n",
        "# =========================\n",
        "# Optional: prefer one source's attrs when conflicts (kept minimal here)\n",
        "# =========================\n",
        "# You can extend this block to pull preferred per-type attributes.\n",
        "\n",
        "# =========================\n",
        "# Save merged graph in multiple formats\n",
        "# =========================\n",
        "print(\"Saving merged graph...\")\n",
        "\n",
        "# Save as GraphML\n",
        "nx.write_graphml(MG, OUT_MERGED_GRAPH)\n",
        "print(f\"Saved merged graph (GraphML) -> {OUT_MERGED_GRAPH}\")\n",
        "\n",
        "# Save as pickle\n",
        "with open(OUT_MERGED_PICKLE, 'wb') as f:\n",
        "    pickle.dump(MG, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "print(f\"Saved merged graph (Pickle) -> {OUT_MERGED_PICKLE}\")\n",
        "\n",
        "# =========================\n",
        "# Build & save summary\n",
        "# =========================\n",
        "print(\"Generating summary...\")\n",
        "summary = summarize_graph(MG, node_type_key=NODE_TYPE_KEY, edge_rel_key=EDGE_REL_KEY)\n",
        "\n",
        "# Triplet schema preview\n",
        "schema_total, schema_top = triplet_schema(MG, node_type_key=NODE_TYPE_KEY, edge_rel_key=EDGE_REL_KEY, top=30)\n",
        "summary[\"triplet_schema_types\"] = int(schema_total)\n",
        "summary[\"triplet_schema_top\"] = [[list(k), int(v)] for k, v in schema_top]\n",
        "\n",
        "with open(OUT_SUMMARY_JSON, \"w\") as f:\n",
        "    json.dump(summary, f, indent=2)\n",
        "\n",
        "print(\"\\n=== MERGED SUMMARY ===\")\n",
        "print(json.dumps(summary, indent=2))\n",
        "print(f\"\\nSummary saved -> {OUT_SUMMARY_JSON}\")\n",
        "\n",
        "# =========================\n",
        "# Additional info about the saved files\n",
        "# =========================\n",
        "print(f\"\\n=== FILES SAVED ===\")\n",
        "print(f\"GraphML: {OUT_MERGED_GRAPH}\")\n",
        "print(f\"Pickle:  {OUT_MERGED_PICKLE}\")\n",
        "print(f\"Summary: {OUT_SUMMARY_JSON}\")\n",
        "\n",
        "# Quick comparison of file sizes\n",
        "import os\n",
        "if os.path.exists(OUT_MERGED_GRAPH) and os.path.exists(OUT_MERGED_PICKLE):\n",
        "    graphml_size = os.path.getsize(OUT_MERGED_GRAPH) / (1024*1024)  # MB\n",
        "    pickle_size = os.path.getsize(OUT_MERGED_PICKLE) / (1024*1024)  # MB\n",
        "    print(f\"\\nFile sizes:\")\n",
        "    print(f\"GraphML: {graphml_size:.2f} MB\")\n",
        "    print(f\"Pickle:  {pickle_size:.2f} MB\")\n",
        "    print(f\"Ratio:   {graphml_size/pickle_size:.2f}x (Pickle is {pickle_size/graphml_size:.2f}x smaller)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qYQHNoZvymo",
        "outputId": "480a4d9c-8b02-4dc8-f5d2-d374b5c4d2b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Loading graphs...\n",
            "Loaded /content/drive/MyDrive/drug_data_kg_openfda_edges_no_drop.graphml -> DiGraph | nodes=100,495 edges=160,229\n"
          ]
        }
      ]
    }
  ]
}